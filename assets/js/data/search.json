[ { "title": "[Golang] map, slice, list 정리 ", "url": "/posts/golang-basic/", "categories": "Golang", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-07-23 00:00:00 +0900", "snippet": "[Golang] map, slice, list 정리Array 고정길이 배열 배열 크기를 동적으로 증가시키거나 부분 배열을 잘라내는 기능 없음. 배열의 크기를 데이터 타입 앞에 써줘야 함package mainfunc main() { var a [3] int a[0] = 1 a[1] = 2 a[2] = 3 println(a[1]) 초기화 값을 지정해주지 않으면 0으로 초기화가 됨. var a = [3]int{1,2,3}var b = [...]int{1,2,3}Slice 가변길이 배열. Python 의 List와 유사! Array와는 다르게 고정된 크기를 미리 지정하지 않을 수 있고, 동적으로 변경 가능. 부분 잘라내기 가능 선언 var v []T make(slice_type, slice_length, capacity) 함수 capacity : 내부 배열의 최대 길이 생략 시 capacity는 length와 동일 모든 요소가 zero value인 슬라이스를 생성함. package mainfunc main() { var a []int a = []int{1,2,3} a[1] = 10 println(a)}---func main() { s := make([]int, 5, 10) println(len(s), cap(s))}---ss := s[0:11]// 가변길이보다 더 큰 값을 주면 에러 발생 -&amp;gt; panic: runtime error: slice bounds out of range---s := make([]int, 5, 10)ss := s[0:10]fmt.Println(s)fmt.Println(ss)ss = append(ss, 1)sss := ss[0:11]fmt.Println(sss) Sub-slice func main(){ s := []int{0,1,2,3,4,5} s = s[2:5] } Append &amp;amp; Copy func main() { s := []int{0,1} s = append(s,2) s = append(s,3,4,5) } Map Key-value 쌍으로 된 데이터 타입. Python의 Dictionary와 유사var sMap map[int]string---sMap = make(map[int]string)---tickers := map[string]string{ &quot;GOOG&quot;: &quot;Google Inc&quot;, &quot;MSFT&quot;: &quot;Microsoft&quot;, &quot;FB&quot;: &quot;FaceBook&quot;,}" }, { "title": "[번역] Pid 네임스페이스에 대한 궁금증 ", "url": "/posts/eng04_pid-namespace/", "categories": "Linux", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-07-16 00:00:00 +0900", "snippet": "The Curious Case of Pid Namespaces[원본링크] https://hackernoon.com/the-curious-case-of-pid-namespaces-1ce86b6bc900Pid 네임스페이스에 대한 궁금증컨테이너들은 어떻게 pid들을 공유할까?네임스페이스들은 리눅스 컨테이너들의 가장 중요한 컴포넌트 중 하나이다.네임스페이스들은 공유 자원에 대해서 격리를 지원하는데, 각각의 어플리케이션이 자기 자신의 유니크한 시스템 뷰를 가질 수 있게 한다. 네임스페이스 덕분에 각각의 도커 컨테이너들은 자신의 파일시스템과 네트워크를 가질 수 있는 것이다. 리눅스는 수많은 배포를 통해서 네임스페이스를 더해왔다. 이러한 점진적인 변화 떄문에 네임스페이스의 각 타입들은 자신의 유니크한 도전들을 제공한다. 그 중에서도 Pid 네임스페이스는 특히 멀티 프로세스가 포함될 때 특별한 처리를 요구한다.리눅스에서의 Pid리눅스에서의 프로세스는 트리구조를 가지게 된다. 커널의 각 프로세스들은 유니크한 프로세스 식별자를 가지고 있는데, pid라고도 불린다. 각 프로세스의 발자취에 대한 기록은 직계 부모 프로세스로부터 물려받는다. Pid는 fork 시스템 콜로 생성되었을 때도 부모로부터 전달받는다. 커널은 새로운 자식 pid 를 생성하고 식별자를 호출한 프로세스로 반환해준다. 하지만 자식 pid를 수동으로 추적하는 것은 부모 프로세스에게 달려있다.커널에 의해 시작되는 첫번째 프로세스는 pid를 1로 가진다. 이 프로세스는 init process라고도 불리며 쉽게 init이라 불린다. init 의 부모 프로세스의 pid는 0이며 그것이 커널을 의미한다는 것을 알 수 있다. Pid 1은 유저스페이스 프로세스 트리의 루트이다. 리눅스 시스템에서는 어떤 프로세스든 반복적으로 각자의 부모 프로세스를 따라가다 보면 pid 1 을 찾을 수 있다. 만약 pid 1 이 죽게되면, 커널은 panic에 빠지고 서버를 재부팅해야만 한다.네임스페이스 훑어보기리눅스 네임스페이스들은 unshare 시스템 콜에 어떤 네임스페이스를 생성할 것인지에 대한 플래그를 전달해서 만들어진다. 대부분의 케이스에서 unshare 는 새로운 네임스페이스로 당신을 던져버린다. 예를 들어, 프로세스가 네트워크 네임스페이스를 생성하자마자 어떠한 디바이스도 연결되지 않은 빈 네트워크를 즉각적으로 확인할 수 있다.Pid 네임스페이스는 약간 다른데, 당신이 pid 네임스페이스를 unshare 했을때 프로세스는 즉각적으로 새로운 네임스페이스에 들어가지 않는다. 대신, fork를 해줘야한다. 자식 프로세스는 pid 네임스페이스에 들어가고 pid 1 이 된다. 이것을 통해서 특별한 성격이 가득 채워진다.또한 pid 네임스페이스는 프로세스 계층에 대해서 분리되어진다는 것을 주목해야한다. 다시말해서 fork 된 프로세스는 실제로는 두개의 Pid를 가지고 있다는 것이다. 새로운 네임스페이스에서의 pid 1, 네임스페이스 바깥에서 봤을 때의 pid.네임스페이스에서의 Pid 1네임스페이스 안에서 init (Pid 1)은 다른 프로세스와 비교했을 때 3개의 특별한 특성을 가진다. 자동으로 디폴트 시그널 핸들러를 가지지 않기 때문에 해당 시그널에 대해서 시그널 핸들러를 등록해두지 않았다면 시그널을 받았을 때 무시한다. (왜 도커라이즈 된 수 많은 프로세스들이 ctrl+c 를 했을 때 강제 종료되지 않고 docker kill 을 해야만 죽는 이유이다!) 만약 네임스페이스에서 다른 프로세스가 자식보다 먼저 죽었다면, 그 프로세스의 자식은 pid 1을 부모로 다시 가지게 된다. init 이 exit 상태인 프로세스들을 거두면서 커널이 프로세스 테이블에서 지울 수 있게 된다. 만약 프로세스가 죽는다면, pid 네임스페이스에서의 모든 프로세스들은 강제로 종료가 되며 네임스페이스는 정리가 될 것이다.init 프로세스는 컨테이너의 라이프타임과 매우 밀접하게 연관되어 있음을 알 수 있다.Docker의 “실수”도커(그리고 runc)는 새로운 pid 네임스페이스에서 지정된 프로세스를 컨테이너 엔트리 포인트로 pid 1 으로 실행시킨다. pid 1 로 실행하도록 디자인 된 부분은 어플리케이션 프로세스에 예기치 못한 행동을 불러일으킨다. 위에서 설명한 것처럼 pid 1로 프로세스가 실행되었을 때 만약 자신의 시그널 핸들러를 등록하지 않으면, 시그널이 먹히지 않을 것이다. 만약 포트한 자식 프로세스가 자식의 자식 프로세스가 죽기전에 먼저 죽어버리면, 좀비 프로세스가 컨테이너에 생성될 수 있고 잠재적으로 프로세스 테이블을 계속 채워갈 것이다.도커는 이 내용에 대해서 거의 손을 떼어 왔다. 대신에 컨테이너에서 특별한 init 프로세스를 실행할 수 있는데 어플리케이션 프로세스가 fork-exec 이 되는 것이다.(pid 1이 되는 것이 아니라, 1의 자식 프로세스로 해당 어플리케이션 프로세스가 생성된다) 많은 컨테이너들이 위의 문제를 피하기 위해서 이렇게 수행해왔다. 이 방법에는 한가지 불운한 영향이 있는데 컨테이너가 좀 더 복잡해진다는 것이다. 컨테이너가 진짜 init 시스템을 가지고 있을 때는 사람들이 의존성 격리에 대한 이점을 희생시키는 멀티 프로세스를 컨테이너에 내장하는 경향이 있었다. 도커의 pod 에 대한 네이티브 지원 부족은 이 문제를 계속해서 악화시킬 뿐이다.The Rkt “Solution”Rkt 는 이 문제에 대해서 좀 더 깔끔한 해결책을 제시한다. 당신이 시작한 프로세스가 init 프로세스가 아니라고 가정하고 사용자(systemd)를 위한 init 프로세스를 생성하는데 이 때 systemd는 컨테이너 프로세스에 대한 파일 시스템 네임스페이스를 만들고 실행한다. Systemd는 네임스페이스에서 pid 1이 되고 컨테이너 프로세스는 pid 2로 실행된다. 즉, 컨테이너가 init 프로세스를 제공할 경우 pid 2로 실행될 것이지만, 실제로는 거의 문제가 발생하지 않는다는 것이다.더 간단한 대안책단일 프로세스에 대해서" }, { "title": "[Linux System Programming] Ch10 시그널 ", "url": "/posts/linux_ch10/", "categories": "Linux", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-07-10 00:00:00 +0900", "snippet": "[Ch10 시그널]Ch10 시그널리눅스 환경에서 Robustness Test (강건성 테스트) 나 디버깅을 진행하다보면 여러가지 오류로 인해서 프로그램이 종료되는데, 이 때 Core dump가 있으면 디버깅에 유용하지만 로그만 남아 있는 경우도 있음.이 때 단서가 되는 부분이 시그널임 시그널은 비동기 이벤트 처리를 위한 메커니즘을 제공하는 소프트웨어 인터럽트이다.Hardware interrupt : 외부에서 전기적 신호(이벤트)가 발생했을 때Software interrupt : CPU가 연산중에 어떠한 조건에 맞는 이벤트가 발생했을 때 유저가 Ctrl+C 를 눌러 시스템 외부에서 발생시키거나, 프로세스가 0으로 나누는 연산을 수행한 경우처럼 프로그램이나 커널 내부 작업 중에 발생할 수도 있다. 또는 IPC(Inter-Process Communication) 기법으로 프로세스간 시그널 송수신도 가능하다. 중요한 점은 이벤트가 비동기적으로 발생할 뿐만 아니라 해당 프로그램도 시그널을 비동기적으로 처리할 수 있다는 점. 시그널 처리 함수는 커널에 등록되어 시그널이 전달되었을 때 그 함수가 비동기식으로 호출된다. → 프로세스 입장에서 일을 하고 있는 도중에 시그널이 오면 잠시 일을 멈추고 시그널에 대한 처리를 한 뒤 다시 본래의 일로 돌아온다는 의미 시그널 전달 가능 흐름 Kernel → Process Process → Process Thread → Thread 10.1 시그널 개념시그널의 생명 주기 시그널 발생 → 커널은 해당 시그널을 전달 가능할 때까지 쌓아둠 → 커널은 가능한 시점에 적절하게 시그널을 처리 커널은 프로세스 요청에 따라 세 가지 동작 중 하나를 수행함.시그널을 무시한다. 무시할 수 없는 시그널은 SIGKILL 과 SIGSTOP 두 가지 시스템 관리자가 프로세스를 종료하거나 멈출 수 있어야 하기 떄문 시그널을 붙잡아 처리한다. 커널은 프로세스의 현재 코드 실행을 중단하고 이전에 등록했던 함수로 건너뛰어서 해당 함수를 실행함. SIGINT 와 SIGTERM 은 가장 흔하게 잡을 수 있는 시그널. ex. 터미널 프로그램은 시그널을 잡아서 프롬프트로 다시 돌아간다. ex. 프로그램이 종료되기 전에 SIGTERM을 붙잡아서 네트워크 연결을 끊거나, 임시파일 삭제 등 종료와 관련된 작업을 수행할 수 있음 SIGKILL 과 SIGSTOP은 잡을 수 없다.기본 동작을 수행한다. 기본 동작은 시그널에 따라 다름. 대부분은 프로세스 종료 시그널을 전달 받게 되면 진행중인 테스크를 잠시 중단하고, Signal Handler를 수행한 후 다시 프로세스로 돌아옴 내부적으로는 조금 더 복잡하게 동작함 Signal을 처리하는 것은 Kernel 이지만, handler를 등록했다면 signal handler를 수행하기 위해서 다시 user 영역으로 돌아옴. handler를 호출하고 다시 Kernel 영역으로 돌아가서 본래 Task의 context를 이용해서 signal이 불린 시점으로 돌아감.10.1.1 시그널 식별자시그널은 모두 &amp;lt;signal.h&amp;gt; 파일에 정의되어 있음 시그널은 단순 양의 정수를 나타내는 선행처리기의 정의이다.시그널 번호는 1(보통 SIGHUP)에서 시작해서 선형적으로 증가하고, 전체 시그널이 대략 31개지만 대다수 프로그램은 몇 개만 처리함.10.1.2 리눅스에서 지원하는 시그널Table 10-1. SignalsSIGABRT abort() 함수를 호출한 프로세스에 이 시그널을 보낸다. 프로세스는 종료되고 코어 파일을 생성함. 리눅스에서는 assert() 호출이 실패할 경우 abort()를 호출함 abort() : 현재 상태를 core dump 하고 프로세스를 비정상적으로 종료하는 함수 exit() : 정상적으로 종료하는 함수 **core dump** : UNIX 계열에서 프로그램이 비정상적으로 종료되는 경우에 프로그램이 종료될 당시의 메모리 상태를 기록하여 생성된 파일. 디버깅 용도로 사용됨 SIGBUS 프로세스가 메모리 보호 이외에 다른 하드웨어 장애를 유발한 경우 커널에서 이 시그널을 보냄. 프로세스가 mmap() 으로 만든 메모리 영역에 부적절하게 접근할 때 커널에서 이 시그널을 보냄 SIGHUP 제어터미널 상에서 부모 프로세스가 죽거나 멈춘 게(hangup) 감지되면 SIGHUP 시그널을 보냄. 세션의 터미널 접속이 끊어질 때마다 커널에서 해당 세션 리더에게 이 시그널을 보냄. 또한, 커널은 세션 리더가 종료될 때 foreground process 그룹에 속한 모든 프로세스에 이 시그널을 보냄. 기본동작 이 시그널은 사용자의 로그아웃을 의미 → 프로세스 종료 데몬프로세스일 경우 자신의 설정을 다시 읽도록 하는 의미 ex. 아파치에 SIGHUP 을 보내면 httpd.conf를 다시 읽음. 데몬 프로세스는 제어 터미널이 없어서 정상적인 상황에서는 이 시그널을 절대 받을 수 없음. SIGINT 사용자가 인터럽트 문자(보통 Ctrl + C)를 입력했을 때 커널은 포어그라운드 프로세스 그룹에 속한 모든 프로세스에 이 시그널을 보냄. 기본동작 프로세스 종료. 하지만 프로세스에서 이 시그널을 붙잡아 처리할 수 있고, 일반적으로 종료 직전에 마무리 목적으로 사용 SIGKILL kill() 시스템 콜에서 보냄 시스템 관리자가 프로세스를 무조건 종료하도록 만드는 방법을 제공 잡거나 무시할 수 없으며 결과는 항상 해당 프로세스의 종료SIGSEGV 세그멘테이션 위반(Segmentation Violation) 에서 유래된 이름 유효하지 않은 메모리 접근을 시도하는 프로세스에 보냄 맵핑되지 않은 메모리에 접근하거나, 읽기를 허용하지 않는 메모리를 읽거나, 메모리에서 실행 가능하지 않은 코드를 실행하거나, 쓰기를 허용하지 않는 메모리에 쓰는 경우 기본동작 프로세스의 종료와 코어 덤프 생성 SIGSTOP kill() 에서만 보낸다. 무조건 프로세스를 정지시키며 잡을 수도 무시할 수도 없음.SIGWINCH 터미널 윈도우 크기가 변한 경우, 커널에서 포어그라운드 프로세스 그룹에 속한 모든 프로세스에 이 시그널을 보냄. 기본적으로는 무시하지만, 붙잡아 처리할 수 있음.10.2 시그널 관리 기초시그널 관리를 위한 가장 단순하면서도 오래된 인터페이스는 signal() 함수이다.#include &amp;lt;signal.h&amp;gt;typedef void (*sighandler_t)(int);sighandler_t signal (int signo, sighandler_t handler); signal() 호출이 성공되면 signo 시그널을 받았을 때 수행할 현재 핸들러를 handler로 명시된 새로운 시그널 핸들러로 옮겨 해당 시그널을 처리한다. handler 함수는 일반 함수와는 달리 이 함수의 반환값을 받아 처리할 수 있는 곳이 없기 때문에 반드시 void 를 반환해야 한다. 유일한 인자는 처리될 시그널의 시그널 식별자(ex. SIGUSR2) 를 나타내는 정수이다. void my_handler (int signo); 현재 프로세스에 대해 시그널을 무시하게 하거나 시그널을 기본 동작으로 재설정하는 용도로도 커널에 signal() 함수를 사용할 수 있음. (handler 위치에 넣어줄 수 있음 ) SIG_DFL signo로 지정한 시그널에 대한 동작을 기본값으로 설정한다. SIG_IGN signo로 지정한 시그널을 무시한다. return 해당 시그널의 이전 동작인 시그널 핸들러에 대한 포인터 or SIG_DFL, SIG_IGN 을 반환 에러 발생 시 SIG_ERR 반환 10.2.1 모든 시그널 기다리기pause() 시스템 콜은 프로세스를 종료시키는 시그널을 받을 때까지 해당 프로세스를 잠재운다.(테스트와 디버깅에 유용함)#include &amp;lt;unistd.h&amp;gt;int pause (void); pause() 는 붙잡을 수 있는 시그널을 받았을 때만 반환되며 -1을 반환. 리눅스 커널에서 가장 단순한 시스템 콜 중 하나이다. 해당 프로세스를 인터럽트 가능한 잠들기 상태로 만듬 실행 가능한 다른 프로세스를 찾기 위해 schedule() 을 호출하여 리눅스 프로세스 스케줄러를 실행한다. 예시#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;signal.h&amp;gt;/* handler for SIGINT and SIGTERM */static void signal_handler (int signo){ if (signo == SIGINT) printf (&quot;Caught SIGINT!\\n&quot;); else if (signo == SIGTERM) printf (&quot;Caught SIGTERM!\\n&quot;); else { /* this should never happen */ fprintf (stderr, &quot;Unexpected signal!\\n&quot;); exit (EXIT_FAILURE); } exit (EXIT_SUCCESS);}int main (void){ /* * Register signal_handler as our signal handler * for SIGINT. */ if (signal (SIGINT, signal_handler) == SIG_ERR) { fprintf (stderr, &quot;Cannot handle SIGINT!\\n&quot;); exit (EXIT_FAILURE); } /* * Register signal_handler as our signal handler * for SIGTERM. */ if (signal (SIGTERM, signal_handler) == SIG_ERR) { fprintf (stderr, &quot;Cannot handle SIGTERM!\\n&quot;); exit (EXIT_FAILURE); } /* Reset SIGPROF&#39;s behavior to the default. */ if (signal (SIGPROF, SIG_DFL) == SIG_ERR) { fprintf (stderr, &quot;Cannot reset SIGPROF!\\n&quot;); exit (EXIT_FAILURE); } /* Ignore SIGHUP. */ if (signal (SIGHUP, SIG_IGN) == SIG_ERR) { fprintf (stderr, &quot;Cannot ignore SIGHUP!\\n&quot;); exit (EXIT_FAILURE); } for (;;) pause (); return 0;}10.2.3 실행과 상속 fork() 시스템 콜을 통해서 프로세스가 생성되면 자식 프로세스는 부모 프로세스의 시그널에 대한 동작을 상속받는다. 대기 중인 시그널은 상속되지 않는데, 대기 중인 시그널은 특정 pid로 보낸 것이지, 자식 프로세스로 보낸 것이 아니기 때문. exec 시스템 콜 을 통해서 프로세스가 처음 생성되면 모든 시그널은 부모 프로세스가 이를 무시하는 경우를 제외하고 모두 기본 동작으로 설정 됨실행과 상속10.2.4 시그널 번호를 문자열에 맵핑하기시그널 이름으로 코드를 작성하면 힘듦→ 시그널 번호를 시그널 이름의 문자열로 변환할 수 있음sys_siglistextern const char * const sys_siglist[];static void signal_handler (int signo){ printf (&quot;Caught %s\\n&quot;, sys_siglist[signo]);} 최선의 선택 시스템에서 지원하는 시그널 이름을 담고 있는 문자열의 배열 시그널 번호를 색인으로 이용함BSD에서 정의된 psignal() 인터페이스#include &amp;lt;signal.h&amp;gt;void psignal (int signo, const char *msg); msg 인자로 전달한 문자열을 stderr에 출력하는데, 콜론과 공백 그리고 signo로 지정한 시그널 이름이 따라옴더 나은 인더페이스 strsignal()#define _GNU_SOURCE#include &amp;lt;string.h&amp;gt;char * strsignal (int signo); signo로 지정한 시그널의 설명을 가리키는 포인터를 반환함 하지만 반환된 문자열은 다음에 strsignal() 을 호출하기 전까지만 유효하기 때문에 Thread-safe 하지 않다. strsignal() uses a static buffer and is not thread safe. Use bsd_strsignal() for thread safety. 10.3 시그널 보내기kill() 시스템 콜은 특정 프로세스에서 다른 프로세스로 시그널을 보낸다.#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;signal.h&amp;gt;int kill (pid_t pid, int signo); pid가 0보다 큰 경우 (일반적) pid가 가리키는 프로세스에 signo 시그널을 보냄 pid 0 호출한 프로세스의 프로세스 그룹에 속한 모든 프로세스에 signo 시그널을 보냄 pid -1 호출한 프로세스가 시그널을 보낼 권한이 있는 모든 프로세스에 signo를 보냄 호출한 프로세스 자신과 init은 제외 pid &amp;lt; -1 프로세스 그룹 -pid 에 signo를 보냄 10.3.1 권한다른 프로세스에 시그널을 보내기 위해서는 보내는 프로세스가 적절한 권한을 가지고 있어야함 CAP_KILL 기능이 있는 (root process) 프로세스는 모든 프로세스에 시그널을 보낼 수 있음 이 기능이 없을 경우 프로세스의 유효 사용자 ID 나 실제 사용자 ID는 반드시 시그널을 받는 프로세스의 실제 사용자 ID나 저장된 사용자 ID와 유효해야함 → 즉, 사용자는 자신이 소유하고 있는 프로세스에만 시그널을 보낼 수 있음 SIGCONT(프로세스 정지 후 계속 수행) 에 대한 예외를 정의함. signo가 0 (null 시그널) 이라면 시그널을 보내진 않지만, 에러 검사는 수행하기 때문에 권한 체크가 가능함!int ret;ret = kill (1722, 0);if (ret) ; /* we lack permission */else ; /* we have permission */10.3.3 자신에게 시그널 보내기raise() 함수는 자기 자신에게 시그널을 보낼 수 있는 간단한 방법을 제공함#include &amp;lt;signal.h&amp;gt;int raise (int signo);raise (signo);===kill (getpid(), signo);10.3.4 프로세스 그룹 전체에 시그널 보내기프로세스 그룹 ID를 음수로 바꿔서 kill() 을 사용하는 것이 아니라 프로세스 그룹에 속한 모든 프로세스에 시그널을 보낼 수 있는 함수도 있음#include &amp;lt;signal.h&amp;gt;int killpg (int pgrp, int signo); killpg (pgrp, signo);===kill (-pgrp, signo);10.4 재진입성 (Reenterancy) Reenterant 함수 둘 이상의 스레드에 의해서 호출되었을 때, 호출된 순서에 상관없이 하나가 수행되고 난 다음 다른 함수 호출이 수행된 것처럼 제대로 된 결과를 반환해주는 함수를 의미 interrupt handler 와 signal handler에서 찾아볼 수 있음 특성 no static (or global) non-constant data not return the address to static (or global) non-constant data … 예시 function_a()가 호출되고 있는 도중 interrupt가 발생 interrupt_handler() 가 수행 interrupt_handler() 내부에서 function_a()를 다시 사용해도, 기존에 수행중이던 function_a() 의 수행 결과에 영향을 주면 안된다는 것이 Reenterancy 이다. Thread-safe VS Reenterancy Thread-safe : A Function that may be safely invoker soncurrently by multiple threads 즉, 멀티 스레드 환경에서 올바른 결과를 내어주는 함수를 의미 모든 reenterant 함수는 thread-safe 하지만, 모든 thread-safe 함수가 reenterant 함수인 것은 아니다. 커널이 시그널을 보낼 때, 프로세스는 코드 어디선가에서 실행 중인 상태이다.해당 시그널의 핸들러는 어떤 작업 도중에도 실행이 가능하다. 따라서 프로세스에 설정된 시그널 핸들러는 자신이 실행하는 작업과 자신이 손대는 데이터(특히 Global Data 를 수정할 때)를 아주 조심스럽게 다뤄야 함 !10.5 시그널 모음여러개의 시그널을 간편하게 다루기 위해서는 시그널을 집합으로 표시하는 자료 형식이 필요int 형식을 한 비트마다 하나의 신호로 대응시켜서 표시할 수 있지만 signal은 32개보다 많음→ sigset_t 라는 자료 형식이 만들어짐.sigset_t 와 같은 신호 집합을 사용하는 이유는 많은 신호를 간편하게 다루기 위함모든 신호를 막는다거나 (BLOCK), 막은 신호를 다시 푼다거나(UNBLOCK), 신호가 발생했지만 Block 되어서 대기(PENDING) 중인 신호가 무엇이 있는가 를 쉽게 파악할 수 있음 SIGSTOP과 SIGKILL은 절대 제어할 수 없음#include &amp;lt;signal.h&amp;gt;int sigemptyset (sigset_t *set);int sigfillset (sigset_t *set);int sigaddset (sigset_t *set, int signo);int sigdelset (sigset_t *set, int signo);int sigismember (const sigset_t *set, int signo); sigemptyset() set으로 지정된 시그널 모음을 비어있다고 표시하며 초기화 함 sigfillset() set으로 지정된 시그널 모음을 가득 차 있다고 표시하며 초기화 함 sigaddset() set으로 지정된 시그널 집합에 signo를 추가함 sigdelset() set으로 지정한 시그널 모음에서 signo를 제거함 sigismember() set으로 지정한 시그널 모음에서 signo가 있으면 1을 반환, 그렇지 않아면 0을 반환 10.5.1 추가적인 시그널 모음 함수 이 함수들은 유용하지만 POSIX 호환이 중요한 프로그램에서는 사용하면 안됨#define _GNU_SOURCE#define &amp;lt;signal.h&amp;gt;int sigisemptyset (sigset_t *set);int sigorset (sigset_t *dest, sigset_t *left, sigset_t *right);int sigandset (sigset_t *dest, sigset_t *left, sigset_t *right); sigisemptyset() set으로 지정된 시그널 모음이 비어있는 경우에는 1, 그렇지 않으면 0을 반환 sigorset() 시그널 모음인 left와 right의 합집합을 dest에 넣음 sigandset() 시그널 모음인 left와 right의 교집합을 dest에 넣음 10.6 시그널 블록시그널 핸들러와 프로그램의 다른 부분이 데이터를 공유해야 할 필요가 있다면 어떻게 할까?일시적으로 시그널 전달을 보류하여 이 영역을 보호한다.→ 시그널은 블록 되었다고 표현함 블록되는 동안 발생하는 어떤 시그널도 블록이 해제될 때까지는 처리되지 않음. 프로세스는 여러 시그널을 블록할 수 있으며 프로세스가 블록한 시그널 모음을 해당 프로세스의 시그널 마스크 라고 한다. sigprocmask() 는 how값에 따라 다르게 동작하며 프로세스 시그널 마스크를 관리한다.#include &amp;lt;signal.h&amp;gt;int sigprocmask (int how, const sigset_t *set, sigset_t *oldset);how SIG_SETMASK : 호출한 프로세스의 시그널 마스크를 set으로 변경함 SIG_BLOCK : 호출한 프로세스의 시그널 마스크를 현재 마스크와 set의 합집합으로 변경 SIG_UNBLOCK : 기존의 블록된 시그널에서 set의 시그널을 제거 oldset 이 null이 아니라면 이전 시그널 모음을 oldset에 넣는다. set 이 null인 경우 how를 무시하고 시그널 마스크를 변경하지 않지만, 시그널 마스크를 oldset에 넣는다 → set에 null 값을 넣어 전달하면 현재 시그널 마스크를 조회할 수 있음 예시#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;signal.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;int main(){ sigset_t set, oldset; // set과 oldset을 깨끗이 비워줌 sigemptyset(&amp;amp;set); sigemptyset(&amp;amp;oldset); // sigaddset으로 set에 SIGINT와 SIGQUIT을 추가 sigaddset(&amp;amp;set,SIGINT); sigaddset(&amp;amp;set,SIGQUIT); // set에 있는 시그널들을 block 시키기 위해서 sigprocmask를 호출하는데 how의 인자는 SIG_BLOCK sigprocmask(SIG_BLOCK,&amp;amp;set,NULL); printf(&quot;SIGINT와 SIGQUIT는 블록되었습니다.\\n&quot;); printf(&quot;Ctrl+C와 Ctrl+\\\\ 눌러도 반응이 없습니다.\\n&quot;); //만약 Ctrl + \\(SIGQUIT)을 눌렀다면 5초후 Coredump가 생기고 종료 //SIGQUIT의 기본동작은 Coredump + 종료 sleep(5); //현재 set에서 SIGINT를 뺌. set에는 SIGQUIT만 있는 상태 //중요한것은 프로세스에 적용하지 않은 상태 sigdelset(&amp;amp;set,SIGINT); //프로세스에 Unblock을 set에 적용. SIGQUIT은 이제 Block되지 않음 sigprocmask(SIG_UNBLOCK,&amp;amp;set,&amp;amp;oldset); printf(&quot;만약 Ctrl+\\\\을 눌렀다면 종료합니다.\\n&quot;); printf(&quot;현재 남은 시그널은 SIGINT입니다.\\n&quot;); printf(&quot;Ctrl+C를 눌러도 반응이 없습니다.\\n&quot;); sleep(5); set=oldset; sigprocmask(SIG_SETMASK,&amp;amp;set,NULL); printf(&quot;다시 SIGINT와 SIGQUIT이 블록됩니다.\\n&quot;); printf(&quot;Ctrl+C와 Ctrl+\\\\ 눌러도 반응이 없습니다.\\n&quot;); sleep(5); sigprocmask(SIG_UNBLOCK,&amp;amp;set,NULL); //아무 시그널(Cntl +C 혹은 Cntl+\\)을 주지 않았다면 아래의 메시지가 출력되고 종료 printf(&quot;모든 시그널이 해제되었습니다.\\n&quot;);}10.6.1 대기 중인 시그널 조회하기#include &amp;lt;signal.h&amp;gt;int sigpending (sigset_t *set); 커널에서 블록된 시그널이 발생할 경우, 이 시그널은 전달되지 않는다. sigpending() 는 대기 중인 시그널 모음을 조회할 수 있음 호출이 성공하면 대기 중인 시그널 모음을 set에 넣고 0을 반환함. 실패하면 -1을 반환10.6.2 여러 시그널 기다리기 프로세스가 자신의 시그널 마스크를 일시적으로 변경하고, 자신을 종료시키거나 자신이 처리할 시그널이 발생할 때까지 기다리게 만든다.#include &amp;lt;signal.h&amp;gt;int sigsuspend (const sigset_t *set); 시그널을 BLOCK시킴과 동시에 대기함. sigprocmask같은 경우 how를 SIG_BLOCK이나 SIG_SETMASK로 설정하면 블록하기만 할뿐 대기하지는 않는데, sigsuspend는 블록과 대기를 동시에 할 수 있음. 성공시 0, 실패시 -1을 반환 활용 방법 프로그램이 critical section에 머물러 있을 때 도착해서 블록되었던 시그널을 조회할 수 있음. 10.7 고급 시그널 관리 signal()은 시그널 핸들러를 구축하는 오래되고 가장 간단한 방법이지만, 매우 기초적이고 시그널 관리를 위한 최소한의 부분만 제공함 sigaction() 시스템 콜이 훨씬 더 훌륭한 시그널 관리 능력을 제공한다.#include &amp;lt;signal.h&amp;gt;int sigaction (int signo, const struct sigaction *act, struct sigaction *oldact); sigaction() 을 호출하면 signo로 지정한 시그널의 동작 방식을 변경한다. SIGKILL, SIGSTOP을 제외 act 가 NULL이 아닌 경우 시스템 콜은 해당 시그널의 현재 동작 방식을 act가 지정한 내용으로 변경함 oldact 가 NULL이 아닌 경우 해당 호출은 이전의 동작 방식( act가 NULL인 경우에는 현재의 방식) 을 oldact에 저장한다. sigaction 구조체는 시그널을 세세하게 제어할 수 있게 함struct sigaction { void (*sa_handler)(int); /* signal handler or action */ void (*sa_sigaction)(int, siginfo_t *, void *); sigset_t sa_mask; /* signals to block */ int sa_flags; /* flags */ void (*sa_restorer)(void); /* obsolete and non-POSIX */}; sa_handler 와 sa_sigaction이 유니언이라는 사실을 주의하고, 두 필드 모두에 값을 할당하지 않도록 해야 함 sa_handler 해당 시그널을 받았을 때 수행할 동작을 지정함. signal()과 마찬가지로 SIG_DFL, SIG_IGN, 시그널을 처리하는 함수를 가리키는 포인터가 들어올 수 있음 sa_sigaction void my_handler (int signo, siginfo_t *si, void *ucontext); 시그널 번호, siginfo_t 구조체, ucontext_t 구조체를 void 포인터로 타입 변환하여 받음. sa_flags 0개 혹은 하나 이상의 플래그에 대한 비트마스크. 해당 플래그들은 signo로 지정한 시그널의 처리를 변경함. (p.456 플래그 설명) SA_SIGINFO 를 설정하면 sa_handler 가 아니라 sa_signaction이 시그널을 처리하는 함수를 명시한다. SA_NODEFER 를 설정하지 않으면 현재 처리 중인 시그널도 블록됨. sa_mask 시그널 핸들러를 실행하는 동안 시스템이 블록해야 할 시그널 모음을 제공함 이 필드를 사용해서 여러 시그널 핸들러 간의 재진입을 적절하게 막을 수 있다. 10.7.1 siginfo_t 구조체siginfo_t 구조체에는 sa_handler 대신 sa_sigaction 을 이용하는 경우 시그널 핸들러로 전달할 정보가 가득함시그널을 보낸 프로세스에 대한 정보와 시그널을 일으킨 원인에 대한 정보를 포함하여 흥미로운 데이터가 많음.(p.458 각 필드 설명)typedef struct siginfo_t { int si_signo; /* signal number */ int si_errno; /* errno value */ int si_code; /* signal code */ pid_t si_pid; /* sending process&#39;s PID */ uid_t si_uid; /* sending process&#39;s real UID */ int si_status; /* exit value or signal */ clock_t si_utime; /* user time consumed */ clock_t si_stime; /* system time consumed */ sigval_t si_value; /* signal payload value */ int si_int; /* POSIX.1b signal */ void *si_ptr; /* POSIX.1b signal */ void *si_addr; /* memory location that caused fault */ int si_band; /* band event */ int si_fd; /* file descriptor */}; si_code 프로세스가 왜 그리고 어디서부터 시그널을 받았는지에 대한 설명이 있음 si_addr SIGBUS, SIGFPE, SIGILL, SIGSEGV, SIGTRAP 의 경우 이 void 포인터는 장애를 일으킨 주소를 저장함. si_value si_int와 si_ptr 의 유니언이다. 10.7.2 si_code 의 멋진 세계 si_code 필드는 시그널을 일으킨 원인을 알려주는데, 커널이 시그널을 보냈을 때 이 필드를 보면 왜 시그널을 보냈는지 알 수 있다. 모든 시그널에 대해서 유효한 값이 있고, 각 시그널에 대해서 유효한 값들도 존재한다. (p.459 참고)10.8 페이로드와 함께 시그널 보내기앞에서 확인했듯이 sigaction에서 SA_SIGINFO 플래그가 함께 등록된 시그널 핸들러는 siginfo_t 인자를 전달하는데, siginfo_t 구조체는 si_value 라는 필드를 포함하고있다.si_value 필드는 시그널을 생성한 곳에서 시그널을 받는 곳까지 전달되는 선택적인 페이로드이다.sigqueue() 함수를 이용해서 페이로드와 함께 시그널을 보낼 수 있다.#include &amp;lt;signal.h&amp;gt;int sigqueue (pid_t pid, int signo, const union sigval value); sigqueue() 는 kill()과 유사하게 동작 호출이 성공하면 signo 시그널은 pid 프로세스나 프로세스 그룹 큐에 들어가고 0을 반환 value int 와 void 포인터의 유니언임 union sigval { int sival_int; void *sival_ptr; }; 10.8.1 시그널 페이로드 예제sigval value;int ret;value.sival_int = 404;ret = sigqueue (1722, SIGUSR2, value);if (ret) perror (&quot;sigqueue&quot;); pid가 1722 인 프로세스에 404라는 정수 값을 페이로드에 담아 SIGUSR2 시그널과 함께 보낸다.10.9 시그널은 미운 오리 새끼? 시그널은 커널과 사용자 간 통신을 위한 구식 메커니즘이며 IPC의 원시적인 형태로 볼 수 있다. 멀티스레딩 프로그램과 이벤트 루프 세계에서 시그널은 적절하지 않음. 하지만 시그널은 커널에서 수많은 통보를 수신할 수 있는 유일한 방법이다!ref. https://d-yong.tistory.com/10 / http://slideplayer.com/slide/10812592/https://reakwon.tistory.com/53" }, { "title": "[번역] The Code Review Pyramid", "url": "/posts/eng03-code/", "categories": "Translate, codereview", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-07-09 00:00:00 +0900", "snippet": " Code review Pyramid에 대한 글 번역원본 링크The Code Review Pyramid코드리뷰에 대해서 이야기할 때 코드 포매팅이나 스타일에 관한 재미없는 논의들이 길고 지루하게 초점을 맞추는 경향이 있는 반면 중요한 측면(코드의 변경이 의도와 맞는지, 성능저하는 없는지, 기존 클라이언트와 호환은 잘 되는지 등)들은 덜 주목을 받는다.이 이슈에 대한 인지도를 높이고 초점을 맞춰야하는 측면에 대한 가이드를 제공하기 위해서 트위터에 Code Review Pyrimid라고 내가 부르는 하나의 이미지를 올렸다. 이 트윗의 의도는 코드리뷰를 하는 동안 어떤 중요한 부분에 초점을 맞춰야하는지, 어떤 부분이 자동화가 될 수 있고 되어야하는지에 대해서 알려주기 위함이다.몇몇 분들이 이 자료에 대해서 영구적이고 참조할 수 있는 포스팅과 고화질 사진을 원해서 여기다가 다시 올려둔다 :)Code Style (코드 스타일) 프로젝트의 포매팅 스타일이 적용되었나요? 네이밍 컨벤션을 잘 적용했나요? DRY(Don’t Repeat Yourself) 한가요? 중복이 없나요? 코드가 충분히 읽을만 한가요? (메서드 길이 등…)Tests (테스트) 모든 테스트를 패스했나요? 새로은 기능이 합리적으로 테스트되었나요? 코너 케이스들도 테스트되었나요? 유닛테스트가 가능한 곳이라면 유닛테스트를, 통합테스트가 필요한 곳이라면 통합테스트를 사용하고 있나요? NFR(non-functional requirement, 비기능요구사항) 들에 대한 테스트도 있나요? e.g. 성능Documentation (문서화) 새로운 기능이 합리적으로 문서화되어있나요? 관련 문서들 (README, API 문서, 사용자 가이드, 참조문서 등)이 잘 업데이트 되었나요? 문서들이 이해가 잘 되고 오타나 문법적인 실수는 없나요?Implemetaion Semantics 기존 요구사항을 잘 만족하나요? 논리적으로 정확한가요? 불필요한 복잡성이 없나요? 견고한가요? (동시성 이슈, 적절한 에러 핸들링 등) 성능 저하 문제는 없나요? 안전한가요? (SQL 인젝션 등) 관측 가능한가요? (메트릭, 로그, 추적 등) 덩치를 키우는 의존성이 새롭게 추가되진 않았나요? 라이센스는 적절한가요?API Semantics API가 줄일 수 있는 것은 잘 줄이고 필요한 만큼만의 크기로 잘 짜여졌나요? 여러가지 일을 수행하는 것이 아니라 한 가지 일만 잘 수행하고 있나요? 일관성이 있나요? 최소한의 원칙을 따르고 있나요? API 내부에서 구멍 뚫린 곳 없이 깔끔하게 나누어져 있나요? 유저가 직접적으로 겪는 변화는 없나요? (API 클래스들, 설정, 메트릭, 로그 포맷 등) 새로운 API가 일반적으로 유용하고 오버스펙이진 않나요?FAQ 왜 피라미드인가요?-&amp;gt; 피라미드의 하위 부분은 코드리뷰의 기초가 되어야하고 대부분을 차지해야 하기 떄문 에이, 저거 삼각형이잖아요! -&amp;gt; 그렇게 생각할 수도 있지, 근데 저거는 피라미드의 측면이야 저 그림 그리는데 어떤 툴 사용했나요?-&amp;gt; Excalidraw" }, { "title": "[Code Review] 코드리뷰 참고자료 정리", "url": "/posts/cr-01/", "categories": "Code Review", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages, codereview", "date": "2022-07-08 00:00:00 +0900", "snippet": "Code Review 란소프트웨어를 실행하지 않고 사람이 직접 검토하는 과정을 통해서, 잠재된 결함을 찾아내고 이를 개선해나가면서 전반적인 소프트웨어의 품질을 높이고자 하는 활동Programmer’s Ego개발자는 자신의 코드를 자신의 것으로 여기고 비판을 수용하지 않는 경우가 있다. 이를 Programmer&#39;s Ego라고 한다.The Ten Commandments of Egoless Programming ref. Understand and accept that you will make mistakes. (당신이 실수했다는 것을 이해하고 받아들여라) You are not your code. (당신은 당신의 코드가 아니다) No matter how much “karate” you know, someone else will always know more. (‘Karate’를 당신이 얼마나 알던지간에, 누군가는 당신보다 더 잘 알 수 있다. ) Don’t rewrite code without consultation (협의없이 코드를 다시 작성하지마라) Treat people who know less than you with respect, deference, and patience. (당신보다 많이 알지 못하는 사람이라 해도 존중과 인내로 대해라) The only constant in the world is change. (이 세상의 유일한 상수는 세계가 변화한다는 것이다.) The only true authority stems from knowledge, not from position. (권위는 지위에서 오는 것이아니라 오직 지식으로부터 나온다. ) Fight for what you believe, but gracefully accept defeat. (당신이 믿는 것에 대해서 투쟁하되, 우아하게 패배를 받아들여라) Don’t be “the guy in the room.” (방 안에 혼자 박혀있는 사람이 되지 마라) Critique code instead of people – be kind to the coder, not to the code. (사람이 아니라 코드를 비판해라 - 코드에게는 친절하지 안되, 코더에게는 친절해라 )Code review에 대한 공부최근 코드리뷰에 대해서 엄청난 필요성을 느끼고 관심을 가져보고 있다. (늦었다고 생각할 때가 제일 빠를때.. ㅎㅎ)이전부터 팀원 분들과의 협업 문화에 많은 갈증을 느끼고 있던 나였다. 하지만 협업문화를 누가 나에게 떠먹여주지 않는다는 것을 다시 한번 깨닫게 된 요즘.내가 열심히 공부해서 팀원분들과 문화를 만들어가고 함께 배워야한다고 생각했다.아래는 한번씩 보면 좋을 내용들을 정리해봤다.읽을 서적 읽기 좋은 코드가 좋은 코드다 좋은 코드, 나쁜 코드(Good Code, Bad Code) 구글 엔지니어는 이렇게 일한다(9장, 코드리뷰) 클린 코드기사/글 코드 리뷰 in 뱅크샐러드 개발 문화 (라인) 효과적인 코드 리뷰를 위해서 구글의 코드 리뷰 가이드 소스코드 리뷰에 대한 짧은 이야기… (카카오) 코드리뷰를 시작하려는 그대에게" }, { "title": "[Movie] Contact (with.스포) (WIP) ", "url": "/posts/movie/", "categories": "Movie", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-06-19 00:00:00 +0900", "snippet": "[Movie] ContactOcakham’s Razor All things being equal, the simplest solution tends to be the best one.전능하고 신비한 신이 우주를 창조하고 자신의 존재를 증명할 여지를 남기지 않은 것All powerful mysterious god created universe and decided not to give any proof to existencevs혹은 신은 원래 없었고, 우리가 나약하고 외로워서 만들어낸 존재라는 것Or god doesn’t exist and we created them어떤 것이 더 간단한가?주인공 앨리는 신이 없는 세상을 상상할 수 없다는 팔머에게 신의 존재가 착각이 아니라면 증거를 달라고 한다. 이때 팔머는 앨리에게 되묻는다.“Did you love your father?”“Yes, very much”“Prove it”아버지를 사랑했다면 증명해봐요. 라는 팔머의 질문에 대답을 하지 못하는 앨리.마음으로서 느끼는 감정과 신의 존재를 동등하게 볼 수 있을까?차원 이동을 경험하고 온 앨리는 청문회를 가게 된다.“멋지네요, 그들이 증거를 주길 거부해서 당신이 증거가 없군요.정신과에선 그런 걸 과대 망상증이라고 합니다. “여기서 과연 종교적인 것 그리고 과학적인 것은 이 자가 말하는 과대 망상증과 다른 것이 무엇일까. 우리는 어떤 것을 믿고 어떻게 살아가야 할까 ?“박사님, 혹시 과학 이론 중에 오컴의 면도날을 아시오?”“네, 모든 조건이 동일하면 가장 단순한 설명이 답일 수 있다.”“바로 그거에요. 이제 말해봐요 어떤게 더 말이 되죠?외계인으로부터 메시지가 와서 마법의 기계를 타고, 은하계의 중심에 갔다가 아버지와 윈드 서핑을 한 후 한 순간 후에 증거 하나 없이 집으로 돌아온 것? 아니면 당신의 경험은 해든의 마지막 퍼포먼스에 자신도 모르게 출연한 결과였다는 것? “박사는 말한다.“이 일이 일어나지 않을 가능성이 있냐구요? 네 있습니다.과학자로서 그 가능성도 인정해야만 하죠.하지만 그럴 수 없어요. 저는 경험했습니다.증거도 없고 설명할 수도 없지만, 인간으로서 제가 아는 모든 것이 그것이 실제였다고 말하니까요.저를 완전히 바꿔준 멋진 경험을 선물받은거에요.저는 봤습니다.우주에서 우리가 얼마나 작고 하찮고 얼마나 드물고도 소중한지요.우리는 우리보다 더 큰 뭔가에 속해 있고, 우리 중 누구도 혼자가 아니라는 것을요.그걸 모두와 나눌 수 있었으면 좋겠어요.제 소망은,, 모두가 한 순간만이라도 그 경외심과 겸허함과 희망을 느낄 수 있었으면 하는 겁니다.하지만 그저 제 소망일 뿐이겠죠.”증거가 없다고 믿지 못하면 종교는 어떻게 믿는단 말인가?이 장면을 보고 나는 그런 생각이 들었다.가끔 종교인들 중 신을 보았고 대화를 했다는 사람이 있다. 나는 그런 사람들을 믿지 못했다. 하지만 위의 장면과 다를 것이 무엇인가? 그는 보았고 그가 느낀 경외심, 희망을 나누고 싶었던 것 뿐이다.마지막 장면에서 기자들은 팔머에게 질문을 한다.“당신은 무엇을 믿습니까?”“신앙인으로서 저는 애로웨이 박사와는 다른 서약을 따르지만, 우리의 목표는 같습니다. 진실을 추구하는 것. 저는 그녀를 믿습니다.”너희는 단절되고 외롭다고 생각해. 하지만 그렇지 않아.그거 아니? 우리가 찾아낸 것 중에 이 공허함을 견딜 수 있게 하는 유일한 것은 서로밖에 없어." }, { "title": "[Golang] go module &#39;connection refuesd&#39; 오류 해결", "url": "/posts/tb_golang/", "categories": "Trouble Shooting, Golang", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-06-03 00:00:00 +0900", "snippet": "Go module ‘connection refuesd’ 오류 해결에러 go mod tidy 로 module 설치 시 connection refused에러 발생github.in/misc@v0.0.0-20220602070448-f6621fa768b4: verifying go.mod: github.in/misc@v0.0.0-20220602070448-f6621fa768b4/go.mod: reading https://sum.golang.org/lookup/github.in/misc@v0.0.0-20220602070448-f6621fa768b4: 410 Gone server response: not found: github.in/misc@v0.0.0-20220602070448-f6621fa768b4: unrecognized import path &quot;github.in/misc&quot;: https fetch: Get &quot;https://github.in/misc?go-get=1&quot;: dial tcp 10.182.235.107:443: connect: connection refusedmake: *** [mod_tidy] Error 1해결법$ export GOSUMDB=off$ go get -u참고 : https://lejewk.github.io/go-mod/" }, { "title": "[Linux] User에 Sudo 권한 부여하기 (feat. Jupyter notebook)", "url": "/posts/tb_linux/", "categories": "Trouble Shooting, Linux", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-05-12 00:00:00 +0900", "snippet": "User에 Sudo 권한 부여하기 (feat. Jupyter notebook)Su Superuser 라는 뜻 Linux에서 모든 것들을 접근하고 수정할 수 있다.Sudo SuperUser DO 에서 유래하였으나 Substitute User Do (다른 사용자의 권한으로 실행) 의 줄임말로 해석됨. 기본적으로 사용자 비밀번호를 요구하지만 Nopassword 옵션을 줄 수 도 있다.사용법 /etc/sudoers 에 sudo 정보가 저장이 되어있음. readonly이기 때문에 visudo 로 열어야 수정 가능# User privilege specificationroot ALL=(ALL:ALL) ALL root 는 이렇게 되어있음.새로운 유저 정보를 추가하기jovyan ALL=(ALL:ALL) ALL 요런식으로 /etc/sudoers 파일에 추가하면 됨. 근데 이렇게 하면 Password 요구하는데 password 없이 접속할 수 있게 하려면 이렇게 하면 됨.jovyan ALL=(ALL:ALL) NOPASSWD: ALL 나는 Dockerfile의 command Line 상에서 해당 user의 sudo 권한을 주고 싶었기 때문에$ root# echo &quot;jovyan ALL=(ALL:ALL) NOPASSWD: ALL&quot; &amp;gt;&amp;gt; /etc/sudoers&amp;gt;&amp;gt;# Dockerfile# Give sudo privilege to jovyanRUN echo &quot;jovyan ALL=(ALL:ALL) NOPASSWD: ALL&quot; &amp;gt;&amp;gt; /etc/sudoers 이런식으로 root 권한으로 해당 문구를 넣어주었다.참고 : https://ko.wikipedia.org/wiki/Sudo , https://info-lab.tistory.com/163" }, { "title": "[System Design Interview] 14. 유튜브 설계 ", "url": "/posts/system_arch_14/", "categories": "System Design Interview", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-05-02 00:00:00 +0900", "snippet": "14. 유튜브 설계 유튜브 시스템은 언뜻 보기에는 간단 (창작자가 비디오를 올리고, 시청자는 재생 버튼을 누름) 하지만 이면에는 매우 복잡함. DAU : 20억 매일 재생되는 비디오 수 : 50억 미국 성인 73% 사용 5천만명의 크리에이터 광고수입은 19년 기준 150억 달러 모바일 인터넷 트래픽 중 37%를 유튜브가 점유 80개 언어로 이용 가능1단계. 문제 이해 및 설계 범위 확정 댓글 비디오 공유 좋아요 버튼 재생목록 채널 구독 → 설계 범위를 좁혀야함. 빠른 비디오 업로드 원활한 비디오 재생 재생 품질 선택 기능 Infrastructure cost 높은 가용성과 규모확장성, 안정성 모바일 앱, 웹, 스마트 TV개략적 규모 추정 DAU : 5백만 한 사용자는 하루에 평균 5개의 비디오 시청 10%의 사용자가 하루에 1개의 비디오 업로드 비디오 평균 크기 300MB 비디오 매일 저장 용량 → 5백만 _ 10% _ 300MB = 150TB CDN (Content Delivery Network) aws 사용 5백만 _ 5비디오 _ 0.3GB * $0.02 = $150,000 2단계. 개략적 설계안 제시 및 동의 구하기 BLOB 이나 CDN 상세설계는 지나침 Client 컴퓨터, 모바일, 스마트 TV CDN 비디오는 CDN에 저장. 재생누르면 CDN으로부터 스트리밍 API Server 비디오 스트리밍을 제외한 모든 요청을 처리함. 피드 추천, 비디오 업로드 URL 생성, 메타데이터 데이터베이스와 캐시 갱신, 사용자 가입 등 비디오 업로드 절차 사용자 컴퓨터나 모바일 폰 을 통해 유튜브를 시청하는 이용자 로드 밸런서 API 서버 각각으로 고르게 분산 API 서버 비디오 스트리밍을 제외한 모든 요청 처리 메타데이터 데이터베이스 비디오의 메타데이터를 보관 샤딩과 다중화를 적용해서 성능 및 가용성 충족 메타데이터 캐시 성능을 위해 비디오 메타데이터와 사용자 객체 캐싱 Original Storage 원본 비디오를 보관한 대형 BLOB 시스템 BLOB 이진 데이터를 하나의 개체로 보관하는 DB관리 시스템 트랜스 코딩 서버 비디오 트랜스 코딩은 비디오 인코딩이라 불리는 절차 비디오의 포맷(MPEG, HLS) 을 변환하는 절차 단말이나 대역폭 요구사항에 맞는 최적의 비디오 스티림을 제공 트랜스 코딩 비디오 저장소 트랜스 코딩이 완료된 비디오를 저장하는 BLOB 저장소 CDN 비디오를 캐싱 Completion Queue 비디오 트랜스 코딩 완료 이벤트들 보관 메시지 큐 Competion Handler 트랜스 코딩 완료 큐에서 이벤트 데이터를 꺼내어 메타데이터 캐시와 디비를 갱신할 작업 서버들 프로세스 A. 비디오 업로드 비디오를 원본 저장소에 업로드 트랜스 코딩 서버는 원본 저장소에서 해당 비디오를 가져와 트랜스코딩을 시작 트랜스 코딩 완료되면 아래의 절차 병렬 수행 완료된 비디오를 트랜스 코딩 비디오 저장소로 업로드 완료 핸들러가 이벤트 데이터를 큐에서 꺼냄 완료 핸들러가 메타데이터 디비와 캐시를 갱신 API 서버가 단말에게 비디오 업로드가 끝나서 스트리밍 준비가 되었음을 알린다.프로세스 B. 비디오 메타데이터 갱신. (비디오 URL, 크기, 해상도, 포맷, 사용자 정보가 포함) 원본 저장소에 파일이 업로드되는 동안, 단말은 병렬적으로 비디오 메타데이터에 갱신 요청을 API서버에 보낸다.비디오 스트리밍 절차 스트리밍 프로토콜 비디오 스트리밍을 위해 데이터를 전송할 때 쓰이는 표준화 된 통신 방법 MPEG-DASH Moving Picture Experts Group / Dynamic Adaptive Streaming over HTTP HLS HTTP Live Streaming Microsoft Smooth Streaming Adobe HTTP Dynamic Streaming. HDS 프로토콜마다 지원하는 비디오 인코딩이 다르고 플레이어도 다름. CDN Edge Server가 비디오 전송을 담당할 것이기 때문에 latency가 아주 낮음.3단계. 상세 설계비디오 트랜스 코딩 비디오가 다른 단말에서도 순조롭게 재생되려면 다른 단말과 호환되는 Bitrate와 Format으로 저장되어야 함. Bitrate 비디오를 구성하는 비트가 얼마나 빨리 처리되어야 하는지를 나타내는 단위 높으면 일반적으로 고화질 비디오 트랜스코딩의 중요성 Raw video는 사이즈가 큼. 호환성 문제 네트워크 대역폭에 따라 화질이 달라져야 사용자에게 끊김이 없음. 모바일 단말의 경우 네트워크 상황에 따라 비디오 화질을 자동 변경 인코딩 포맷 컨테이너 .avi, .mov, .mp4 코덱 압축 및 압축 해제 알고리즘 H.264, VP9, HEVC 유향 비순환 그래프 (DAG) 모델 크리에이터 각자 자기만의 비디오 프로세싱 요구사항이 있는데 (썸네일, 워터마크, 화질… ) 이 부분을 파이프라인을 지원함으로써 클라이언트가 직접 task 정의가 가능 원본 비디오 비디오 검사 비디오 인코딩 : 해상도, 코덱, 비트레이트 인코딩 조합 섬네일 워터마크 : 오버레이 형태로 표시 오디오 오디오 인코딩 메타데이터 병합비디오 트랜스 코딩 아키텍쳐 전처리기 비디오 분할 : 비디오 스트림을 Group Of Pictures라고 불리는 단위로 쪼갬. DAG 생성 : 클라이언트 프로그래머가 작성한 설정 파일에 따라 DAG를 만듬. 데이터 캐시 : 안정성을 높이기 위해 GOP와 메타데이터를 임시 저장소에 보관 DAG 스케줄러 DAG 그래프를 stage로 분할한 다음 각각 자원 관리자의 Queue에 넣음. 자원 관리자 자원 배분을 효과적으로 수행 세 개의 큐와 작업 스케줄러 작업 큐 실행할 작업이 보관되어 있는 우선순위 큐 작업 서버 큐 실행 큐 작업 스케줄러 작업 서버 DAG에 정의된 작업을 수행 임시 저장소 메타데이터는 캐시 / 비디오,오디오는 BLOB 인코딩된 비디오 인코딩 파이프라인의 최종 결과물 시스템 최적화 속도 최적화 : 비디오 병렬 업로드 하나의 비디오는 작은 GOP들로 분할 가능. 분할한 GOP를 병렬적으로 업로드 속도 최적화 : 업로드 센터를 사용자 근거리에 지정 Region Center 이용 속도 최적화 : 모든 절차를 병렬화 느슨하게 결합된 시스템을 만들어서 병렬성을 높이는 것 각 작업 사이에 메시지 큐 도임 Async하게 진행 가능 안전성 최적화 : 미리 사인된 업로드 URL Pre-signed 업로드 URL을 사용해서 authorized 사용자만 업로드할 수 있게 수행 POST 요청시 미리 사인된 URL을 받음. 클라이언트는 해당 URL으로 비디오 업로드 진행 안전성 최적화 : 비디오 보호 Digital Rights Management 도입 AES 암호화 Watermark 비용 최적화 CDN 은 비쌈. 비디오 스트리밍은 롱케일 분호를 따름. 인기있는 비디오는 빈번, 나머지는 거의 보는 사람이 없음. 1. 인기비디오는 CDN, 다른 비디오는 비디오 서버 2. 인기없으면 인코딩 안함 3. 지역별로 구분 4. CDN직접 구축 오류 처리 Highly Fault Tolerant 시스템을 만들어야 함. Recoverable Error 비디오 세그먼트 트랜스코딩 실패 → retry 혹은 오류 코드 반환 Non Recoverable Error 비디오 포맷이 잘못됨. 중단 후 오류 코드 반환 4단계. 마무리 API 서버 규모 확장성 : 수평적 스케일 아웃 디비 규모 확장성 : 다중화 , 샤딩 라이브 스트리밍 레이턴시 낮아야함. 스트리밍 프로토콜 비디오 삭제" }, { "title": "[Kubernetes] Pod 스케줄링 에러 scheduler 0/5 nodes are available", "url": "/posts/tb_k8s_taint/", "categories": "Trouble Shooting", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-04-28 00:00:00 +0900", "snippet": "Pod 스케줄링 에러 scheduler 0/5 nodes are available쿠버네티스에서 Pod 배포를 했을 때Warning FailedScheduling 40s (x5 over 3m50s) default-scheduler 0/5 nodes are available: 1 Too many pods, 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn&#39;t tolerate, 3 node(s) didn&#39;t match Pod&#39;s node affinity/selector.요런 에러 발생.정확하게 읽어보지도 않고 구글링했더니 명확한 답이 안나왔음.근데 하나 하나 제대로 읽어보니 Warning 에 답이 있었다… 1개의 노드는 Pod가 너무 많이 떠있고, 1개의 노드는 Taint (pod가 못뜨게 “얼룩”이 묻은 것임. master) 가 있고, Taint는 얼룩이라는 뜻. Node에 얼룩을 묻힐 수 있는데 얼룩이 있는 Node에는 pod가 마음대로 못뜸. 만약 Taint 가 있는 Node에 Pod를 띄우고 싶으면 Tolerance 값을 줘야함 (얼룩을 참는다는 의미!) 3개의 노드는 node affinity (node 친화도. 즉, 붙고 싶은 node가 이미 있다.)가 맞지 않다. Node Affinity 는 노드 친화도이다. Node selector와 거의 유사. 하지만 조금 더 유연하게 사용가능. 그러니깐 node affinity에다가 node 4 해놓으면 4번 노드에만 붙으려고 한다! 전체 노드는 5개이니 위의 케이스 중 하나가 잘못되어있다!!확인해보니 master 1개, affinity 는 4번 node!! 즉, 1개의 노드에 너무 많은 Pod가 떠 있어서 새로운 pod가 뜨지 못하는 스케줄링 이슈 발생.k get nodes -o yaml | grep pods로 각 노드의 max pod 수를 확인할 수 있다.해당 노드의 pod 하나를 삭제하니 정상적으로 스케줄링이 되는 것을 확인!" }, { "title": "[Kubernetes] Kubectx 사용 시 선택한 kubeconfig 를 제대로 못 불러오는 문제 해결", "url": "/posts/tb_kubeconfig/", "categories": "Trouble Shooting", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-04-21 00:00:00 +0900", "snippet": "Kubectx 사용 시 선택한 kubeconfig 를 제대로 못 불러오는 문제 해결 DOCS 여기에 거의 모든 정보가 나와있다.나는 Kubectx 라는 툴을 사용해서 다중 클러스터를 선택하고 있다. (매우 유용함!!)근데 클러스터 몇 개를 추가했더니, 선택한 새로운 클러스터 정보를 가져오는 것이 아니라 계속 똑같은 정보만 가져오는 것이다…좀 살펴봤더니 Kubectl의 Config 정보에 문제가 있었다.kubectl config view위의 명령어를 치면 저장된 kubectl config 값이 출력된다. k config viewapiVersion: v1clusters:- cluster: certificate-authority-data: DATA+OMITTED server: foo1 name: bar1- cluster: certificate-authority-data: DATA+OMITTED server: foo2 name: bar2contexts:- context: cluster: cluster.local user: foobaruser1 name: foobar1- context: cluster: cluster.local2 user: foobaruser2 name: foobar2- context: cluster: cluster.local user: foobaruser2 name: foobar3current-context: foobaruser1kind: Configpreferences: {}users:- name: foobaruser1 user: client-certificate-data: REDACTED client-key-data: REDACTED- name: foobaruser2 user: client-certificate-data: REDACTED client-key-data: REDACTEDconfig 에 대해서 좀 읽을 수 있어야 하는데, 요건 위에 첨부한 docs를 참고하자.쉽게 말해서current-context 값을 참조해서, 해당 cluster를 해당 user로 로그인해서 접근하는 흐름이다.근데 내가 겪었던 문제는 context의 값이 동일한 경우이다.무조건 각각 다른 cluster Name 과 User Name을 가지고 있어야 각자의 secret으로 다른 클러스터에 접근할 수 있다.근데 나는 전달받은 kubeconfig 를 사용하다보니 위와 같이 동일한 clusterName을 가지고 접근하고 있었다. 정리하자면, kubectl config view 명령어로 저장된 config 를 확인해보고 current context가 정확하게 내가 지정한 cluster, user 를 사용하고 있는지! 중복된 값을 사용하고 있지는 않는지 확인해볼 필요가 있겠다!" }, { "title": "[Linux System Programming] Ch08 파일과 디렉터리 관리 ", "url": "/posts/linux_ch08/", "categories": "Linux", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-04-19 00:00:00 +0900", "snippet": "[Ch08 파일과 디렉터리 관리]File Discripter VS Inode 같은 파일을 open() 으로 두번 열었을 때의 구조 프로세스에서 파일 입출력은 open 함수로 연 작업을 구분하는 것이며, 실제 물리적인 파일이 같은지는 구분하지 않음. 각각의 fd를 부여하고 커널에서도 각각의 파일의 상태와 현재 작업 위치를 별도로 갖음 inode는 파일 시스템에 저장됨 모든 파일 혹은 디렉토리는 유니크한 inode 값을 가지고 있다. fd는 파일 시스템 안에 저장되지 않음 커널에 의해 만들어지고 커널 안 메모리에 있는 fd 테이블에 저장됨. 8.1 파일과 메타데이터 inode 번호는 파일시스템에서 유일한 숫자 값인데 파일은 inode를 참조한다.$ ls -i1689459 Kconfig 1689461 main.c 1680144 process.c 1689464 swsusp.c1680137 Makefile 1680141 pm.c 1680145 smp.c 1680149 user.c1680138 console.c 1689462 power.h 1689463 snapshot.c1689460 disk.c 1680143 poweroff.c 1680147 swap.c inode는 파일의 접근 권한, 마지막 접근 시간, 소유자, 그룹, 크기 그리고 파일의 데이터 위치와 같은 메타데이터를 저장함.8.1.1. stat 함수#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;sys/stat.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;int stat (const char *path, struct stat *buf);int fstat (int fd, struct stat *buf);int lstat (const char *path, struct stat *buf); 메타데이터를 얻을 수 있음. stat path로 지정한 파일의 정보 반환 fstat fd로 지정한 파일의 정보 반환 lstat stat과 동일한데 심벌릭 링크일 경우 링크가 가리키고 있는 파일이 아닌 링크 그 자체의 정보를 반환한다 struct stat { dev_t st_dev; /* ID of device containing file */ ino_t st_ino; /* inode number */ mode_t st_mode; /* permissions */ nlink_t st_nlink; /* number of hard links */ uid_t st_uid; /* user ID of owner */ gid_t st_gid; /* group ID of owner */ dev_t st_rdev; /* device ID (if special file) */ off_t st_size; /* total size in bytes */ blksize_t st_blksize; /* blocksize for filesystem I/O */ blkcnt_t st_blocks; /* number of blocks allocated */ time_t st_atime; /* last access time */ time_t st_mtime; /* last modification time */ time_t st_ctime; /* last status change time */}; 정보는 stat 구조체에 저장됨.8.1.2 권한 주어진 파일의 권한 값을 변경#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;sys/stat.h&amp;gt;int chmod (const char *path, mode_t mode);int fchmod (int fd, mode_t mode); 불투명한 mode_t 정수타입으로 표현되는 mode의 유효한 값은 stat 구조체의 st_mode 필드에서 반환하는 값과 동일 파일 권한을 변경하려면 chmod() 나 fchmod() 를 호출하는 프로세스의 유효 ID가 파일의 소유자와 일치하거나 해당 프로세스에 CAP_FOWNER 기능을 사용할 수 있어야 함.8.1.3. 소유권#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;int chown (const char *path, uid_t owner, gid_t group);int lchown (const char *path, uid_t owner, gid_t group);int fchown (int fd, uid_t owner, gid_t group); lchown 은 심벌릭 링크를 따라가지 않고 그 자체의 소유권을 변경함. 호출이 성공하면 파일 소유자를 owner로, 그룹을 group으로 변경한 다음 0을 반환. CAP_CHOWN 기능이 있는 프로세스 (보통은 Root 프로세스임.) 만이 파일의 소유자를 변경할 수 있다. uid, gid 가 모두 0 이면 root 를 뜻함. -1 을 넘기면 바뀌지 않음.8.1.4 확장 속성 xattrs 라고 불리기도 하는 확장 속성은 파일과 관련한 키/값을 연권짓는 메커니즘을 제공한다. 확장 속성은 보안을 위한 필수 접근 제어처럼 원래 설계에는 포함되지 않은 새로운 기능을 지원함. 사용자 영역 애플리케이션이 임의로 키/값을 생성하고 읽고 쓸 수 있다는 점키와 값 확장 속성은 유일한 키로 구분된다. 키는 ‘namespace.attrb’ 형태를 취함.확장 속성 네임스페이스 커널은 네임스페이스에 따라 접근 정책을 다르게 적용한다. 리눅스는 현재 4가지 확장 속성 네임스페이스를 정의하고 있음. system security trusted user8.1.5 확장 속성 연산" }, { "title": "[Linux System Programming] Ch07 스레딩 ", "url": "/posts/linux_ch07/", "categories": "Linux", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-04-09 00:00:00 +0900", "snippet": "[Ch07 스레딩] 스레딩은 단일 프로세스 내에서 실행 유닛을 여러 개 생성하고 관리하는 작업을 뜻한다. 스레딩은 Data-race condition과 Deadlock을 통해 어마어마한 프로그래밍 에러를 발생시키는 원인이다.7.1 바이너리, 프로세스, 스레드 바이너리 저장장치에 기록되어 있는 프로그램 특정 OS와 머신 아키텍처에서 접근할 수 있는 형식으로 컴파일되어 아직 실행되지 않은 프로그램. 프로세스 실행된 바이너리를 표현하기 위한 OS의 추상 개념 메모리에 적재되고 가상화된 메모리와 열린 fd, 연관된 사용자와 같은 커널 리소스 등을 포함 스레드 프로세스 내의 실행 단위로 가상화된 프로세서, 스택, 프로그램 상태 등을 포함. 프로세스는 실행 중인 바이너리이고, 스레드는 OS의 프로세스 스케줄러에 의해 스케줄링될 수 있는 최소한의 실행 단위를 뜻함. 하나의 프로세스는 스레드를 하나 이상 포함한다. 가상 메모리 프로세스가 실제 물리적인 RAM이나 디스크 저장장치에 맵핑된 메모리의 고유한 뷰를 사용할 수 있도록 함. 스레드가 아니라 프로세스와 관련 있음. 각 프로세스는 메모리에 대한 하나의 유일한 뷰를 갖지만 한 프로세스 내의 모든 스레드는 메모리를 서로 공유한다. 가상 프로세서 여러 프로세스 상에서 많은 프로세스가 멀티태스킹 중이라는 사실을 숨김으로써 프로세스가 혼자 실행되고 있다고 착각하게 만든다. 스레드와 관련이 있음. 각각의 스레드는 스케줄이 가능한 독립적인 요소이며, 단일 프로세스가 한번에 여러 가지 일을 할 수 있게 해준다. → 스레드는 프로세스와 마찬가지로 시스템의 프로세서 모두 소유했다는 환상을 가지지만, 가상 메모리의 모든 메모리를 소유했다는 환상을 가지고 있진 않다. 또한 프로세스 내의 모든 스레드는 메모리 주소 공간 전체를 공유한다.7.2 멀티 스레딩 멀티 스레딩의 장점 프로그래밍 추상화 작업을 나누고 각각 실행 단위로 할당하는 것은 좋은 접근 방법 병렬성 프로세서가 여러 개인 머신에서 효과적으로 병렬성을 구현할 수 있음 응답속도 향상 멀티스레딩을 이용해 오래 실행되는 작업을 워커 스레드에 맡기고 최소한 하나의 스레드는 사용자 입력에 대응하는 작업을 수행 입출력 블록 스레드를 사용하지 않으면 입출력을 블록하면서 전체 프로세스를 멈추게 만든다. 컨텍스트 스위칭 스레드의 전환보다 프로세스 단위의 전환이 훨씬 비싸다. 메모리 절약 스레드는 여러개의 실행단위를 활용하면서도 메모리를 공유하는 방법을 제공함. → 스레드는 멀티 프로세스의 대안이기도 하다. 7.2.1 멀티스레딩 비용 같은 프로세스에 속한 스레드는 리소스를 공유하는데 같은 데이터를 읽거나 쓰는 것이다. 따라서 스레드 동기화는 매우 중요하고 어떻게 동작하는지 이해하고 있어야 한다. 설계 시작부터 반드시 스레딩 모델과 동기화 전략을 고려해야함.7.2.2 멀티스레딩 대안 지연시간과 입출력상의 장점이 스레드 사용 이유라면? → 다중입출력, 논블록 입출력, 비동기식 입출력을 조합해서 사용 가능 입출력 작업이 프로세스를 블록하지 않도록 함 제대로 된 병렬화가 목표라면? N개의 프로세스를 N개의 스레드처럼 프로세서를 이용하도록 하고 리소스 사용, 컨텍스트 스위칭 비용의 오버헤드를 감수해서 해결 가능 메모리 절약? → 스레드보다 더 제한된 방식으로 메모리를 공유할 수 있는 도구를 리눅스는 제공함. 7.3 스레딩 모델 리눅스에서는 1:1스레딩을 사용한다.7.3.1 사용자 레벨 스레딩 N:1 스레딩 스레드가 N개인 프로세스 하나는 단일 커널 프로세스에 맵핑됨. 장점 애플리케이션이 커널의 관여 없이 스스로 어떤 스레드를 언제 실행할지 결정할 수 있으므로 Context switching 비용이 거의 안듬. 단점 하나의 커널 요소가 N개의 스레드를 떠받치고 있기 때문에 여러개의 프로세스 활용을 못하고, 제대로 된 병렬성 제공이 안됨. 사용자 스레드에서 I/O가 하나라도 발생하면 해당 프로세스는 I/O가 풀릴 때 까지 영원히 Block됨.7.3.2 하이브리드 스레딩 N:M7.3.3 코루틴과 파이버 코루틴과 파이버는 스레드보다 더 작은 실행 단위를 제공함. 코루틴 : 프로그래밍 언어에서 사용 파이버 : 시스템에서 사용되는 용어 리눅스는 이미 빠른 컨텍스트 스위칭 속도로 인해 커널 스레드의 성능을 극한까지 다듬어야 할 필요가 없어서, 코루틴이나 파이버에 대한 네이티브 지원이 없다.7.4 스레딩 패턴 스레드를 사용하는 애플리케이션을 작성할 때 가장 중요하면서 제일 먼저 해야하는 일은 애플리케이션의 처리과정과 입출력 모델을 결정짓는 스레딩 패턴을 결정하는 것!7.4.1 연결별 스레드 하나의 작업 단위가 스레드 하나에 할당되는 프로그래밍 패턴. 작업 단위가 실행되는 동안 많아 봐야 하나의 작업이 스레드 하나에 할당됨. 즉, 작업이 완료될 떄까지 실행 하는 패턴 스레드는 연결이나 요청을 받아서 완료될 때 까지 처리, 작업을 완료하면 다른 요청을 받아서 다시 처리 연결별 스레드 모델에서는 연결이 스레드를 소유하기 때문에 입출력 블록킹이 허용됨. 프로세스단에서 생각하면 fork 모델이 이와 같은 패턴을 따름7.4.2 이벤트 드리븐 스레딩 대부분의 스레드는 많은 시간을 그저 대기 중임. 방법 모든 입출력을 비동기식으로 처리하고 다중 입출력을 사용해서 서버 내 제어 흐름을 관리한다. 입출력 요청이 반환되면 이벤트 루프는 해당 콜백을 대기 중인 스레드로 넘김. 7.5 동시성, 병렬성, 경쟁 상태 동시성 둘 이상의 스레드가 특정 시간에 함께 실행되는 것을 의미한다. 병렬성 둘 이상의 스레드가 동시에 실행되는 것을 의미 동시성은 병렬성 없이 이루어질 수도 있음. 단일 프로세서를 가진 시스템에서의 멀티태스킹 병렬성은 다중 프로세서를 필요로 하는 동시성의 특수한 예7.5.1 경쟁 상태 (Race Condition) 스레드는 순차적으로 실행되지 않고 실행이 겹치기도 하므로 각 스레드의 실행 순서를 예측할 수 없다. 스레드가 서로 리소스를 공유한다면 문제가 된다. 경쟁 상태 공유 리소스에 동기화되지 않은 둘 이상의 스레드가 접근하려 프로그램의 오동작을 유발하는 상황을 뜻함. 크리티컬 섹션(Critical Section) 경쟁상태가 발생할 수 있기 때문에 반드시 동기화가 되어야 하는 영역 경쟁 상태의 실제 사례 은행 입출금 예제 X++ 의 예제 동시에 진행하면 잘못된 결과를 초래할 수 있음. 7.6 동기화 경쟁 상태를 예방하려면 이 Critical Section의 접근을 Mutual Exclusion (상호 배제) 하는 방식으로 접근을 동기화해야 함. Atomic 다른 연산(혹은 연산의 집합)에 끼어들 여지가 없다는 것 7.6.1 뮤텍스 크리티컬 섹션을 원자적으로 만들기 위한 가장 평범한 기법은 크리티컬 섹션 안에서 상호 배제를 구현해서 원자적으로 만들어주는 Lock이다. 락이 있어서 상호 배제를 구현할 수 있으며 Pthread 및 여러 곳에서 뮤텍스 라고 불린다. Mutex. == Binary Semaphore 락은 동시성이라는 스레딩의 장점을 포기하기 때문에 크리티컬 섹션은 가능한 한 최소한으로 잡는 편이 좋다. Notice 락은 코드가 아니라 데이터에 걸어야 한다. 7.6.2 데드락 스레드를 사용하는 이유는 동시성 떄문. → 동시성이 경쟁 상태 유발 → 뮤텍스 사용 → 데드락 유발 데드락 두 스레드가 서로 상대방이 끝나기를 기다리고 있어서 결국엔 둘 다 끝나지 못하는 상태를 의미. 데드락 피하기7.7 Pthread 리눅스 커널의 스레딩 지원은 clone() 시스템 콜 같은 원시적인 수준뿐임. 하지만 사용자 영역에서 스레딩 라이브러리를 많이 제공한다.7.7.1 리눅스 스레딩 구현7.7.2 Pthread API스레드 관리 스레드 생성, 종료, 조인, 디태치 함수동기화 뮤텍스와 조건 변수, 배리어를 포함하는 스레드 동기화 함수7.7.3 Pthread 링크하기 glic에서 Pthread를 제공하지만 libpthread 라이브러리는 분리되어 있으므로 링크해줄 필요가 있다.gcc -Wall -Werror -pthread beard.c -o beard7.7.4 스레드 생성하기 Pthread 는 새로운 스레드를 생성하는 함수인 pthread_create()를 제공한다.#include &amp;lt;pthread.h&amp;gt;int pthread_create (pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg); 호출이 성공하면 새로운 스레드가 생성되고 start_routine 인자로 명시한 함수에 arg로 명시한 인자를 넘겨서 실행을 시작한다. pthread_t 포인터인 thread가 NULL이 아니라면 여기에 새로 만든 스레드를 나타내기 위해 사용하는 스레드ID를 저장한다. pthread_attr_t 포인터인 attr에는 새로 생성된 스레드의 기본 속성을 변경하기 위한 값을 넘긴다. attr에 NULL을 넘기면 기본 속성 스레드 속성은 스택 크기, 스케줄링 인자, 최초 디태치 상태 등의 특성 결정 start_routine 은 다음과 같은 형태를 갖춰야함 void * start_thread (void *arg); fork와 유사하게 새로 생성된 스레드는 부모 스레드로부터 대부분의 속성과 기능 그리고 상태를 상속받음. 부모 프로세스 리소스의 복사본을 가지는 fork와는 다르게 스레드는 부모 스레드의 리소스를 공유한다. 프로세스의 주소 공간. 시그널 핸들러와 열린 파일을 공유 gcc 로 컴파일 할 때 -pthread 플래그를 넘겨야함. 예제 pthread_t tread;int ret;ret = pthread_create (&amp;amp;thread, NULL, start_routine, NULL);if (!ret) { errno = ret; perror(&quot;pthread_create&quot;); return -1;}/* a new thread is created and running start_routine concurrently ... */ 7.7.5 스레드 ID 스레드 ID (TID) 는 프로세스 ID(PID)와 유사하다. PID를 리눅스 커널에서 할당한다면 TID는 Pthread 라이브러리에서 할당한다. #include &amp;lt;pthread.h&amp;gt;pthread_t pthread_self (void); pthread_create() 호출이 성공하면 thread 인자에 저장된다. pthread_self() 함수를 이용해서 자신의 TID를 얻어올 수 있음.스레드 ID 비교하기 Pthread 표준은 pthread_t 가 산술 타입이기를 강제하지 않으므로 == 연산자가 동작하리라 보장할 수 없음. 따라서 비교 하려면 특수한 인터페이스를 사용해야한다.#include &amp;lt;pthread.h&amp;gt;int pthread_equal (pthread_t t1, pthread_t t2); 예제 int ret;ret = pthread_equal(thing1, thing2);if (ret != 0) printf(&quot;The TIDs are equal!\\n&quot;);else printf(&quot;The TIDs are unequal!\\n&quot;); 7.7.6 스레드 종료하기 스레드 종료는 한 스레드가 종료되도 그 프로세스 내의 다른 스레드는 계속 실행된다는 점만 제외하면 프로세스 종료와 비슷함. 스레드가 종료되는 상황 start_routine 함수가 반환한 경우. 이는 main() 함수가 끝까지 실행된 상황과 비슷 pthread_exit() 함수를 호출한 경우 pthread_cancel() 함수를 통해 다른 스레드에서 중지시킨 경우 위는 관계된 스레드 하나만 종료됨. 아래는 프로세스 내 모든 스레드가 종료되어 그 프로세스도 종료되는 경우 프로세스의 main() 함수가 반환 프로세스가 exit() 호출 프로세스가 execve() 호출로 새로운 바이너리를 실행한 경우 스스로 종료하기 start_routine 을 끝까지 실행하면 스레드 스스로 종료함. start_routine 함수가 몇 번의 호출을 타고 들어간 콜 스택 깊숙한 곳에서 스레드를 종료시켜야 할 때는 아래의 시스템 콜 사용#include &amp;lt;pthread.h&amp;gt;void pthread_exit (void *retval);다른 스레드 종료하기 pthread_cancel 함수를 통해 다른 스레드를 취소시켜 종료할 수 있음.#include &amp;lt;pthread.h&amp;gt;int pthread_cancel (pthread_t thread); 실제 종료는 비동기적으로 일어남. 스레드가 취소될지, 또 언제 실행될지는 조금 복잡함. 스레드의 취소 상태는 가능일 수도 있고, 불가능일 수도 있다. 기본값은 취소 가능임. 스레드의 취소 상태는 pthread_setcancelstate() 를 통해 변경할 수 있음 #include &amp;lt;pthread.h&amp;gt;int pthread_setcancelstate (int state, int *oldstate); 스레드의 취소상태가 state 값으로 설정되고 이정 상태는 oldstate에 저장됨. state PTHREAD_CANCEL_ENABLE PTHREAD_CANCEL_DISABLE 스레드의 취소 타입 비동기 취소 요청이 들어온 이후에 언제든지 스레드를 종료시킬 수 있음 특정한 상황에서만 유용함 프로세스를 정의되지 않은 상태로 남겨두기 때문. 스레드가 공유 리소스를 사용하지 않고 시그널 세이프한 함수를 호출한 경우에만 사용해야함 유예 기본 값 취소 타입 변경 함수 #include &amp;lt;pthread.h&amp;gt;int pthread_setcanceltype (int type, int *oldtype); type PTHREAD_CANCEL_ASYNCHRONOUS PTHREAD_CANCEL_DEFERRED 종료 예제 int unused;int ret;ret = pthread_setcancelstate (PTHREAD_CANCEL_ENABLE, &amp;amp;unused);if (ret) { errno = ret; perror (&quot;pthread_setcancelstate&quot;); return -1;}ret = pthread_setcanceltype (PTHREAD_CANCEL_DEFERRED, &amp;amp;unused);if (ret) { errno = ret; perror (&quot;pthread_setcanceltype&quot;); return -1;} int ret;/* `thread&#39; is the thread ID of the to-terminate thread */ret = pthread_cancel (thread);if (ret) { errno = ret; perror (&quot;pthread_cancel&quot;); return -1;} 취소 상태를 가능으로 바꾸고, 취소 타입은 취소 유예로 설정하는 예제 7.7.7 스레드 조인과 디태치 스레드 생성과 종료는 쉽지만, wait() 함수와 마찬가지로 모든 스레드의 종료를 동기화 해야한다. 이를 스레드 조인이라고 함.스레드 조인 조인은 스레드가 다른 스레드가 종료될 때까지 블록되도록 한다.#include &amp;lt;pthread.h&amp;gt;int pthread_join (pthread_t thread, void **retval); 호출한 스레드는 thread 로 명시한 스레드가 종료될 때까지 블록한다. 해당 스레드가 이미 종료되었다면 pthread_join() 은 즉시 반환된다. 스레드가 종료되면 호출한 스레드가 깨어나고 retval이 NULL이 아니라면 그 값은 종료된 pthread_exit()에 넘긴 값이거나 start_routine 에서 반환한 값이다. 스레드 조인은 다른 스레드의 라이프 사이클에 맞춰 스레드의 실행을 동기화하는 것이다. Pthread 의 모든 스레드는 서로 동등하므로 어떤 스레도도 조인 가능하다. 하나의 스레드는 여러 스레드를 조인할 수 있지만, 하나의 스레드만 다른 스레드에 조인을 시도해야 한다. 예제 int ret;/* join with `thread&#39; and we don&#39;t care about its return value */ret = pthread_join (thread, NULL);if (ret) { errno = ret; perror (&quot;pthread_join&quot;); return -1;} 스레드 디태치 부모 프로세스에서 wait() 을 호출하기전까지 자식 프로세스가 시스템 리소스를 잡아먹는 것과 마찬가지로 스레드도 조인이 되기 전까지 시스템 리소스를 잡아먹고 있으므로 조인을 할 생각이 없는 스레드는 디태치해두어야 한다.#include &amp;lt;pthread.h&amp;gt;int pthread_detach (pthread_t thread);7.7.9 Pthread 뮤텍스뮤텍스 초기화하기 뮤텍스는 pthread_mutex_t 객체로 표현된다.pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;뮤텍스 락 걸기#include &amp;lt;pthread.h&amp;gt;int pthread_mutex_lock (pthread_mutex_t *mutex); 호출이 성공하면 mutex로 지정한 뮤텍스의 사용이 가능해질 때까지 호출한 스레드를 블록한다. 해당 뮤텍스가 사용 가능한 상태가 되면 호출한 스레드가 깨어나고, 이 함수는 0을 반환한다.뮤텍스 해제하기#include &amp;lt;pthread.h&amp;gt;int pthread_mutex_unlock (pthread_mutex_t *mutex);" }, { "title": "[미라클모닝][MKYU] 514 프로젝트 7일차 ", "url": "/posts/miracle07/", "categories": "Miracle Morning, GOOD JJACK World", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-04-07 00:00:00 +0900", "snippet": "[미라클모닝][mkyu] 514 7일차4/7 당신의 빅팬은 누구입니까?내가 나의 빅팬이 되어야 다른 사람을 사랑할 수 있다.탄생! 나 스스로 평생 내 팬이 되겠다는 약속→ 자녀 교육의 베이스→ 탄생! 너 스스로 평생 너의 팬이 되겠다는 약속을 할 수 있게 해라내가 나를 응원하는 시스템 구축경제적 지원, 정서적 지원, 환경적 지원→ 이런 지원적인 부분들은 내가 구축해야한다.내가 팬이 되면 벌어지는 일!덕질을 한다. 계속 나에 대해 물어보고 질문을 던진다.사랑해요, 힘내요! 걱정마 남은 나의 모든 일을 공감하지 못한다. 남이 하기 전에 내가 먼저 해야한다. 자신있게 이런 말을 하기 위해서는 내가 진정한 나의 빅 팬이 되어야 할 수 있음. 후원한다.영어공부#10Well, It made my dad proudNow, Don’t you feel better remy?You’ve helped the noble cause.Noble? We are thieves dad.And what we’re stealing is, Let’s face it, garbage.It isn’t stealing if no one wants itIf no one wants it, why are we stealing it!#11Let’s just say, we have a different points of view.This much I knew.If we are what you eat, then I only want to eat the good stuff.But to my dad,Food is fuel, you get picky about what you put it the tank, your engine is gonna die.Now shut up and eat your garbage." }, { "title": "[미라클모닝][MKYU] 514 프로젝트 5일차 ", "url": "/posts/miracle05/", "categories": "Miracle Morning, GOOD JJACK World", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-04-05 00:00:00 +0900", "snippet": "[미라클모닝][mkyu] 514 5일차4/5 디지털 에셋을 만드는 법디지털에셋 돈을 쓰면서 배워야함.디지털 세상에서 나의 자산을 거래처음 번 돈의 의미. 1,000배로 돌아온다. 디지털 에셋은 린하게 출시하고 유저의 피드백으로 커가는 것이다.무료와 유료의 경험차이 내가 돈 내고 배운 것이 유료 경험.영어공부#6And second, I have a highly developed sense of testing smellFlour, eggs, sugar, vanila bean, oh small twist of lemon.Oh you can smell all that?You have a gift#7This is emilie. My brother.He is easiliy impressed.So you can smell ingredients. So what!This is my dad. He is never impressed.He also happens to be the leader of our clan.So what’s wrong with having a highly developed senses?#8Don’t eat that!What’s going on here?Turns out that funny smell was rat poison.Suddenly dad didn’t think my talent was useless.I was feeling pretty good about my gift.#9Until dad gave me a job.That’s right. Poison checker.Close to godliness. Which means clean.You know cleanliness close to godliness.Never mind. Move on" }, { "title": "[미라클모닝][MKYU] 514 프로젝트 4일차 ", "url": "/posts/miracle04/", "categories": "Miracle Morning, GOOD JJACK World", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-04-04 00:00:00 +0900", "snippet": "[미라클모닝][mkyu] 514 4일차온 동네가 알 때 까지 꾸준해라 경제가 되려면 일정 규모가 되어야함.내 꾸준함이 남들에게 도움이 되게 해라" }, { "title": "[미라클모닝][MKYU] 514 프로젝트 2일차 ", "url": "/posts/miracle02/", "categories": "Miracle Morning, GOOD JJACK World", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-04-02 00:00:00 +0900", "snippet": "[미라클모닝][mkyu] 514 2일차4/2 세상을 사는 3가지 지혜의 말사랑해 시작할 때 많이 표현하라. 사랑을 표현하면 인간관계의 시작하기 쉬움미안해 유지할 때고마워 정리할 때영어공부#3But not everyone celebrates its success.Amusing title anyone can cook, what’s even more amusing is that Gusteu actually seems to believe it.I, on the other hand, take cooking seriously, No I don’t think anyone can do it.#5This is me.I think it aparent I need to rethink my life little bit.What’s my problem, firtst of all, I’m a rat.Which means life is hard." }, { "title": "[미라클모닝][MKYU] 514 프로젝트 1일차 ", "url": "/posts/miracle01/", "categories": "Miracle Morning, GOOD JJACK World", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-04-01 00:00:00 +0900", "snippet": "[미라클모닝][mkyu] 514 1일차4/1 누군가를 응원하는 법언제나 한결같이 그의 편이 되라. 내가 결혼을 안해봐서 모르지만,,, 왜 부부는 서로에게 한결같이 상대의 편이 될 수 없을까? 나는 될 수 있다고 생각한다. 부모라는 것은 한결같이 자식의 편이 되어주는 것대화가 통할 정도로 공부해라 사랑하는 사람을 응원하려면 말이 통해야한다. 말이 통하기 위해서는 공부해야한다. 자녀와 어느순간 말이 안통할 수가 있다. 공부를 해야한다.솔직하게 털어 놓고 친해져라영어공부 진행#1Althogh each of the world’s country will like to dispute this fact, we french know the truth.The best food in the world is made in France.The best food in France is made in Paris.And the Best food, some say, is made by Chef August#2Gusto’s restaurant is the Toast of Paris, booked 5 months in advance.And his dazzling ascent to the top of fine french cuisine has made his competitors envious.He is the youngest chef ever to acheive a five star rating.Chef Gusteau’s cook book ‘Any one can cook’ climbed to the top of best seller list." }, { "title": "[미라클모닝][MKYU] 514 서약서 ", "url": "/posts/miracle00/", "categories": "Miracle Morning, GOOD JJACK World", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-03-31 00:00:00 +0900", "snippet": "[미라클모닝][mkyu] 514 서약서서약서" }, { "title": "[Linux System Programming] Ch06 고급 프로세스 관리 ", "url": "/posts/linux_ch06/", "categories": "Linux", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-03-30 00:00:00 +0900", "snippet": "[Ch06 고급 프로세스 관리] 5장에서는 프로세스가 무엇인지, 생성, 제어, 종료에 관한 시스템 콜과 관련된 시스템에 대해 알아봤음. 이번 장에서는 리눅스 프로세스 스케줄러와 스케줄링 알고리즘을 알아본다.6.1 프로세스 스케줄링 프로세스 스케줄러는 커널의 서브 시스템으로써 유한한 리소스인 프로세서의 시간을 시스템 내의 프로세스에 나눠준다. 즉, 다음에 실행할 프로세스를 선택하기 위한 커널의 구성요소임. 실행 가능한 프로세스 블록되지 않은 프로세스 블록된 프로세스 자고 있거나, 커널로부터 입출력을 기다리고 있는 프로세스 프로세서의 개수보다 실행 가능한 프로세스가 더 많이 존재할 때는 스케줄러가 필요함 선점형 멀티태스킹 리눅스 다른 프로세스를 위해 실행 중인 프로세스를 멈추는 행위를 선점이라고 함. 스케줄러가 선점하기 전까지 프로세스에 허락된 실행 시간을 프로세스 타임 슬라이스라고 한다. 비선점형 멀티태스킹 프로세스가 스스로 실행을 멈추기 전까지 계속 실행함. 자발적으로 실행을 잠시 쉬는 것을 양보라고 함 너무 오래 실행되는 그런 단점때문에 최신 OS는 거의 선점형 을 사용한다. 6.1.1 타임 슬라이스 스케줄러가 각 프로세스에 할당하는 타임 슬라이스는 시스템 전반의 동작 방식과 성능에 관한 중요한 변수이다. 타임 슬라이스가 너무 크다면 프로세스는 다음 실행 시간까지 오래 기다려야 하며, 동시 수행 능력을 떨어트림. 반대로 너무 작으면 잦은 프로세스 전환으로 인해 일시적인 지역성과 같은 장점을 잃게 됨. 목적에 따라 크기를 다르게한다. 시스템이 처리할 수 있는 용량을 극대화하여 성능 향상을 하려고 큰 슬라이스를 사용함. 혹은 빠른 응답속도를 확보하기 위해서 작은 슬라이스를 사용함. → 이상적인 사이즈를 결정하기가 어려움! 6.1.2 입출력 위주 프로세스와 CPU 위주 프로세스 사용 가능한 타임 슬라이스를 끊임없이 계속 사용하는 프로세스를 CPU 위주 프로세스라고 한다. 스케줄러에서 허락하는 시간을 모두 사용함 예시 무한루프 과학계산, 수학연산, 이미지 처리 등 // 100% processor-boundwhile (1) ; 실행 시간보다 리소스를 사용하기 위해 기다리는 시간을 더 많이 사용하는 프로세스를 IO 위주 프로세스 라고 한다. 네트워크 입출력, 파일 입출력 기다림. cp, mv 같은 파일 유틸리티 , User GUI 등. 각각의 특성에 맞게 스케줄러를 선택해야함. CPU 위주 일시적인 지역성을 통해 캐시 적중률을 최대화하고 작업을 빨리 끝내기 위해 큰 타임 슬라이스를 사용 IO 위주 입출력 요청을 보내기까지 아주 짧은 시간이면 충분하고 대부분의 시간을 커널 리소스를 얻기 위해 블록되기 때문에 큰 슬라이스가 필요없음. 현실에서는 CPU와 입출력을 같이 사용함6.1.3 선점형 스케줄링 전통적인 유닉스 프로세스 스케줄링에서 모든 실행 가능한 프로세스는 타임 슬라이스를 할당받음 프로세스가 주어진 타임 슬라이스를 다 소진하면 커널은 그 프로세스를 잠시 멈추고 다른 프로세스를 실행. → 모든 프로세스는 자신보다 우선순위가 높은 프로세스가 있을지라도 그 프로세스가 타임 슬라이스를 모두 소진하거나 블록된다면 결국 실행될 기회를 얻게됨. → 모든 프로세스는 반드시 계속 진행되어야 한다는 규칙을 만들어냄6.2 CFS 스케줄러 Completely Fair Scheduler CFS 전의 전통 유닉스 시스템들은 우선순위와 타임 슬라이스 라는 변수를 사용해서 스케줄링을 구현했음 CFS는 타임 슬라이스 대신 CPU 시간의 일부를 각 프로세스에 할당한다. N개의 프로세스에 각각 1/N 만큼의 CPU 시간을 할당한다. 그리고 이를 각 프로세스의 nice 값에 따라 가중치를 준다. nice 값이 기본값인 0을 그대로 사용하는 프로세스의 가중치는 1이며, 따라서 할당받는 CPU 시간에는 변화가 없다. 기본값보다 적은 nice 값을 사용하는 (우선순위가 높은) 프로세스는 CPU 시간을 더 많이 할당 받음 각 프로세스가 수행될 시간을 결정하기 위해 CFS 스케줄러는 프로세스 별로 가중치가 적용된 값을 한정된 시간(Target Latency) 로 나눈다. 시스템의 스케줄링 레이턴시를 나타냄. 예시 Target Latency : 20 밀리초 5개의 프로세스 → 각 4밀리초 But, 프로세스가 많다면 Context Switching Overhead 때문에 일시적인 지역성의 효과는 줄어들고 시스템 전체 처리 성능은 매우 지장받음 →이런 상황을 피하기 위해 CFS는 최소단위 (Minimum Granularity) 를 사용함 최소 단위 프로세스가 실행되는 최저 시간 단위 모든 프로세스는 할당된 CPU 시간과 관계없이 최소 단위만큼은 실행된다는 의미 근데 이를 사용하면 공정성이 무너짐! → 납득할 수 있는 만큼의 평범한 상황에서는 최소 단위가 적용되지 않고, Target latency 만으로 공정성을 유지할 수 있다. 6.3 프로세서 양보하기 리눅스는 선점형 멀티태스킹 운영체제지만, 프로세스가 명시적으로 실행을 양보해서 스케줄러가 새로운 프로세스를 실행하도록 하는 시스템 콜을 제공한다.#include &amp;lt;sched.h&amp;gt;int sched_yield (void); sched_yield() 를 호출하면 현재 실행 중인 프로세스를 잠시 멈춘 다음 스케줄러가 다음에 실행할 새로운 프로세스를 선택하도록 한다. 다른 실행 가능한 프로세스가 없으면 sched_yield() 를 호출한 프로세스의 실행이 즉시 재개됨. → 이런 불확실성과 일반적으로 더 나은 대안에 대한 믿음 때문에 이 시스템 콜은 잘 안씀. 6.3.1 적당한 사용법 리눅스 커널은 가장 효율적이고 최적의 스케줄링 결정을 내리기에 부족함이 없음 → 일개 어플리케이션이 무엇을 언제 선점해야 할지 결정하는 것보다 커널이 훨씬 더 나은 결정을 할 수 있음 !! 쓰는 경우가 있긴 하지만 잘 안씀.6.4 프로세스 우선 순위 nice 값은 프로세스가 be nice 하기를 바라면서 만들어짐. -20 ~ 19 의 값을 가지고 있다. 값이 높을 수록 Nice 하기때문에 우선순위가 낮음.6.4.1 nice()#include &amp;lt;unistd.h&amp;gt;int nice (int inc); 호출이 성공하면 프로세스의 nice 값을 inc로 지정하고 새롭게 업데이트 된 값을 리턴한다. 오직 CAP_SYS_NICE 값을 가진 프로세스만 negative 값을 받을 수 있다. 보통 root 만 이럼. 결과적으로 non root 프로세스는 오직 우선순위를 낮출 수만 있음. 예시 int ret;errno = 0;ret = nice (10); /* increase our nice by 10 */if (ret == −1 &amp;amp;&amp;amp; errno != 0) perror (&quot;nice&quot;);else printf (&quot;nice value is now %d\\n&quot;, ret); inc 값에 0을 넣으면 프로세스의 현재 nice 값을 알 수 있다.6.4.2 getpriority() 와 setpriority()#include &amp;lt;sys/time.h&amp;gt;#include &amp;lt;sys/resource.h&amp;gt;int getpriority (int which, int who);int setpriority (int which, int who, int prio); which PRIO_PROCESS PRIO_PGRP PRIO_USER 각각 who 값이 pid, pgid, uid를 판단한다. 만약 who 가 0이면 현재 pid,pgid, uid를 받아옴. getpriority() 는 지정된 프로세스들 중에서 가장 높은 우선순위를 리턴함. setpriority() 는 prio 값으로 특정된 프로세스들 전부를 지정함. 예시 현재 프로세스의 우선순위를 출력한다.```cint ret; ret = getpriority (PRIO_PROCESS, 0);printf (“nice value is %d\\n”, ret); - 현재 프로세스 그룹의 전체 프로세스의 우선순위를 10으로 지정한다.```cint ret;ret = setpriority (PRIO_PGRP, 0, 10);if (ret == −1) perror (&quot;setpriority&quot;); 6.4.3 I/O 우선순위 기본적으로 I/O 스케줄러는 프로세스의 nice 값을 기준으로 I/O 우선순위를 결정한다.int ioprio_get (int which, int who)int ioprio_set (int which, int who, int ioprio) glibc 는 지원하지 않음.6.5 프로세서 친화 리눅스는 싱글 시스템에서 멀티프로세서를 지원함. 멀티프로세싱 머신에서 프로세스 스케줄러는 어떤 프로세스가 각 CPU에서 돌 것인지 판단해야만 한다. 프로세스가 놀 동안 CPU가 놀고 있으면 안됨. 프로세스가 한 CPU에 스케줄링 되고 다음에 다시 스케줄링 될 때 같은 CPU에 되어야함. migrating 부분에서 이점이 있음 가장 큰 비용은 migration 할 때 캐쉬의 영향이다. 프로세스 스케줄러는 프로세스를 특정 CPU에 오랫동안 두어야함.6.5.1 sched_getaffinity() 와 sched_setaffinity()#define _GNU_SOURCE#include &amp;lt;sched.h&amp;gt;typedef struct cpu_set_t;size_t CPU_SETSIZE;void CPU_SET (unsigned long cpu, cpu_set_t *set);void CPU_CLR (unsigned long cpu, cpu_set_t *set);int CPU_ISSET (unsigned long cpu, cpu_set_t *set);void CPU_ZERO (cpu_set_t *set);int sched_setaffinity (pid_t pid, size_t setsize, const cpu_set_t *set);int sched_getaffinity (pid_t pid, size_t setsize, cpu_set_t *set); sched_getaffinity() 는 프로세스 pid의 CPU 친밀도를 얻고 cpu_set_t 타입의 값에다가 저장한다. 만약 pid가 0이면 호출은 현재 프로세스의 affinity를 얻어옴. setsize 는 cpu_set_t 타입인데 타입의 사이즈 변화에 사용된다. 예제 cpu_set_t set;int ret, i;CPU_ZERO (&amp;amp;set);ret = sched_getaffinity (0, sizeof (cpu_set_t), &amp;amp;set);if (ret == −1) perror (&quot;sched_getaffinity&quot;);for (i = 0; i &amp;lt; CPU_SETSIZE; i++) { int cpu; cpu = CPU_ISSET (i, &amp;amp;set); printf (&quot;cpu=%i is %s\\n&quot;, i, cpu ? &quot;set&quot; : &quot;unset&quot;);} 현재 프로세스의 affinity 를 출력한다. cpu=0 is setcpu=1 is setcpu=2 is unsetcpu=3 is unset...cpu=1023 is unset 두개의 프로세스가 돌아가는 상태일 때의 출력값 만약 0,1 중에서 0만 쓰고 싶다면,,```ccpu_set_t set;int ret, i; CPU_ZERO (&amp;amp;set); /* clear all CPUs /CPU_SET (0, &amp;amp;set); / allow CPU #0 /CPU_CLR (1, &amp;amp;set); / disallow CPU #1 */ret = sched_setaffinity (0, sizeof (cpu_set_t), &amp;amp;set);if (ret == −1) perror (“sched_setaffinity”); for (i = 0; i &amp;lt; CPU_SETSIZE; i++) { int cpu; cpu = CPU_ISSET (i, &amp;amp;set); printf (&quot;cpu=%i is %s\\n&quot;, i, cpu ? &quot;set&quot; : &quot;unset&quot;); } ``` # 6.6 실시간 시스템 - 실시간 : Time Limit 이 존재함. - Low latency or 빠른 응답시간 : 빠르면 빠를수록 좋은 것 - 예제 - Task A는 특정 기능을 1초안에 수행하지 않으면 전체 시스템에 치명적인 위해를 가할 수 있음.- → Time limit : 1초.- → 1초라는 시간을 준수하면서 특정 기능을 수행하는 것을 `실시간`이라고 함 - Task B는 기능을 수행함에 있어 Time Limit 은 없다.- → 빠르면 좋긴하겠지만 느리다고 해서 치명적인 손상을 입히는 것은 아님. - 리눅스 기반의 Real-time OS - 리눅스 기반의 RTOS와 일반 리눅스 OS는 크게 차이가 없다.- 모든 OS는 preemptive 한 작업 수행을 보장함. - **일반 리눅스는 interrupt가 들어왔을 때 현재 수행 중인 시스템 콜을 끝낸 뒤 Context switching**이 일어나지만, **RT 커널 기반의 리눅스는 현재 작업 중인 프로세스의 시스템 콜 수행마저도 Interrupt를 걸어 작업 Switching에 대한 Latency를 최소화**한다 일반 프로세스 레벨에서는 nice/renice를, RT 프로세스에서는 chrt를 쓰면됨.6.6.1 Hard Real-Time VS Soft Real-Time System hard real-time system os의 데드라인을 무조건 따라야함. 데드라인을 넘어서는것은 제약적인 실패이고 큰 버그를 야기함. 예제 ABS 시스템, 총기 시스템, 의료 장비, 시그널 프로세싱.. soft real-time system 데드라인을 넘는 것을 크리티컬하다고 생각하지 않음. 예제 비디오 프로세싱 애플리케이션 데드라인이 넘어서 조금의 프레임이 깨져도 크게 영향이 없다. 6.6.2 Latency, Jitter and Deadlines Latency 잠재적 시간 지연 응답에 대한 실행이 나타나기 까지의 시간을 의미 지연이 os 데드라인보다 작거나 같다면 잘 동작하는 것이다. Jitter 응답간의 시차 지연 요소의 변동량. 즉, Latency 나 delay의 변화량 수준 연속적인 이벤트 간의 시간 편자는 레이턴시가 아니라 지터임. 6.6.3 Linux’s Real-Time Support 리눅스는 시스템 콜을 지원하여서 soft real-time 애플리케이션을 지원한다.6.6.4 Linux Scheduling Policies and Priorities 리눅스는 두가지 스케줄링 정책을 제공함. 로부터 매크로를 제공받는다. SCHED_FIFO, SCHED_RR, SCHED_OTHER 모든 프로세스들은 nice 값이랑 별개로 static priority 를 가지고 있음. 기본적으로 0이다. 실시간 프로세스에서는 1-99까지의 값을 가진다. 일반적으로 SCHED_OTHER 를 사용함 기본적으로 여러 프로세스 간 Time-sharing 방식(CFS Scheduler) 또는 우선순위 기반 스케줄링을 사용. FIFO, RR RT를 위한 FIFO 전략 FIFO는 timeslices가 없는 매우 심플한 실시간 전략이다. 더 높은 우선순위를 가진 프로세스가 없는 한 계속 진행한다. SCHED_FIFO 매크로를 사용함 정책에 타임슬라이스가 없기 때문에 비교적 간단하다. 프로세스가 가장 높은 우선순위에 있다면 항상 실행됨. 프로세스가 블록되거나 sched_yield() 가 실행되거나, 더 높은 우선순위의 프로세스가 들어오기 전까지 계속 실행됨. Q) 같은 우선순위의 프로세스들이 있다면?Rount-Robin 전략 FIFO 클래스와 동일하지만 같은 우선순위일 때 추가적인 전략들이 있다. SCHED_RR 매크로를 사용 스케줄러는 RR-classed 프로세스 각각에 타임 슬라이스를 배정한다. 프로세스가 자신의 타임슬라이스를 다 쓰면 스케줄러는 그 프로세스를 우선순위 리스트에 끝으로 보낸다. 주어진 우선순위에 프로세스가 하나밖에 없다면 RR은 FIFO 와 동일하다. RR 또한 같은 우선순위의 프로세스들 중에서 스케줄링을 계속 하기 때문에 FIFO와 거의 유사함.Normal 전략 SCHED_OTHER 은 기복적인 스케줄링 전략을 대표한다. (default non-real-time class) 모든 normal-classed 프로세스는 고정된 우선순위 값으로 0을 가지고 있다. 결과적으로 동작중인 FIFO or RR 프로세스들은 normal 프로세스를 점유할 것이다. 이 스케줄러는 nice 값을 사용함.Batch 스케줄링 전략 SCHED_BATCH 는 Batch or idle 스케줄링 전략이다. real-time과 어느정도는 반대된다. 다른 프로세스들이 타임슬라이스를 다 썼더라도, 시스템에 동작 가능한 프로세스가 있다면 실행하지 않는다.Linux 스케줄링 전략 설정하기#include &amp;lt;sched.h&amp;gt;struct sched_param { /* ... */ int sched_priority; /* ... */};int sched_getscheduler (pid_t pid);int sched_setscheduler (pid_t pid, int policy, const struct sched_param *sp); sched_getscheduler() 와 sched_setscheduler() 를 사용해서 리눅스 스케줄링 값을 조작할 수 있다. sched_getscheduler() 호출이 성공하면 pid 프로세스의 스케줄링 전략을 리턴한다. pid가 0이면 호출을 실행한 프로세스의 스케줄링 정책이 반환됨. 예시 int policy;/* get our scheduling policy */policy = sched_getscheduler (0);switch (policy) {case SCHED_OTHER: printf (&quot;Policy is normal\\n&quot;); break;case SCHED_RR: printf (&quot;Policy is round-robin\\n&quot;); break;case SCHED_FIFO: printf (&quot;Policy is first-in, first-out\\n&quot;); break;case -1: perror (&quot;sched_getscheduler&quot;); break;default: fprintf (stderr, &quot;Unknown policy!\\n&quot;);} sched_setscheduler() 를 호출하면 pid 에다가 policy를 넣어준다. sp 정책과 관련된 다른 파라미터들을 넣어주는 곳 shced_param 구조 안의 유효한 값들은 policy에 따라 다름. SCHED_RR과 SCHED_FIFO 는 sched_priority가 필요하고 SCHED_OTHER는 필요없음. 예시 이 예시는 RR 정책으로 static priority를 1로 수정한다.```cstruct sched_param sp = { .sched_priority = 1 };int ret; ret = sched_setscheduler (0, SCHED_RR, &amp;amp;sp);if (ret == −1) { perror (“sched_setscheduler”); return 1;}``` 스케줄링 정책을 지정할 때 SCHED_OTHER를 제외하고는 CAP_SYS_NICE 설정이 필요하다.6.6.5 스케줄링 파라미터 설정하기 POSIX는 스케줄링 정책과 관련된 파라미터들을 설정하고 가져올 수 있게 하기 위해서 sched_getparam() 과 sched_setparam() 을 지원한다.#include &amp;lt;sched.h&amp;gt;struct sched_param { /* ... */ int sched_priority; /* ... */};int sched_getparam (pid_t pid, struct sched_param *sp);int sched_setparam (pid_t pid, const struct sched_param *sp); sched_getscheduler() 호출은 오직 스케줄링 정책만 리턴하지만 sched_getparam() 은 sp에다가 pid 프로세스와 연관된 스케줄링 파라미터들을 전달한다. 예시 struct sched_param sp;int ret;ret = sched_getparam (0, &amp;amp;sp);if (ret == −1) { perror (&quot;sched_getparam&quot;); return 1;}printf (&quot;Our priority is %d\\n&quot;, sp.sched_priority); 만약 pid가 0이면 호출한 프로세스의 파라미터를 넘김. sched_setscheduler() 또한 스케줄링 파라미터를 저장하긴 하지만, sched_setparam() 은 나중에 파라미터를 변경할 때 유용하다. 예시 struct sched_param sp;int ret;sp.sched_priority = 1;ret = sched_setparam (0, &amp;amp;sp);if (ret == −1) { perror (&quot;sched_setparam&quot;); return 1;} 유효한 우선순위 값 범위 결정하기 리눅스에서는 1-99 값의 범위로 RT 스케줄링 정책을 지원한다. 리눅스는 현재 유효한 우선순위 값을 알기 위해서 시스템 콜을 지원한다.#include &amp;lt;sched.h&amp;gt;int sched_get_priority_min (int policy);int sched_get_priority_max (int policy); 각각 유효한 우선순위 값의 최소값과 최대값을 리턴함. policy 스케줄링 정책을 넣어줌 예시 int min, max;min = sched_get_priority_min (SCHED_RR);if (min == −1) { perror (&quot;sched_get_priority_min&quot;); return 1;}max = sched_get_priority_max (SCHED_RR);if (max == −1) { perror (&quot;sched_get_priority_max&quot;); return 1;}printf (&quot;SCHED_RR priority range is %d - %d\\n&quot;, min, max); 6.6.6 sched_rr_get_interval() SCHED_RR은 time slice를 사용한다는 것을 제외하고 SCHED_FIFO와 동일하게 작동한다. 만약 SCHED_RR 프로세스가 타임슬라이스를 다 썼다면, 스케줄러는 현재 우선순위의 동작 리스트 중 가장 마지막으로 간다. 이런 방법에서는 같은 우선순위의 모든 SCHED_RR 프로세스들은 Rount robin 으로 순회한다. 높은 우선순위의 프로세스들 (SCHED_FIFO of the same or higher priority) 은 SCHED_RR 프로세스의 타임슬라이스가 더 남았건 상관안하고 점유한다. POSIX 는 주어진 프로세스의 timeslice의 길이를 얻을 수 있는 인터페이스를 제공한다.#include &amp;lt;sched.h&amp;gt;struct timespec { time_t tv_sec; /* seconds */ long tv_nsec; /* nanoseconds */};int sched_rr_get_interval (pid_t pid, struct timespec *tp); 호출이 성공하면 timespec 구조의 tp에다가 pid에 할당된 타임슬라이스의 길이를 저장한다. POSIX에 따르면 이 함수는 SCHED_RR에만 사용할 수 있지만, 리눅스에서는 어떤 프로세스든 적용할 수 있다. 예시 struct timespec tp;int ret;/* get the current task&#39;s timeslice length */ret = sched_rr_get_interval (0, &amp;amp;tp);if (ret == −1) { perror (&quot;sched_rr_get_interval&quot;); return 1;}/* convert the seconds and nanoseconds to milliseconds */printf (&quot;Our time quantum is %.2lf milliseconds\\n&quot;, (tp.tv_sec * 1000.0f) + (tp.tv_nsec / 1000000.0f)); 만약 프로세스가 FIFO 로 돌고있다면 tv_sec과 tv_nsec는 둘 다 0이다. 6.6.7 Real-time 프로세스의 주의점6.6.8 Determinism (결정론) RT 프로세스는 결정론에 크게 좌지우지 한다. RT 컴퓨팅에서 행동은 결정론적인데, 만약 같은 인풋을 받았을 때 항상 같은 양의 시간에 같은 결과를 만들어야하기 때문. 최신 컴퓨터는 결정론적이지 않은데, 여러 계층에 걸친 캐시와 여러 개의 프로세스, 페이징, 스와핑, 그리고 멀티태스킹은 명령이 얼마나 걸릴지 예측할 수 없음 실시간 애플리케이션은 예측할 수 없는 부분과 최악의 지연을 제한하려고 시도한다.선행 폴트 데이터와 메모리 락 종종 선행 폴트를 일으켜 스왑된 데이터를 메모리에 올린 다음, 주소 공간 내 모든 페이지를 실제 물리 메모리에 ‘락을 걸거나’, ‘고정 배선’한다. 메모리 락을 걸고 나면 커널은 절대로 이 페이지를 디스크로 스왑하지 않는다.CPU 친화도와 실시간 프로세스 각 실시간 프로세스를 위해 프로세서 하나를 예약해두고 나머지 프로세스는 남은 프로세서상에서 시분할 방식으로 동작하게 한다. 구현 방법: init 프로그램을 수정 - CPU_CLR (1, &amp;amp;set): CPU #1을 금지한다. 실행 가능한 프로세서 집합은 부모 프로세스로부터 상속받게 된다. 실시간 프로세스가 CPU #1에서만 실행되도록 affinity를 준다. - CPU_SET (1, %set) " }, { "title": "[Linux System Programming] Ch05 프로세스 관리 ", "url": "/posts/linux_ch05/", "categories": "Linux", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-03-24 00:00:00 +0900", "snippet": "[Ch05 프로세스 관리] 유닉스는 새로운 바이너리 이미지를 메모리에 적재하는 과정에서 새로운 프로세스를 생성하는 부분을 분리했다.5.1 프로그램, 프로세스, 스레드 바이너리는 디스크 같은 저장 장치에 기록되어 있는 컴파일된 실행할 수 있는 코드를 말한다. 흔히 프로그램을 지칭하기도 함. 때로는 애플리케이션을 뜻하기도 함. /bin/ls, /usr/bin/X11 모두 바이너리 프로세스는 실행 중인 프로그램을 뜻함. 프로세스는 메모리에 적재된 바이너리 이미지와 가상화된 메모리의 인스턴스, 열린 파일 같은 커널 리소스, 관련된 사용자 정보와 같은 보안 정보와 하나 이상의 스레드를 포함하고 있다. 스레드는 프로세스 내 실행 단위. 각각의 스레드는 가상화된 프로세서를 가지고 있음 프로세서에는 스택, 레지스터, 명령어 포인터 같은 프로세서의 상태가 포함되어 있다. Q) 리눅스에서 스레드를 어떻게 구현했을까? (프로세스와 거의 유사하다고함…) 스레드든 프로세스든 다 Task로 구분하고 스케줄링함. 또? 구조는? 싱글 스레드 프로세스는 프로세스가 곧 스레드가 된다. 5.2 프로세스 ID 모든 프로세스는 프로세스 ID(pid)라고 하는 유일한 식별자로 구분됨. pid는 특정 시점에서 유일한 값임을 보장한다. 커널이 같은 프로세스 식별자를 다른 프로세스에 다시 할당하지 않으리라 가정한다. 동작 중인 다른 프로세스가 없을 때 커널이 실행하는 idle 프로세스는 Pid가 0이다. 부팅이 끝나면 커널이 실행하는 최초 프로세스인 init 의 pid는 1이다. 리눅스 커널이 적절한 init 프로세스를 찾으면서 실행할 프로세스를 결정하는 순서 /sbin/init /etc/init /bin/init /bin/sh 이 순서에서 가장 먼저 찾은 프로세스를 실행함. 네 가지 모두 실패하면 panic 발생 복구할 수 없는 치명적인 내부 에러를 감지 5.2.1 프로세스 ID 할당 보통 커널의 최대 pid 값은 32768이다. pid값으로 signed 16bit integer를 사용했던 오래된 유닉스 시스템과의 호환성을 위함. 커널은 pid를 순서대로 엄격하게 할당한다. /proc/sys/kernel/pid_max 값에 도달해서 처음부터 다시 할당하기 전까진 앞선 pid가 비어있더라도 재사용되지 않는다. 5.2.2 프로세스 계층 Spawn(새로운 프로세스를 생성하는) 프로세서를 부모 프로세스라고 한다. 새롭게 생성된 프로세스를 자식 프로세스라고 한다. init 프로세스를 제외한 모든 프로세스는 다른 프로세스로부터 생성된다. → 그래서 모든 자식 프로세스에는 부모 프로세스가 있다. ppid 로 확인가능함. 모든 프로세스는 사용자와 그룹이 소유하고 있다. 모든 자식 프로세스는 부모 프로세스의 사용자와 그룹 권한을 상속받는다. 접근 권한을 제어하기 위해 사용됨. 프로세스 그룹 프로세스와 다른 프로세시의 관계를 표현하고 있음. $ echo $$19610$ cat | grep | wc -l////////// other shell /////////$ ps -A -o pid,ppid,pgid,sid,command PID PPID PGID SID COMMAND19610 18942 19610 19610 /usr/bin/zsh29844 19610 29844 19610 cat29845 19610 29844 19610 grep --color=auto --exclude-dir=.bzr --exclude-dir=CVS --exclude-dir=.git --exclude-dir=.hg --exclude-dir=.svn --exclude-d29846 19610 29844 19610 wc -l5.2.3 pid_t pid 는 pid_t 자료형으로 표현됨 C의 int 자료형에 대한 typedef이다. typedef __kernel_pid_t __pid_t;#ifndef __kernel_pid_t typedef int __kernel_pid_t;#endif pid_t 자료형은 사실 int 형이다. 5.2.4 프로세스 ID와 부모 프로세스 ID 얻기 getpid() 시스템 콜은 호출한 프로세스의 pid를 반환함.#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;pid_t getpid (void); getppid() 는 호출한 프로세스의 부모 프로세스 pid를 반환함#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;pid_t getppid (void); 예제 printf (&quot;My pid=%jd\\n&quot;, (intmax_t) getpid ());printf (&quot;Parent&#39;s pid=%jd\\n&quot;, (intmax_t) getppid ()); 5.3 새로운 프로세스 실행하기 유닉스에서는 프로그램 이미지를 메모리에 적재하고 실행하는 과정 새로운 프로세스를 생성하는 과정 두 가지가 분리되어 있음. 5.3.1 exec 함수들 exec 류 시스템 콜은 한 가지로 제공되지 않고 여러 형태로 제공된다. 먼저 excel을 알아보자 #include &amp;lt;unistd.h&amp;gt;int execl (const char *path, const char *arg, ...); 호출하면 현재 프로세스를 path가 가리키는 프로그램으로 대체한다. arg path에 명시된 프로그램을 위한 첫 번째 인자다. ... 가변인자 뒤에 다른 인자가 여럿 올 수 있음 마지막은 반드시 NULL로 끝나야함. 예제 int ret;ret = execl (&quot;/bin/vi&quot;, &quot;vi&quot;, NULL);if (ret == −1) perror (&quot;execl&quot;); 실행 파일의 경로인 path의 마지막 요소 vi 를 첫 번째 인자로 두어, 프로세스의 fork()/exec 과정에서 argv[0]을 검사하여 바이너리 이미지의 이름을 찾을 수 있도록 한다. 일반적으로 반환값이 없다. 에러 발생시 -1 반환, errno 설정 성공 시 새로운 프로그램의 시작점으로 건너 뛰므로 이전에 실행했던 코드는 그 프로세스의 주소 공간에 더 이상 존재하지 않음. 대기 중인 시그널 사라짐 프로세스가 받은 시그널은 시그널 핸들러가 더 이상 프로세스의 주소 공간에 존재하지 않으므로 디폴트 방식으로 처리됨 메모리 락이 해제됨 스레드의 속성 대부분이 기본값으로 돌아감 프로세스의 통계 대부분이 재설정됨 맵핑된 파일을 포함하여 프로세스의 메모리 주소 공간과 관련된 모든 내용이 사라짐 사용자 영역에만 존재하는 모든 내용이 사라짐. Q) 마지막에 NULL을 넣는 이유는 뭘까? 즉, fork 로 child 프로세스를 만든 후 그 프로세스를 새로운 독립적인 프로세스로 만들어 주는 역할을 한다.다른 exec 함수들#include &amp;lt;unistd.h&amp;gt;int execlp (const char *file, const char *arg, ...);int execle (const char *path, const char *arg, ..., char * const envp[]);int execv (const char *path, char *const argv[]);int execvp (const char *file, char *const argv[]);int execve (const char *filename, char *const argv[], char *const envp[]); exec 라는 기본 이름 뒤에 함수의 특징을 나타내는 알파벳이 뒤따름. l 포함하는 함수 : 인자를 리스트로 전달함. v 포함하는 함수 : 인자를 배열로 전달함. e 포함하는 함수 : 새로 생성되는 함수의 환경변수를 지정함 p 포함하는 함수 : 실행파일을 사용자의 환경변수에서 찾도록함 exec 함수군 중에서 execve() 만 시스템 콜이고 다른 것들은 래퍼 함수임. 인자로 배열을 사용하면 인자를 실행 시간에 결정할 수 있다는 장점이 있음 Q) 바로 위의 문장 무슨 뜻? Q)tip 으로 나온 execlp()와 execvp() 함수의 보안위험 무슨말?? 205페이지5.3.2 fork() 시스템 콜 fork 시스템 콜을 사용해서 현재 실행 중인 프로세스와 동일한 프로세스를 새롭게 실행할 수 있다.#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;pid_t fork (void); fork() 호출이 성공하면 fork() 를 실행한 프로세스와 거의 모든 내용이 동일한 새로운 프로세스를 생성함. 두 프로세스는 계속 실행 상태 성공 시 부모 프로세스에서는 fork() 시스템 콜의 반환값은 자식 프로세스의 pid가 됨. 필수적인 항목을 제외하고는 거의 모든 측면에서 자식,부모가 동일 자식의 pid는 새롭게 할당됨 자식의 ppid는 부모의 pid 자식 프로세스에서 리소스 통계는 0으로 초기화됨 처리되지 않은 시그널은 모두 사라지고 자식 프로세스로 상속되지 않음. 부모가 가지고 있던 파일 락은 상속되지 않음 호출 실패 시 -1반환, errno 설정 예제 pid_t pid;pid = fork ();if (pid &amp;gt; 0) printf (&quot;I am the parent of pid=%d!\\n&quot;, pid);else if (!pid) printf (&quot;I am the child!\\n&quot;);else if (pid == −1) perror (&quot;fork&quot;) 가장 흔한 예제는 새로운 프로세스를 생성하고 그 후에 새 프로세스에 새로운 바이너리 이미지를 올리는 것임. 즉 ,fork() 하고 자식 프로세스는 exec 를 진행함 예제 pid_t pid;pid = fork ();if (pid == −1) perror (&quot;fork&quot;);/* the child ... */if (!pid) { const char *args[] = { &quot;windlass&quot;, NULL }; int ret; ret = execv (&quot;/bin/windlass&quot;, args); if (ret == −1) { perror (&quot;execv&quot;); exit (EXIT_FAILURE); }} 부모 프로세스는 자식 프로세스가 생겼다는 사실 외에는 아무런 변화 없이 진행됨 copy-on-write 기존에는 fork() 수행 시 페이지 단위로 복사했음 최신 유닉스 시스템은 주소 공간 모두 복사하는 것이 아니라 페이지에 대한 COW를 수행함. COW 복사에 의한 부하를 완화하기 위한 최적화기법. 자신이 가지고 있는 리소스의 읽기 요청이 들어오더라도 포인터만 넘겨받으면 된다는 전제에서 시작함. 쓰기 작업을 할 경우에만 복사가 일어남. vfork() 쓸모없는 주소 공간 복사 문제를 해결하기 위한 옛날 노력 fork()와 같은 동작을 하지만 자식 프로세스는 즉시 exec 계열의 함수를 성공적으로 호출하든가, _exit() 함수를 호출해서 프로세스를 끝내야함 vfork() 구현은 버그를 수반함 exec 호출이 실패할 경우는? 자식 프로세스가 어떻게 처리해야할지 파악하거나 종료하기 전까지는 계속 멈춰있음. Q) 요부분 다시 이해하기 5.4 프로세스 종료하기#include &amp;lt;stdlib.h&amp;gt;void exit (int status); exit()을 호출하면 몇 가지 기본적인 종료 단계를 거쳐 커널이 프로세스를 종료함. 반환값이 없기 때문에 exit 호출 이후 명령은 의미가 없음 종료 순서 atexit()이나 on_exit()에 등록된 함수가 있다면 등록 수선의 역순으로 호출 열려있는 모든 표준 입출력 스트림의 버퍼를 비운다. tmpfile() 함수를 통해 생성한 임시 파일을 삭제 프로세스가 사용자 영역에서 해야하는 모든 작업을 종료시킴. 마지막으로 exit()은 _exit() 시스템 콜을 실행해서 나머지 단계를 커널이 처리하게 한다. 프로세스가 종료되면 커널은 해당 프로세스가 생성한 더 사용되지 않는 모든 리소스를 정리한다. _exit()을 직접 사용하면 표준 출력 스트림을 비우는 등의 사후 처리를 직접 해야한다. vfork()를 사용하면 _exit() 을 사용해야함. 5.4.1 프로세스를 종료하는 다른 방법 고전적인 방법은 시스템 콜을 사용하지 않고, 단순히 프로그램을 끝까지 진행시키는 것임 main() 함수가 반환되는 경우 하지만 이런 경우도 컴파일러가 프로그램 종료 코드 이후에 exit() 시스템 콜을 묵시적으로 추가한다. SIGTERM 과 SIGKILL 을 보내서 종료도 가능 커널에 밉보이는 방법 잘못된 연산 수행 세그멘테이션 폴트 일으킴 메모리 고갈 리소스 과다 소모 → 프로세스를 강제로 죽임 5.4.2 atexit() atexit() 함수는 프로세스가 종료될 때 실행할 함수를 등록하기 위한 용도로 사용됨.#include &amp;lt;stdlib.h&amp;gt;int atexit (void (*function)(void)); 정상적으로 실행되면 프로세스가 정상적으로 종료될 때 호출할 함수를 등록함. 등록할 함수는 아무런 인자도 갖지 않고 어떠한 값도 반환하지 않는 함수여야함. 이 함수들을 스택에 저장되며 LIFO 방식으로 실행됨. 등록된 함수에서 exit()을 호출한다면 무한 루프에 빠진다. _exit() 을 사용하자 예제 #include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;void out (void){ printf (&quot;atexit() succeeded!\\n&quot;);}int main (void){ if (atexit (out)) fprintf(stderr, &quot;atexit() failed!\\n&quot;); return 0;} 5.4.3 on_exit() SunOS4 는 atexit()와 동일한 자신만의 함수를 정의하고 있으며, 리눅스의 glibc에서도 지원한다.#include &amp;lt;stdlib.h&amp;gt;int on_exit (void (*function)(int, void *), void *arg); atexit()와 동일하게 동작하지만 등록할 수 있는 함수의 프로토 타입이 다름.void my_function (int status, void *arg);5.4.4 SIGCHLD 프로세스가 종료될 때 커널은 SIGCHLD 시그널을 부모 프로세스로 보낸다. 기본적으로 부모 프로세스는 이 시그널을 무시하며 아무런 행동도 하지 않음. 하지만 프로세스는 signal() 이나 sigaction() 시스템 콜을 사용해서 처리한다. 부모 프로세스 관점에서는 자식 프로세스의 종료가 비동기로 일어남5.5. 자식 프로세스 종료 기다리기 시그널을 통해 알림을 받는 방법도 훌륭하지만, 많은 부모 프로세스는 자식 프로세스 중 하나가 종료될 때 좀 더 많은 정보를 얻고자 함. 자식 프로세스가 완전히 사라져버리면 정보를 얻을 수 없어서, 유닉스 초기 설계자들은 자식 프로세스가 부모 프로세스보다 먼저 죽으면 자식 프로세스를 좀비 프로세스로 바꾸기로 함. 아주 최소한의 기본적인 커널 자료구조만 가지고 있음. 좀비프로세스는 부모 프로세스가 자신의 상태를 조사하도록 기다림. 부모 프로세스가 종료된 자식 프로세스로부터 정보를 회수한 다음에야 공식적으로 종료됨. 리눅스 커널은 종료된 자식 프로세스에 대한 정보를 얻기 위해 몇 가지 인터페이스를 제공함 wait()#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;sys/wait.h&amp;gt;pid_t wait (int *status); wait()을 호출하면 종료된 프로세스의 pid를 반환하며 에러가 발생한 경우 -1을 반환. 만약 자식 프로세스가 종료되지 않았다면 자식 프로세스가 종료될 때까지 블록됨. (대기 상태) 이미 종료된 상태라면 호출은 즉시 반환됨. 예제 #include &amp;lt;unistd.h&amp;gt;#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;sys/wait.h&amp;gt;int main (void){ int status; pid_t pid; if (!fork ()) return 1; pid = wait (&amp;amp;status); if (pid == −1) perror (&quot;wait&quot;); printf (&quot;pid=%d\\n&quot;, pid); if (WIFEXITED (status)) printf (&quot;Normal termination with exit status=%d\\n&quot;, WEXITSTATUS (status)); if (WIFSIGNALED (status)) printf (&quot;Killed by signal=%d%s\\n&quot;, WTERMSIG (status), WCOREDUMP (status) ? &quot; (dumped core)&quot; : &quot;&quot;); if (WIFSTOPPED (status)) printf (&quot;Stopped by signal=%d\\n&quot;, WSTOPSIG (status)); if (WIFCONTINUED (status)) printf (&quot;Continued\\n&quot;); return 0;} 이 프로그램은 즉시 종료되는 자식 프로세스를 생성한다. 부모 프로세스는 wait() 시스템 콜을 호출해서 자식 프로세스의 상태를 확인한다. 자식 프로세스의 pid와 어떻게 종료되었는지를 출력함. 5.5.1 특정 프로세스 기다리기 자식프로세스의 행동을 관찰하는 것은 중요한데, 모든 자식프로세스의 상황을 확인하는 것은 번거롭다. 기다리길 원하는 프로세스의 pid를 알고있다면 waitpid() 시스템 콜을 사용할 수 있다.#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;sys/wait.h&amp;gt;pid_t waitpid (pid_t pid, int *status, int options); watipid() 는 wait() 보다 훨씬 강력한 버전이다. pid &amp;lt; -1 프로세스 gid가 이 값의 절댓값과 동일한 모든 자식 프로세스를 기다림. -1 모든 자식 프로세스를 기다린다. 이렇게 하면 wait()와 동일하게 동작함 0 호출한 프로세스와 동일한 프로세스 그룹에 속한 모든 자식 프로세스를 기다림 0 인자로 받은 pid와 일치하는 자식 프로세스를 기다린다. status wait() 의 status와 동일하게 동작 options WNOHANG 이미 종료된 자식 프로세스가 없다면 블록되지 않고 바로 반환 WUNTRACED 호출하는 프로세스가 자식 프로세스를 추적하지 않더라도 반환되는 status 인자에 WIFSTOPPED비트가 설정됨 WCONTINUED waitpid() 는 상태가 바뀐 프로세스의 pid를 반환함. WNOHANG 이 설정되고 지정한 자식 프로세스의 상태가 아직 바뀌지 않았다면 0을 반환 에러 발생시 -1 반환, errno 설정 예제 pid가 1742인 특정 자식 프로세스의 반환값을 알려고 하며 자식 프로세스가 아직 종료되지 않았다면 즉시 반환 하는 예제 int status;pid_t pid;pid = waitpid (1742, &amp;amp;status, WNOHANG);if (pid == −1) perror (&quot;waitpid&quot;);else { printf (&quot;pid=%d\\n&quot;, pid); if (WIFEXITED (status)) printf (&quot;Normal termination with exit status=%d\\n&quot;, WEXITSTATUS (status)); if (WIFSIGNALED (status)) printf (&quot;Killed by signal=%d%s\\n&quot;, WTERMSIG (status), WCOREDUMP (status) ? &quot; (dumped core)&quot; : &quot;&quot;);} 사용법 wait (&amp;amp;status);둘은 동일waitpid (−1, &amp;amp;status, 0); 5.5.2 좀 더 다양한 방법으로 기다리기 waitid()#include &amp;lt;sys/wait.h&amp;gt;int waitid (idtype_t idtype, id_t id, siginfo_t *infop, int options); wait() 이나 waitpid()와 마찬가지로 waitid()는 자식 프로세스를 기다리고 상태변화 (종료, 멈춤, 다시 실행) 을 얻기 위해 사용함. 더 많은 옵션을 제공하는 대신 훨씬 복잡함. pid인자 하나로 기다리는 것이 아니라, idtype 과 id 인자로 기다릴 자식 프로세스를 지정함. idtype P_PID pid가 id와 일치하는 자식 프로세스를 기다림 P_GID gid가 id와 일치하는 자식 프로세스를 기다림 P_ALL 모든 자식 프로세스를 기다림. id는 무시됨 id_t 타입은 거의 보기 힘든 타임. 일반적인 식별 번호를 나타내는 타입이다. 나중에 새로운 idtype 값이 추가되었을 경우를 대비하여 미리 정의된 타입이 나중에 새롭게 생성된 식별자를 저장할 수 있도록 충분한 여유를 제공하기 위해서임. options WEXITED WSTOPPED WCONTINUED WNOHANG WNOWAIT 성공적으로 반환하면 유효한 siginfo_t 타입을 가리키는 infop 인자에 값을 채운다. siginfo_t 타입 si_pid si_uid si_code 자식프로세스의 종료상태를 나타냄 si_signo si_status 성공하면 0반환, 에러 발생 시 -1 반환하고 errno 설정 waitid() 는 siginfo_t 구조체를 통해 다양한 정보를 얻을 수 있다. 근데 만약 이런 정보가 필요하지 않다면 단순 함수를 사용하는게 시스템 이식성을 위해서 더 바람직하다.5.5.3 BSD 방식으로 기다리기 : wait3()과 wait4() BSD는 자식 프로세스의 상태 변화를 기다리기 위한 두 가지 독자적인 함수를 제공함. Berkeley Software Distribution #include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;sys/time.h&amp;gt;#include &amp;lt;sys/resource.h&amp;gt;#include &amp;lt;sys/wait.h&amp;gt;pid_t wait3 (int *status, int options, struct rusage *rusage);pid_t wait4 (pid_t pid, int *status, int options, struct rusage *rusage);pid_t wait3(int* status, int options, struct rusage* rusage) { return wait4(-1, status, options, rusage);} 함수 뒤에 붙은 숫자는 인자의 개수를 뜻한다. rusage 인자만 예외로 하면 두 함수는 waitpid와 흡사하다. 예제 wait3() pid = wait3 (status, options, NULL);동일pid = waitpid (−1, status, options); wait4() pid = wait4 (pid, status, options, NULL);동일pid = waitpid (pid, status, options); wait3()는 모든 자식 프로세스의 상태 변화를 기다리며, wait4()는 pid인자로 지정한 특정 자식 프로세스의 상태 변화만 기다린다. options 인자는 waitpid와 동일 rusage (Resource Usage) waitpid와 가장 큰 차이점인데, rusage 포인터가 NULL이 아니면 자식 프로세스에 관한 정보를 채워넣는다. #include &amp;lt;sys/resource.h&amp;gt;struct rusage { struct timeval ru_utime; /* user time consumed */ struct timeval ru_stime; /* system time consumed */ long ru_maxrss; /* maximum resident set size */ long ru_ixrss; /* shared memory size */ long ru_idrss; /* unshared data size */ long ru_isrss; /* unshared stack size */ long ru_minflt; /* page reclaims */ long ru_majflt; /* page faults */ long ru_nswap; /* swap operations */ long ru_inblock; /* block input operations */ long ru_oublock; /* block output operations */ long ru_msgsnd; /* messages sent */ long ru_msgrcv; /* messages received */ long ru_nsignals; /* signals received */ long ru_nvcsw; /* voluntary context switches */ long ru_nivcsw; /* involuntary context switches */}; 성공할 경우 상태가 변경된 프로세스의 pid를 반환함. 실패 시 -1반환하고 errno 설정 wait3 와 wait4 는 POSIX가 정의한 함수는 아니므로 리소스 사용정보가 매우 중요한 경우에만 사용하자.5.5.4 새로운 프로세스를 띄운 다음에 기다리기 ANSI C와 POSIX는 새로운 프로세스를 생성하고 종료를 기다리는 동작을 하나로 묶은, 말하자면 동기식 프로세스 생성 인터페이스를 정의하고 있음.#define _XOPEN_SOURCE /* if we want WEXITSTATUS, etc. */#include &amp;lt;stdlib.h&amp;gt;int system (const char *command); 함수이름이 system인 이유는 동기식 프로세스 생성이 시스템 외부로 셸 띄우기라고 불리기 때문임. 흔히 간단한 유틸리티나 셸 스크립트를 실행할 목적으로 system() 을 사용하는데 종종 실행 결과의 반환값을 얻기 위한 명시적인 목적으로 사용하기도 한다. command 주어진 명령을 실행한다. /bin/sh -c 뒤에 command가 따라 붙음 즉, 셸에 그대로 전달되는 것 NULL 이면 /bin/sh가 유효하면 0이 아닌 값, 그렇지 않다면 0 반환 호출이 성공하면 wait()와 마찬가지로 그 명령의 상태를 반환함. 실행한 명령의 종료 코드는 WEXITSTATUS 로 얻을 수 있다. 명령어 수행에 실패했다면 exit(127)과 동일 command 를 실행하는 동안 SIGCHLD 는 블록되고 SIGINT와 SIGQUIT는 무시된다. 몇 가지 주의점 system()이 반복문안에서 실행될 때 문제가 발생함. 프로그램이 자식 프로세스의 종료 상태를 적절하게 검사할 수 있도록 해야한다. 예제 do { int ret; ret = system (&quot;pidof rudderd&quot;); if (WIFSIGNALED (ret) &amp;amp;&amp;amp; (WTERMSIG (ret) == SIGINT || WTERMSIG (ret) == SIGQUIT)) break; /* or otherwise handle */} while (1); fork(), exec 함수군, waitpid()를 사용해서 system() 구현하기 /* * my_system - synchronously spawns and waits for the command * &quot;/bin/sh -c &amp;lt;cmd&amp;gt;&quot;. * * Returns −1 on error of any sort, or the exit code from the * launched process. Does not block or ignore any signals. */int my_system (const char *cmd){ int status; pid_t pid; pid = fork (); if (pid == −1) return −1; else if (pid == 0) { const char *argv[4]; argv[0] = &quot;sh&quot;; argv[1] = &quot;-c&quot;; argv[2] = cmd; argv[3] = NULL; execv (&quot;/bin/sh&quot;, argv); exit (−1); } if (waitpid (pid, &amp;amp;status, 0) == −1) return −1; else if (WIFEXITED (status)) return WEXITSTATUS (status); return −1;} System 의 문제 child의 stdout 등 의 값을 볼 수가 없음. popen을 쓴다? 5.5.5 좀비 프로세스 실행을 마쳤지만 부모 프로세스에서 종료 코드를 읽어가지 않은, 즉 부모 프로세스에서 wait() 시스템 콜을 호출하지 않은 프로세스를 의미 최소한의 기본 뼈대만 유지할만큼 적은 리소스를 차지하지만 어쨌든 시스템 리소스를 계속 소비하고 있음. 부모 프로세스가 종료될 때마다 리눅스 커널은 그 프로세스의 자식 프로세스 목록을 뒤져서 모두 init 프로세스 (pid = 1) 의 자식으로 입양시킨다. 고아 프로세스가 생기지 않도록 보장함. 5.6 사용자와 그룹5.6.1 실제, 유효, 저장된 사용자 ID와 그룹 ID 그룹아이디도 아래와 동일하게 적용됨 실제 사용자 ID (Rreal User ID) 프로세스를 최초로 실행한 사용자의 ID 유효 사용자 ID (Effective User ID) 프로세스가 현재 영향을 미치고 있는 사용자 ID 저장된 사용자 ID (Saved User ID) 프로세스의 최초 유효 사용자 ID → 유효한 사용자 ID가 가장 중요한 값. 이는 프로세스의 자격을 확인하는 과정에서 점검하는 사용자 ID이다5.6.2 실제, 저장된 사용자, 그룹 ID 변경하기#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;int setuid (uid_t uid);int setgid (gid_t gid); setuid() 호출하면 현재 프로세스의 유효 사용자 ID를 설정한다. 현재 유효 사용자 ID가 0(root) 이면 실제 사용자와 저장된 사용자 ID 역시 설정됨 성공하면 0반환, 실패 시 -1 반환 errno 설정 앞의 내용은 그룹 ID에도 동일하다.5.6.3 유효 사용자 ID나 유효 그룹 ID 변경하기#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;int seteuid (uid_t euid);int setegid (gid_t egid); seteuid() 를 호출하면 유효 사용자 ID 를 euid로 설정한다. root 사용자는 euid 값으로 어떤 값이든 사용할 수 있다. 비 root 사용자는 seteuid() 와 setuid() 가 동일하게 동작함. 앞의 내용은 그룹 ID에도 동일하다.5.6.4 BSD 방식으로 사용자, 그룹 ID 변경하기#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;int setreuid (uid_t ruid, uid_t euid);int setregid (gid_t rgid, gid_t egid); setreuid() 를 호출하면 프로세스의 실제 사용자 ID와 유효 사용자 ID를 각각 ruid와 euid로 설정한다.5.6.5 HP-UX 방식으로 사용자, 그룹 ID 변경하기#define _GNU_SOURCE#include &amp;lt;unistd.h&amp;gt;int setresuid (uid_t ruid, uid_t euid, uid_t suid);int setresgid (gid_t rgid, gid_t egid, gid_t sgid); setresuid() 를 호출하면 실제, 유효, 그리고 저장된 사용자 ID를 각각 ruid, euid, suid로 설정한다. -1 을 지정하면 ID는 변경하지 않은채로 놔둔다. 5.6.6 바람직한 사용자/그룹 ID 조작법 비 root 프로세스는 seteuid() 를 사용해서 유효 사용자 ID를 바꿔야한다.5.6.7 저장된 사용자 ID 지원5.6.8 사용자 ID와 그룹 ID 얻어오기#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;sys/types.h&amp;gt;uid_t getuid (void);gid_t getgid (void);#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;sys/types.h&amp;gt;uid_t geteuid (void);gid_t getegid (void); 이 함수들은 실패하지 않으며 유효 사용자 ID와 유효 그룹 ID를 반환함.5.7 세션과 프로세스 그룹 각 프로세스는 작업 제어 목적으로 관련된 하나 이상의 프로세스를 모아놓은 집합인 프로세스 그룹의 일원이다. 프로세스 그룹의 주된 속성은 그룹 내 모든 프로세스에게 시그널을 보낼 수 있다는 점이다. 각 프로세스 그룹은 pgid 로 구분하며 프로세스 그룹마다 그룹 리더가 있다. 구성원이 하나라도 남아있는 동안에는 그룹이 사라지지 않음 그룹 리더가 종료되더라도 프로세스 그룹은 남는다. 새로운 사용자가 처음으로 시스템에 로그인하면 로그인 프로세스는 사용자 로그인 셸 프로세스 하나로 이루어진 새로운 세션을 생성한다. 세션은 하나 이상의 프로세스 그룹이 들어 있는 집합이다. 로그인한 사용자 활동을 처리하며 사용자의 터미널 입출력을 다루는 tty 장치로 명시되어 제어 터미널과 사용자 사이를 연결한다. 대부분 셸과 관련을 맺고 있다. 프로세스 그룹이 작업 제어와 다른 셸 기능을 쉽게 하도록 모든 구성원에게 시그널을 보내는 메커니즘을 제공한다면 세션은 제어 터미널을 둘러싼 로그인을 통합하는 기능을 제공한다. 세션에 속한 프로세스 그룹은 하나의 Foreground 프로세스 그룹과 0개 이상의 Background 프로세스 그룹으로 나뉜다. 사용자가 터미널을 종료하면 Foreground 프로세스 그룹 내 모든 프로세스에 SIGQUIT 시그널이 전달됨 터미널에서 네트워크 단절이 포착되면 Foreground 프로세스 그룹 내 모든 프로세스에 SIGHUP 시그널이 전달됨. 사용자가 Ctrl + C 같은 취소 명령을 입력했을 경우 Foreground 프로세스 그룹 내 모든 프로세스에 SIGINT 시그널이 전달됨. 예제 사용자가 시스템에 로그인했고, bash의 pid가 1700일 때 bash 인스턴스는 gid가 1700인 새로운 프로세스 그룹의 유일한 멤버이자 리더가 됨. 그 셸에서 실행하는 명령어는 세션 1700에 속하는 새로운 프로세스 그룹에서 동작. 사용자에게 직접 연결되어 있고 터미널 제어가 가능한 프로세스 그룹 중 하나가 포어그라운드 프로세스 그룹 다른 프로세스 그룹은 백그라운드 프로세스 그룹 다른 예제 $ cat ship-inventory.txt | grep booty | sort 세 개의 프로세스를 가지는 하나의 프로세스 그룹은 생성함. → 셸에서 한번에 세 프로세스 모두에 시그널을 보낼 수 있다는 뜻. 사용자가 명령어 뒤에 &amp;amp;를 붙인다면 백그라운드로 돈다. 5.7.1 세션 시스템 콜 시스템에 로그인을 하는 시점에 셸은 새로운 세션을 생성한다. 이 작업은 새로운 세션을 쉽게 만들 수 있는 특수한 시스템 콜을 통해서 이루어진다.#include &amp;lt;unistd.h&amp;gt;pid_t setsid (void); setsid() 를 호출하면 그 프로세스가 프로세스 그룹의 리더가 아니라고 가정하고 새로운 세션을 생성한다. 호출한 프로세스는 새롭게 만들어진 세션의 유일한 멤버이자 리더가 되며 제어 tty를 가지지 않는다. → setsid() 는 새로운 세션 내부에 새로운 프로세스 그룹을 생성하며 호출한 프로세스를 그 세션과 프로세스 그룹 모두의 리더로 정한다. 호출 성공 시 새롭게 생성한 세션의 ID 반환, 실패 시 -1 반환하고 errno 설정.(EPERM 뿐) 예제 어떤 프로세스가 프로세스 그룹 리더가 되지 않게 하는 가장 손쉬운 방법은 프로세스를 포크하고 부모 프로세스를 종료한 다음 자식 프로세스에서 setsid() 를 호출하는 것 pid_t pid;pid = fork ();if (pid == −1) { perror (&quot;fork&quot;); return −1;} else if (pid != 0) exit (EXIT_SUCCESS);if (setsid () == −1) { perror (&quot;setsid&quot;); return −1;} 세션 ID를 얻는 법 #define _XOPEN_SOURCE 500#include &amp;lt;unistd.h&amp;gt;pid_t getsid (pid_t pid); getsid() 호출이 성공하면 pid가 가리키는 프로세스 세션 ID를 반환한다. Q) 왜 유용하지 않음? getsid() 는 드물지만 주로 진단 목적으로 사용함 pid값이 0 이면 getsid() 를 호출한 프로세스의 세션 ID를 반환한다. pid_t sid;sid = getsid (0);if (sid == −1) perror (&quot;getsid&quot;); /* should not be possible */else printf (&quot;My session id=%d\\n&quot;, sid); 5.7.2 프로세스 그룹 시스템 콜 setpgid() 는 pid 인자로 지정한 프로세스의 프로세스 그룹 ID를 pgid로 설정한다.#define _XOPEN_SOURCE 500#include &amp;lt;unistd.h&amp;gt;int setpgid (pid_t pid, pid_t pgid); pid인자가 0인 경우 현재 프로세스의 프로세스 그룹 ID를 변경하며 pgid 인자가 0인 경우 pid 인자로 지정한 프로세스의 ID를 프로세스 그룹 ID로 설정한다. 호출 성공 여부 pid로 지정한 프로세스가 해당 시스템 콜을 호출하는 프로세스이거나 호출하는 프로세스의 자식 프로세스이며 아직 exec 호출을 하지 않았고 부모 프로세스와 동일한 세션에 속해 있어야 한다. pid로 지정한 프로세스가 세션의 리더가 아니어야 한다. pgid가 이미 있으면 호출하는 프로세스와 동일한 세션에 속해 있어야 한다. pgid 값이 양수여야 한다. 세션과 마찬가지로 프로세스의 프로세스 그룹 ID를 얻는 것도 가능하지만 유용하지 않음. #define _XOPEN_SOURCE 500#include &amp;lt;unistd.h&amp;gt;pid_t getpgid (pid_t pid); Q) 왜 유용하지 않음?5.7.3 사용되지 않는 프로세스 그룹 관련 함수들 리눅스는 프로세스 그룹 ID를 가져오거나 설정하는 두 가지 오래된 BSD 인터페이스를 지원한다. 프로세스 그룹 ID를 설정할 때 사용 #include &amp;lt;unistd.h&amp;gt;int setpgrp (void); if (setpgrp () == −1) perror (&quot;setpgrp&quot;); 다음 setpgid() 코드와 동일함 if (setpgid (0,0) == −1) perror (&quot;setpgid&quot;); 둘 다 현재 프로세스를 현재 프로세스의 pid와 같은 프로세스 그룹으로 설정함. getpgrp() 함수는 프로세스의 그룹 ID를 알아내기 위해 사용함 #include &amp;lt;unistd.h&amp;gt;pid_t getpgrp (void); pid_t pgid = getpgrp (); getpgid() 코드와 동일 pid_t pgid = getpgid (0); 5.8 데몬 Daemon 은 백그라운드에서 수행되며 제어 터미널이 없는 프로세스이다. 일반적으로 부팅 시에 시작되며 root 혹은 다른 특수한 사용자 계정 (apache, postfix … ) 권한으로 실행되어 시스템 수준의 작업을 처리한다. 데몬의 두 가지 일반적인 요구사항 반드시 init 프로세스의 자식 프로세스여야 함. 터미널과 연결되어 있으면 안됨. 다음 과정을 통해 데몬이 될 수 있다. fork() 를 호출해서 데몬이 될 새로운 프로세스를 생성 부모 프로세스에서 exit() 을 호출해서 데몬 프로세스의 부모 프로세스를 종료한다. setsid()를 호출해서 데몬이 새로운 프로세스 그룹과 세션의 리더가 되도록 한다. chdir() 를 사용하여 작업 디렉터리를 루트 디렉터리로 변경한다. 모든 fd 를 닫는다. 0, 1, 2번 fd(각각 표준 입력,출력,에러) 를 열고 /dev/null 로 리다이렉트 한다. 예제 규칙에 따라 스스로 데몬이 되는 예제 코드 #include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;sys/stat.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;fcntl.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;linux/fs.h&amp;gt;int main (void){ pid_t pid; int i; /* create new process */ pid = fork (); if (pid == −1) return −1; else if (pid != 0) exit (EXIT_SUCCESS); /* create new session and process group */ if (setsid () == −1) return −1; /* set the working directory to the root directory */ if (chdir (&quot;/&quot;) == −1) return −1; /* close all open files--NR_OPEN is overkill, but works */ for (i = 0; i &amp;lt; NR_OPEN; i++) close (i); /* redirect fd&#39;s 0,1,2 to /dev/null */ open (&quot;/dev/null&quot;, O_RDWR); /* stdin */ dup (0); /* stdout */ dup (0); /* stderror */ /* do its daemon thing... */ return 0;} 대부분의 유닉스 시스템은 C 라이브러리에서 daemon() 함수를 제공하여 이 과정을 자동화하여 간단하게 쓸 수 있다. #include &amp;lt;unistd.h&amp;gt;int daemon (int nochdir, int noclose); nochdir 인자가 0이 아니면 현재 작업 디렉터리를 루트 디렉터리로 변경하지 않는다. noclose 인자가 0이 아니면 열려있는 모든 fd를 닫지 않는다. 일반적으로 두 인자를 0으로 넘긴다. " }, { "title": "[Linux System Programming] Ch04 고급 버퍼 입출력 ", "url": "/posts/linux_ch04/", "categories": "Linux", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-03-21 00:00:00 +0900", "snippet": "[Ch04 고급 버퍼 입출력]2장에서는 파일입출력의 근본일 뿐만 아니라, 리눅스에서 일어나는 모든 통신의 토대인 기본 입출력 시스템 콜을 배웠다.3장에서는 기본 입출력 시스템 콜에 사용자 영역 버퍼링이 필요한 때를 알아보고 해법으로 C언어의 표준 입출력 라이브러리에 대해 공부했다.4장에서는 리눅스의 고급 입출력 시스템 콜에 대해 알아본다.벡터 입출력 한번의 호출로 여러 버퍼에서 데이터를 읽거나 쓸 수 있도록 해줌. 다양한 자료구조를 단일 입출력 트랜젝션으로 다룰 때 유용하다.epoll poll()과 select() 시스템 콜을 개선한 시스템 콜이다. 싱글 스레드에서 수백 개의 FD를 poll해야 하는 경우에 유용하다.메모리맵 입출력 파일을 메모리에 맵핑해서 간단한 메모리 조작을 통해 파일 입출력을 수행함. 특정 패턴의 입출력에 유용하다.파일 활용법 조언 프로세스에서 파일을 사용하려**의도**를 커널에게 제공할수 있도록 하여, 입출력 성능을 향상시킴.비동기식 입출력 작업 완료를 기다리지 않는 입출력을 요청한다. 스레드를 사용하지 않고 동시에 입출력 부하가 많은 작업을 처리할 경우 유용함4.1 벡터 입출력 한번의 시스템 콜을 사용해서 여러개의 버퍼 벡터에 쓰거나, 여러 개의 버퍼 벡터로 읽어 들일 때 사용하는 입출력 메서드 2장의 표준 읽기와 쓰기는 선형 입출력이라고 함. 벡터 입출력의 장점 좀 더 자연스러운 코딩 패턴 - 미리 정의된 구조체의 여러 필드에 걸쳐서 데이터가 분리되어 있는 경우, 벡터 입출력을 사용하면 직관적인 방법으로 조작할 수 있음 효율 - 한번의 사용으로 여러번의 선형 입출력 연산을 대체할 수 있음 성능 - 시스템 콜 호출 횟수 ⬇️, 내부적으로 최적화된 구현을 제공 원자성 - 벡터 입출력 연산 중에 다른 프로세스가 끼어들 수 없음 4.1.1 readv() 와 writev() readv() 함수는 fd에서 데이터를 읽어서 count 개수만큼 iov 버퍼에 저장한다.ssize_t readv (int fd, const struct iovec *iov, int count); writev() 함수는 count 개수만큼 iov 버퍼에 있는 데이터를 fd에 기록함ssize_t writev(int fd, const struct iovec *iov, int count); readv()와 writev() 함수는 여러 개의 버퍼를 사용한다는 점에서 read(), write()와 구분됨 iovec 구조체는 세그먼트라고 하는 독립적으로 분리된 버퍼를 나타낸다.struct iovec{ void *iov_base; // 버퍼의 시작 포인터 size_t iov_len; // 버퍼 크기 (바이트)} 이런 세그먼트의 집합을 벡터라고 한다. 벡터의 각 세그먼트에는 데이터를 기록하거나 읽어올 메모리 공간의 주소와 크기가 저장되어 있다. 두 함수는 각 버퍼에 iov_len 바이트만큼 데이터를 채우거나 쓴 다음, 다음 버퍼로 넘어간다. 두 함수 모드 iov[0] 부터 시작해서 iov[1], 그리고 iov[count-1]까지 세그먼트 순서대로 동작한다.반환값 두 함수는 호출이 성공했을 때 읽거나 쓴 바이트 개수를 반환함 반환값은 반드시 count * iov_len 값과 같아야함. 에러 발생 시 -1을 반환, errno 를 설정 각각 read(), write() 시스템 콜에서 발생 가능한 모든 종류의 에러가 발생할 수 있음 추가로 두 가지 에러 상황을 정의하고 있음 반환값의 자료형이 ssize_t 이기 때문에, 만약 count * iov_len 값이 SSIZE_MAX보다 큰 경우에는 데이터가 전송되지 않고 -1을 반환하며 errno 는 EINVAL로 설정됨 POSIX에서는 count가 0보다 크고 IOV_MAX(리눅스에서는 현재 1024로 정의하고 있음) 와 같거나 작아야 한다고 명시하고 있는데, 만약 count가 0이라면 readv()와 writev()는 0을 반환한다. 만약 count 값이 IOV_MAX보다 크다면 데이터는 전송되지 않고 -1을 반환하며 errno는 EINVAL로 설정됨 최적 count 찾기 벡터 입출력 작업을 할 때 리눅스 커널에서는 각 세그먼트를 위해 내부 데이터 구조체를 반드시 할당하게 됨! 근데 이 할당은 count의 크기에 따라 동적으로 일어난다. 만약 count값이 크지 않다면 스택에 미리 만들어둔 작은 세그먼트 배열을 사용해서, 동적 할당이 일어나지 않도록한다. → 성능 개선! (아주 효율적으로 동작함) 그러니깐 벡터 입출력 연산을 사용할 때 세그먼트의 개수의 감이 오지 않는다면 8 이하로 시도~~예제 writev() 예제 3개의 벡터 세그먼트에 데이터를 쓰는 예제 각각 크기가 다른 문자열을 담고 있음 int main(){ struct iovec iov[3]; ssize_t nr; int fd, i; char *buf[] = { &quot;aaa&quot;, &quot;bbbb&quot;, &quot;cccccc&quot; }; fd = open(&quot;buccaneer.txt&quot;, O_WRONLY | OCREAT | O_TRUNC); if (fd == -1) // error return 1; // 세 iovec 구조체 값을 채운다 for (i = 0; i&amp;lt;3;i++){ iov[i].iov_base = buf[i]; iov[i].iov_len = strlen(buf[i]) + 1; } // 단 한번의 호출로 세 iovec 내용을 모두 쓴다 nr = writev (fd, iov, 3); if (nr == -1 ) //error return 1; printf(&quot;wrote %d bytes\\n&quot;, nr); if (close(fd)) //error return 1; return 0} readv()예제#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;sys/stat.h&amp;gt;#include &amp;lt;fcntl.h&amp;gt;#include &amp;lt;sys/uio.h&amp;gt;int main (){ char foo[48], bar[51], baz[49]; struct iovec iov[3]; ssize_t nr; int fd, i; fd = open (&quot;buccaneer.txt&quot;, O_RDONLY); if (fd == −1) { perror (&quot;open&quot;); return 1; } /* set up our iovec structures */ iov[0].iov_base = foo; iov[0].iov_len = sizeof (foo); iov[1].iov_base = bar; iov[1].iov_len = sizeof (bar); iov[2].iov_base = baz; iov[2].iov_len = sizeof (baz); /* read into the structures with a single call */ nr = readv (fd, iov, 3); if (nr == −1) { perror (&quot;readv&quot;); return 1; } for (i = 0; i &amp;lt; 3; i++) printf (&quot;%d: %s&quot;, i, (char *) iov[i].iov_base); if (close (fd)) { perror (&quot;close&quot;); return 1; } return 0;} 구현#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;sys/uio.h&amp;gt;ssize_t naive_writev (int fd, const struct iovec *iov, int count){ ssize_t ret = 0; int i; for (i = 0; i &amp;lt; count; i++) { ssize_t nr; errno = 0; nr = write (fd, iov[i].iov_base, iov[i].iov_len); if (nr == −1) { if (errno == EINTR) continue; ret = −1; break; } ret += nr; } return ret;} readv()와 writev()는 사용자 영역에서 단순 루프를 사용해서 구현할 수 있음! 사실 리눅스 커널 내부의 모든 입출력은 벡터 입출력이다. read, write 구현 역시 하나짜리 세그먼트를 가지는 벡터 입출력으로 구현되어 있음. 4.2 epoll poll과 select 의 한계에 대해서 인지하면서 커널 2.6버전에서는 epoll(event poll) 이라는 기능이 추가되었음 poll과 select 실행할 때마다 전체 fd를 요구함 → 커널은 검사해야 할 모든 파일 리스트를 다 살펴봐야함. → fd 리스트의 크기가 수백 ~ 수천까지 커지면 병목현상이 발생 epoll은 실제로 검사하는 부분과 검사할 fd를 등록하는 부분을 분리해서 위의 문제를 해결함 epoll은 세 가지 System call로 동작함 epoll 컨텍스트를 초기화 검사해야 할 fd를 epoll 컨텍스트에 등록하거나 삭제함 실제 이벤트를 기다리도록 동작 4.2.1 새로운 epoll 인스턴스 생성하기 epoll 컨텍스트는 epoll_create1()을 통해서 생성됨#include &amp;lt;sys/epoll.h&amp;gt;int epoll_create1 (int flags);/* deprecated. use epoll_create1() in new code. */int epoll_create (int size); 호출이 성공하면 새로운 epoll 인스턴스를 생성하고 그 인스턴스와 연관된 fd (epoll fd) 를 반환한다. 요 fd는 실제 파일과는 아무런 관계가 없고 epoll 기능을 사용하는 다음 호출에 사용되는 핸들일 뿐임. flag 인자는 epoll 동작을 조정하기 위한 것 0을 쓰면 size 인자가 없어졌다는 점을 빼면 epoll_create()과 동일함! epoll_fd 의 크기정보를 전달했었음 현재는 EPOLL_CLOSEXEC 만 유효함 새 프로세스가 실행될 때 이 파일을 자동적으로 닫아준다. 에러가 발생하면 -1을 반환, errno를 설정 EINVAL 잘못된 flags 인자 EMFILE 사용자의 최대 파일 초과 ENFILE 시스템의 최대 파일 초과 ENOMEM 메모리 부족 사용예제 int epfd;epfd = epoll_create1 (0);if (epfd &amp;lt; 0) perror (&quot;epoll_create1&quot;); epoll_create1()에서 반환하는 fd는 폴링이 끝난 뒤에 반드시 close()로 닫아줘야한다. 4.2.2 epoll 제어 epoll_ctl() 시스템 콜은 주어진 epoll 컨텍스트에 fd를 추가하거나 삭제할 때 사용한다. #include &amp;lt;sys/epoll.h&amp;gt;int epoll_ctl (int epfd, int op, int fd, struct epoll_event *event); struct epoll_event { __u32 events; /* events */ union { void *ptr; int fd; __u32 u32; __u64 u64; } data;}; epoll_ctl() 호출이 성공하면 해당 epoll 인스턴스는 epfd 파일 디스크립터와 연결된다. epfd 이전에 epoll_create1() 로 생성한 epoll fd fd 등록할 fd op 인자는 fd가 가리키는 파일에 대한 작업을 명시한다. 어떤 변경을 할지 결정하는 값 EPOLL_CTL_ADD epfd와 연관된 epoll 인스턴스가 fd와 연관된 파일을 감시하도록 추가하며, 각 이벤트는 event 인자로 정의한다. EPOLL_CTL_DEL epfd와 연관된 epoll 인스턴스에 fd를 감시하지 않도록 삭제한다. EPOLL_CTL_MOD 기존에 감시하고 있는 fd에 대한 이벤트를 event에 명시된 내용으로 갱신한다. event 인자는 그 작업의 동작에 대한 설명을 담고 있다. 이벤트 유형 epoll_event 구조체의 events 필드는 주어진 fd에서 감시할 이벤트의 목록을 담고 있음 여러가지 이벤트를 OR로 묶을 수 있다. enum Events{ EPOLLIN, //수신할 데이터가 있다. EPOLLOUT, //송신 가능하다. EPOLLPRI, //중요한 데이터(OOB)가 발생. EPOLLRDHUD,//연결 종료 or Half-close 발생 EPOLLERR, //에러 발생 EPOLLET, //엣지 트리거 방식으로 설정 EPOLLONESHOT, //한번만 이벤트 받음} epoll_event 구조체의 data 필드는 사용자 데이터를 위한 필드이다. 이 필드에 담긴 내용은 요청한 이벤트가 발생해서 사용자에게 반환될 때 함께 반환됨. 일반적인 사용 예 event.data.fd를 fd로 채워서 이벤트가 발생했을 때 어떤 fd를 들여다 봐야 하는지 확인하는 용도 성공 시 0을 반환하고 실패 시 -1을 반환, errno 설정 예제 코드 struct epoll_event event;int ret;event.data.fd = fd; /* return the fd to us later (from epoll_wait) */event.events = EPOLLIN | EPOLLOUT;ret = epoll_ctl (epfd, EPOLL_CTL_ADD, fd, &amp;amp;event);if (ret) perror (&quot;epoll_ctl&quot;); epfd와 연관된 fd에 설정된 기존 구독 이벤트를 변경하려면 아래와 같이 작성하면 됨 struct epoll_event event;int ret;event.data.fd = fd; /* return the fd to us later */event.events = EPOLLIN;ret = epoll_ctl (epfd, EPOLL_CTL_MOD, fd, &amp;amp;event);if (ret) perror (&quot;epoll_ctl&quot;); 반대로 epoll 인스턴스 epfd에 등록된 fd에 연관된 기존 이벤트를 삭제하려면 아래와 같이! struct epoll_event event;int ret;ret = epoll_ctl (epfd, EPOLL_CTL_DEL, fd, &amp;amp;event);if (ret) perror (&quot;epoll_ctl&quot;); op 값이 EPOLL_CTL_DEL인 경우 이벤트 마스크가 없기 때문에 event 값이 NULL이 될 수도 있음. 하지만, 호환성 문제 떄문에 유효한 포인터를 넘겨야함. 4.2.3 epoll로 이벤트 기다리기 epoll_wait() 시스템 콜은 epoll 인스턴스와 연관된 fd에 대한 이벤트를 기다린다.#include &amp;lt;sys/epoll.h&amp;gt;int epoll_wait( int efpd, //epoll_fd struct epoll_event* event, //event 버퍼의 주소 int maxevents, //버퍼에 들어갈 수 있는 구조체 최대 개수 int timeout //select의 timeout과 동일 단위는 1/1000 ); epoll_wait 를 호출하면 timeout 밀리 초 동안 epoll 인스턴스인 epfd와 연관된 파일의 이벤트를 기다린다. 성공할 경우 events에는 발생한 해당 이벤트 (파일이 읽어나 쓰기가 가능한 상태인지를 나타내는 epoll_event 구조체에 대한 포인터) 가 기록된다. 발생한 이벤트 개수를 반환 events의 data 필드에는 사용자가 epoll_ctl() 을 호출하기 전에 설정한 값이 담겨 있다. 따라서 모든 fd에 대해 순회하면서 체크할 필요가 없음! 이벤트가 있는 fd들이 배열에 담겨오고 그 개수를 알 수 있으니 꼭 필요한 event 만 순회하면서 처리할 수 있다는 장점! 에러가 발생할 경우 -1을 반환하고 errno 를 설정 timeout 0이면 epoll_wait()는 이벤트가 발생하지 않아도 즉시 0을 반환함. -1이면 이벤트가 발생할 때까지 해당 호출은 반환되지 않음 예제#define MAX_EVENTS 64struct epoll_event *events;int nr_events, i, epfd;events = malloc (sizeof (struct epoll_event) * MAX_EVENTS);if (!events) { perror (&quot;malloc&quot;); return 1;}nr_events = epoll_wait (epfd, events, MAX_EVENTS, −1);if (nr_events &amp;lt; 0) { perror (&quot;epoll_wait&quot;); free (events); return 1;}for (i = 0; i &amp;lt; nr_events; i++) { printf (&quot;event=%ld on fd=%d\\n&quot;, events[i].events, events[i].data.fd); /* * We now can, per events[i].events, operate on * events[i].data.fd without blocking. */}free (events);4.2.4 에지 트리거와 레벨 트리거 epoll_ctl()로 전달하는 event 인자의 events 필드를 EPOLLET로 설정하면 fd에 대한 이벤트 모니터가 레벨 트리거가 아닌 에지 트리거로 동작한다. 유닉스 파이프 통신 입출력 예시 출력하는 쪽에서 파이프에 1KB만큼의 데이터를 씀 입력을 받는 쪽에서는 파이프에 대해서 epoll_wait()를 수행하고 파이프에 데이터가 들어와서 읽을 수 있는 상태가 되기를 기다림 레벨 트리거일 경우 2단계의 epoll_wait() 호출은 즉시 반환하며 파이프가 읽을 준비가 되었음을 알려줌 에지 트리거일 경우 1단계가 완료될 때까지 호출이 반환되지 않음. 즉, epoll_wait()를 호출하는 시점에 파이프를 읽을 수 있는 상황이더라도 파이프에 데이터가 들어오기 전까지는 결과 반환 안함. 기본 동작 방식은 레벨 트리거 poll()과 select()의 동작방식도 동일 4.3 메모리에 파일 맵핑하기 리눅스 커널은 표준 파일 입출력의 대안으로 애플리케이션이 파일을 메모리에 맵핑할 수 있는 인터페이스를 제공한다. 메모리 주소와 파일의 단어가 일대일 대응이 된다는 것을 의미 → 개발자가 메모리를 통해 파일에 직접 접근이 가능함. → 메모리 주소에 직접 쓰는 것만으로 디스크에 있는 파일에 기록할 수 있음 4.3.1 mmap() mmap()을 호출하면 fd가 가리키는 파일의 offset 위치에서 len 바이트만큼 메모리에 맵핑하도록 커널에 요청한다.#include &amp;lt;sys/mman.h&amp;gt;void * mmap (void *addr, size_t len, int prot, int flags, int fd, off_t offset); addr addr가 포함되면 메모리에서 해당 주소를 선호한다고 커널에 알려줌 그저 힌트일 뿐이며 대부분 0을 넘겨줌 len fd 가 가리키는 파일의 offset 위치에서 len 바이트만큼 메모리에 맵핑하도록 커널에 요청함. prot 접근권한을 지정 맵핑에 원하는 메모리 보호 정책을 명시PROT_NONE: 접근 불가PROT_READ: 읽기 가능PROT_WRITE: 쓰기 가능PROT_EXEC: 실행 가능 flag 맵핑의 유형과 그 동작에 관한 몇 가지 요소를 명시 MAP_FIXED : mmap()의 addr 인자를 힌트가 아니라 요구사항으로 취급하도록 함 MAP_PRIVATE : 맵핑이 공유되지 않음을 명시. 파일은 copy-on-write 로 맵핑됨. MAP_SHARED : 같은 파일을 맵핑한 모든 프로세스와 맵핑을 공유 MAP_SHARED와 MAP_PRIVATE를 함께 지정하면 안됨. 반환 메모리 맵핑의 실제 시작 주소를 반환한다. fd를 맵핑하면 해당 파일의 참조 카운터가 증가한다. → 따라서 파일을 맵핑한 후에 fd를 닫더라도 프로세스는 여전히 맵핑된 주소에 접근할 수 있다. 예시 fd가 가리키는 파일의 첫 바이트부터 len 바이트까지를 읽기 전용으로 맵핑한다. void *p;p = mmap (0, len, PROT_READ, MAP_SHARED, fd, 0);if (p == MAP_FAILED) perror (&quot;mmap&quot;); mmap() 에 전달하는 인자가 맵핑하는 과정 페이지 크기 페이지는 메모리 관리 유닛 (MMU)에서 사용하는 최소 단위이다. 별도의 접근 권한과 동작 방식을 따르는 가장 작은 메모리 단위라고 할 수 있음. 메모리 맵핑을 구성하는 블록이자 프로세스 주소 공간을 구성하는 블록 mmap() 시스템 콜은 페이지를 다루기 때문에 addr과 offset 인자는 페이지 크기 단위(페이지 크기의 정수배)로 정렬되어야 한다. 만약 len인자가 페이지 크기 단위로 정렬되지 않았다면 다음 크기의 페이지 정수배로 확장됨 마지막 유효 바이트와 맵핑의 끝 사이에 추가된 메모리는 0으로 채워짐 페이지 크기를 얻을 수 있는 표준 메서드는 sysconf()이다. #include &amp;lt;unistd.h&amp;gt;long sysconf (int name); POSIX는 페이지 크기를 바이트 단위로 _SC_PAGESIZE (or _SC_PAGE_SIZE) 로 정의함. 런타임의 페이지 크기를 구하는 방법은 아래와 같다. long page_size = sysconf (_SC_PAGESIZE); 리눅스는 바이트 단위의 페이지 크기를 반환하는 getpagesize()를 제공함 #include &amp;lt;unistd.h&amp;gt;int getpagesize (void); int page_size = getpagesize (); PAGE_SIZE 매크로를 통해서도 페이지 크기를 구할 수 있는데, 런타임이 아닌 컴파일 시점에 시스템의 페이지 크기를 가져온다. int page_size = PAGE_SIZE; 반환값과 에러 mmap() 호출이 성공하면 맵핑된 주소를 반환한다. 실패하면 MAP_FAILED(-1) 를 반환하고 errno를 설정한다. 절대 0을 반환하지 않음.관련 시그널 SIGBUS 프로세스가 더 이상 유효하지 않은 맵핑 영역에 접근하려고 할 때 발생함. 맵핑된 후에 파일이 잘렸을 경우에 이 시그널이 발생함. SIGSEGV 프로세스가 읽기 전용으로 맵핑된 영역에 쓰려고 할 때 발생 4.3.2 munmap() mmap()으로 생성한 맵핑을 해제하기 위한 munmap() 시스템 콜을 제공함.#include &amp;lt;sys/mman.h&amp;gt;int munmap (void *addr, size_t len); 페이지 크기로 정렬된 addr에서 시작해서 len 바이트만큼 이어지는 프로세스 주소 공간에 존재하는 페이지를 포함하는 맵핑을 해제함. 맵핑 해제하고 다시 접근하면 SIGSEGV 시그널이 발생함. 성공 시 0을 반환, 실패 시 -1을 반환하고 errno 설정 예제 [addr, addr+len] 사이에 포함된 페이지를 담고 있는 메모리 영역에 대한 맵핑을 해제함. if (munmap (addr, len) == −1) perror (&quot;munmap&quot;); 4.3.3 맵핑 예제#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;sys/stat.h&amp;gt;#include &amp;lt;fcntl.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;sys/mman.h&amp;gt;// 인자로 파일 이름을 받음int main (int argc, char *argv[]){ struct stat sb; off_t len; char *p; int fd; if (argc &amp;lt; 2) { fprintf (stderr, &quot;usage: %s &amp;lt;file&amp;gt;\\n&quot;, argv[0]); return 1; } fd = open (argv[1], O_RDONLY); // 인자로 넘겨받은 파일을 연다 if (fd == −1) { perror (&quot;open&quot;); return 1; } if (fstat (fd, &amp;amp;sb) == −1) { // fstat : 주어진 파일에 대한 정보 반환 perror (&quot;fstat&quot;); return 1; } if (!S_ISREG (sb.st_mode)) { // 주어진 파일이 디바이스 파일이나 디렉터리가 아닌 일반 파일인지 점검 fprintf (stderr, &quot;%s is not a file\\n&quot;, argv[1]); return 1; } p = mmap (0, sb.st_size, PROT_READ, MAP_SHARED, fd, 0); // 맵핑 수행 if (p == MAP_FAILED) { perror (&quot;mmap&quot;); return 1; } if (close (fd) == −1) { perror (&quot;close&quot;); return 1; } for (len = 0; len &amp;lt; sb.st_size; len++) putchar (p[len]); if (munmap (p, sb.st_size) == −1) { perror (&quot;munmap&quot;); return 1; } return 0;}4.3.4 mmap()의 장점 read()와 write() 시스템 콜을 사용하는 것보다 mmap()을 이용해서 파일을 조작하는 것이 좀 더 유용하다. read, write 시스템 콜 사용할 때 발생하는 불필요한 복사를 방지할 수 있음. 사용자 영역의 버퍼로 데이터를 읽고 써야 하기 때문에 추가적인 복사가 발생함. (잠재적인 페이지 폴트 가능성을 제외하면) 시스템 콜 호출이나 컨텍스트 스위칭 오버헤드가 발생하지 않음 여러 개의 프로세스가 같은 객체를 메모리에 맵핑한다면 데이터는 모든 프로세스 사이에서 공유된다. lseek() 같은 시스템 콜을 사용하지 않고도 맵핑영역 탐색 가능4.3.5 mmap()의 단점 메모리 맵핑은 항상 페이지 크기의 정수배만 가능하다. 메모리 맵핑은 반드시 프로세스의 주소 공간에 딱 맞아야한다. 다양한 사이즈의 맵핑이 있다면 파편화가 일어남 메모리 맵핑과 관련 자료구조를 커널 내부에서 생성, 유지하는데 오버헤드가 발생한다. 이중 복사 제거 방법으로 방지할 수 있음 읽기 요청마다 표준 입출력 버퍼를 가리키는 포인터를 반환하는 대체 구현을 통해 데이터를 표준 입출력 버퍼에서 직접 읽을 수 있음 → 불필요한 복사 피함 4.3.6 맵핑 크기 변경하기 리눅스는 주어진 메모리 맵핑 영역의 크기를 확장하거나 축소하기 위한 mremap() 시스템 콜을 제공함.#define _GNU_SOURCE#include &amp;lt;sys/mman.h&amp;gt;void * mremap (void *addr, size_t old_size, size_t new_size, unsigned long flags); mrepap()은 [addr, addr + old_size) 에 맵핑된 영역을 new_size 만큼의 크기로 변경한다. flag 0 MREMAP_MAYMOVE : 크기 변경 요청을 수행하는데 필요하다면 맵핑의 위치를 이동해도 괜찮다고 커널에 알려준다. 맵핑 위치를 이동시킬 수 있다면 큰 크기 변경 요청이 성공할 가능성이 높아짐 성공 시 조정된 메모리 맵핑의 시작 주소를 반환함. 실패할 경우 MAP_FAILED 를 반환하며 errno 를 설정 예제 glibc 같은 라이브러리는 malloc()으로 할당한 메모리의 크기를 변경하기 위한 realloc()을 효율적으로 구현하기 위해 mremap()을 자주 사용함 void * realloc (void *addr, size_t len){ size_t old_size = look_up_mapping_size (addr); void *p; p = mremap (addr, old_size, len, MREMAP_MAYMOVE); if (p == MAP_FAILED) return NULL; return p;} 4.3.7 맵핑의 보호 모드 변경하기 POSIX는 기존 메모리 영역에 대한 접근 권한을 변경할 수 있는 mprotect() 인터페이스를 저으히함#include &amp;lt;sys/mman.h&amp;gt;int mprotect (const void *addr, size_t len, int prot); [addr, addr+len) 영역내에 포함된 메모리 페이지의 보호 모드를 변경한다. prot mmap()에 사용한 prot 와 같은 값을 사용할 수 있다. 즉, 메모리 영역이 읽기가 가능한 상태에서 prot로 PROT_WRITE를 설정한다면 쓰기만 가능해짐! 어떤 시스템에서는 mmap()으로 생성한 메모리 맵핑에 대해서만 mprotect()를 쓸 수 있지만, 리눅스에서는 어떤 메모리 영역에도 사용할 수 있다. 성공 시 0반환, 실패 시 -1 반환하고 errno 설정4.3.8 파일과 맵핑의 동기화 POSIX 는 2장에서 살펴본 fsync() 시스템 콜의 메모리 맵핑 버전인 msync()를 제공한다.#include &amp;lt;sys/mman.h&amp;gt;int msync (void *addr, size_t len, int flags); msync()는 mmap()으로 맵핑된 파일에 대한 변경 내용을 디스크에 기록하여 파일과 맵핑을 동기화한다. 구체적으로 살펴보면 메모리 주소 addr에서부터 len 바이트 만큼 맵핑된 파일이나 파일 일부를 디스크로 동기화함. 이때 addr 값은 반드시 페이지 크기로 정렬되어야 한다. 보통은 mmap()에서 반환한 값을 사용함 msync()를 호출하지 않으면 맵핑이 해제되기 전까지는 맵핑된 메모리에 쓰여진 내용이 디스크로 반영된다는 보장을 할 수가 없다. 쓰기 과정 중에 갱신된 버퍼를 디스크에 쓰도록 큐에 밀어넣는 write()와는 동작방식이 다름 flag MS_SYNC : 디스크에 모든 페이지를 기록하기 전까지 msync()는 반환하지 않는다. MS_ASYNC : 비동기 방식으로 동기화한다. MS_INVALIDATE : 맵핑의 캐시 복사본을 모두 무효화한다. OR로 명시할 수 있지만, MS_SYNC와 MS_ASYNC 중 하나는 반드시 해야함. (둘을 함께하는 것은 안됨) 예제 [addr, addr+len) 영역에 맵핑된 파일을 디스크로 동기화한다. fsync()에 비해서 10배 빠름 (메모리라서) if (msync (addr, len, MS_ASYNC) == −1) perror (&quot;msync&quot;); 성공하면 0 반환, 실패하면 -1반환하고 errno 설정4.3.9 맵핑의 사용처 알려주기 리눅스는 프로세스가 맵핑을 어떻게 사용할 것인지 커널에 알려주는 madvise() 시스템 콜을 제공한다. 커널이 이를 통해 얻는 힌트를 사용해서 최적화가 가능함. 부하가 걸리는 상황에서 필요한 캐시와 미리 읽기 방식을 확실히 보장할 수 있게 된다.#include &amp;lt;sys/mman.h&amp;gt;int madvise (void *addr, size_t len, int advice); addr 로 시작해서 len 바이트의 크기를 가지는 메모리 맵핑 내의 페이지와 관련된 동작 방식에 대한 힌트를 커널에 제공함. len 0 이라면 커널은 addr에서 시작하는 전체 맵핑에 힌트를 적용한다. advice MADV_NORMAL : 이 메모리 영역에 대한 특별한 힌트를 제공하지 않는다. MADV_RANDOM : 이 영역의 페이지는 랜덤하게 접근한다. MADV_SEQUENTIAL : 이 영역의 페이지는 낮은 주소에서 높은 주소로 순차적으로 접근한다. MADV_WILLNEED : 이 영역의 페이지는 곧 접근한다. MADV_DONTNEED : 이 영역의 페이지는 당분간 접근하지 않는다. POSIX는 힌트에 대한 의미만 정의하고 있다. 리눅스 커널 2.6 버전 부터는 각 힌트에 대해 조금 다르게 대응한다. madvise 예시 [addr, addr + len) 메모리 영역을 순차적으로 접근할 것이라고 커널에 알려줌 int ret;ret = madvise (addr, len, MADV_SEQUENTIAL);if (ret &amp;lt; 0) perror (&quot;madvise&quot;); 성공하면 0을 반환, 실패 시 -1을 반환하고 errno 설정4.4 일반 파일 입출력에 대한 힌트 위에서는 메모리 맵핑을 사용하는데 힌트를 제공하는 방법에 대해서 알아봤음. 4.4 에서는 커널에 일반적인 파일 입출력에 대한 힌트를 제공하는 방법에 대해서 알아본다.4.4.1 posix_fadvise() 시스템 콜#include &amp;lt;fcntl.h&amp;gt;int posix_fadvise (int fd, off_t offset, off_t len, int advice); fd의 [offset, offset + len) 범위에 대한 힌트를 커널에 제공한다. len 0이면 파일 전체인 [offset, 파일 길이] 에 적용된다. len과 offset을 0으로 넘기면 전체 파일에 대한 힌트제공 advise madvise와 유사함. 한 가지 설정만 가능하다. POSIX_FADV_NORMAL : 힌트 제공 안함 POSIX_FADV_RANDOM : 데이터에 랜덤하게 접근 POSIX_FADV_SEQUENTIAL : 낮은 주소에서 높은 주소로 순차적 POSIX_FADV_WILLNEED : 곧 접근 POSIX_FADV_NOREUSE : 한번만 접근 POSIX_FADV_DONTNEED : 당분간 접근안함 madvise와 동일하게 커널이 이런 힌트에 대응하는 방법은 구현에 따라 다른다. (심지어는 커널 버전에 따라 다르게 동작함.) 예제 커널에게 fd가 가리키는 전체 파일에 랜덤하게 접근하겠다고 알려줌 int ret;ret = posix_fadvise (fd, 0, 0, POSIX_FADV_RANDOM);if (ret == −1) perror (&quot;posix_fadvise&quot;); 성공하면 0을 반환, 실패하면 -1 반환하고 errno 설정4.4.2 readahead() 시스템 콜 POSIX_FADV_WILLNEED 힌트와 동일한 동작 방식을 제공하기 위해 사용 리눅스 전용 인터페이스이다.#define _GNU_SOURCE#include &amp;lt;fcntl.h&amp;gt;ssize_t readahead (int fd, off64_t offset, size_t count); fd가 가리키는 파일의 [offset, offset+count) 영역의 페이지 캐시를 생성한다. 성공하면 0 반환, 실패 시 -1반환하고 errno 설정4.4.3 부담 없이 힌트를 사용하자 !! 일반적으로 애플리케이션에서 발생하는 일부 부하는 커널에 힌트를 제공함으로써 쉽게 개선할 수 있음! 힌트는 입출력의 부하를 완화시킨다. 파일 조각을 읽기 전에 POSIX_FADV_WILLNEED(곧 접근) 힌트를 제공하여 커널이 읽으려는 파일을 페이지 캐시에 밀어 넣을 수 있음 입출력은 백그라운드에서 비동기식으로 일어남. 애플리케이션이 최종적으로 파일에 접근하면 입출력을 블록킹하지 않고 원하는 작업을 완료할 수 있다. 많은 데이터를 연속적으로 디스크에 기록하는 경우 POSIX_FADV_DONTNEED(당분간 접근 X) 힌트를 제공하면 파일 조각을 페이지 캐시에서 제거할 수도 있다. 다시 접근하지 않으면, 불필요한 데이터로 가득 차있을 수 있기 때문에 주기적으로 캐시에서 스트림 데이터를 제거하는것이 합리적 파일 전체를 읽을 때는 POSIX_FADV_SEQUENTIAL(순차적) 힌트를 사용해서 커널에 미리읽기를 공격적으로 수행하도록 할 수 있다. 파일을 랜덤하게 접근하거나 파일의 이곳 저곳을 읽어야 한다면 POSIX_FADV_RANDOM(랜덤하게 접근) 힌트를 사용해서 불필요한 미리읽기를 방지할 수 있음4.5 동기화, 동기식, 비동기식 연산 동기식(Synchronous)과 동기화(Synchroinized)는 크게 다르지 않음 동기식 쓰기 연산 동기식 쓰기 연산은 최소한 쓰고자 하는 데이터가 커널의 버퍼 캐시에 기록되기 전까지는 반환되지 않는다. 비동기식 쓰기 연산은 데이터가 사용자 영역에 머무르고 있을지라도 즉시 반환될 수 있다. 읽기 연산 동기식 읽기 연산은 읽고자 하는 데이터가 애플리케이션에서 제공하는 사용자 영역의 버퍼에 저장되기 전까지는 반환되지 않는다. 비동기식 읽기 연산은 읽으려는 데이터가 미처 준비되기도 전에 반환될 수 있다. 비동기식 연산은 나중을 위해 요청을 큐에 넣을 뿐 실제로 요청된 작업을 수행하지 않음! 동기화 연산은 단순 동기식 연산보다 좀 더 제약적이지만 더 안전하다. 동기화 쓰기 연산은 데이터를 디스크에 기록해서 커널 버퍼에 있던 데이터와 디스크에 기록된 데이터가 동기화되도록 보장한다. 동기화 읽기 연산은 항상 데이터의 최신 복사본을 반환하며 이 복사본은 디스크에서 읽어낼 가능성이 높다. → 동기식과 비동기식이라는 용어는 입출력 연산이 반환하기 전에 데이터 저장과 같은 이벤트를 기다리는지의 여부를 나타냄 → 동기화와 비동기화는 데이터를 디스크에 기록하는 것과 같은 정확한 이벤트가 발생해야 함을 나타냄 보통 유닉스의 쓰기 연산은 동기식이자 비동기화 연산임 특징들의 모든 가능한 조합으로 동작이 가능함| | 동기화 | 비동기화 || ——– | ————————————————————————————— | ——————————————————————————————————– || 동기식 | 데이터를 디스크에 다 비우기 전에는 반환되지 않음. O_SYNC 플래그 명시했을 때 이렇게 동작 | 데이터가 커널 버퍼에 저장되기 전까지 반환되지 않음. 일반적인 동작 || 비동기식 | 요청이 큐에 들어가자마자 반환됨. 최종적으로 쓰기 연산이 실행되어야 디스크에 기록된다. | 요청이 큐에 들어가자마자 반환됨. 최종적으로 쓰기 연산이 실행되어야 적어도 데이터가 커널 버퍼에 저장된다. | 읽기 연산은 동기식이면서 동기화 연산이다. 오랜 데이터를 읽는 것이 의미가 없으므로 항상 동기화 방식으로 동작함| | 동기화 || ——– | ——————————————————————————————– || 동기식 | 최신 데이터가 제공된 버퍼로 읽어오기 전에는 반환하지 않는다. 일반적 동작 || 비동기식 | 요청이 큐에 들어가자마자 반환된다. 하지만 최종적으로 연산이 실행되어야 최신 데이터를 반환함. | 4.5.1 비동기식 입출력 비동기식 입출력을 수행하려면 커널의 최하위 레벨에서부터 지원이 필요하다. aio 인터페이스가 정의되어 있으며 리눅스에서 구현하고 있다. 이는 비동기식 입출력을 요청하고 작업이 완료되면 알림을 받는 함수를 제공함.#include &amp;lt;aio.h&amp;gt;/* asynchronous I/O control block */struct aiocb { int aio_fildes; /* file descriptor */ int aio_lio_opcode; /* operation to perform */ int aio_reqprio; /* request priority offset */ volatile void *aio_buf; /* pointer to buffer */ size_t aio_nbytes; /* length of operation */ struct sigevent aio_sigevent; /* signal number and value */ /* internal, private members follow... */};int aio_read (struct aiocb *aiocbp);int aio_write (struct aiocb *aiocbp);int aio_error (const struct aiocb *aiocbp);int aio_return (struct aiocb *aiocbp);int aio_cancel (int fd, struct aiocb *aiocbp);int aio_fsync (int op, struct aiocb *aiocbp);int aio_suspend (const struct aiocb * const cblist[], int n, const struct timespec *timeout);4.6 입출력 스케줄러와 성능 디스크 성능을 가장 떨어뜨리는 부분은 seek 이라고 하는 하드 디스크에서 데이터를 읽고 쓰는 헤드를 이동시키는 과정이다. 프로세스의 사이클 하나보다 25,000,000배나 더 오래 걸리는 시간. 입출력 요청을 순서대로 디스크로 보내는 방식은 비효율적임 → 입출력 스케줄러를 통해서 디스크 탐색 횟수를 최소화 함.4.6.1 디스크 주소 지정 방식 하드 디스크는 실린더, 헤드, 섹터 또는 CHS 주소 지정방식을 사용함 하드 디스크는 플래터 여러 장으로 구성되어 있으며, 각 플래터는 하나의 디스크, 스핀들, 그리고 read/write 헤더로 구성되어 있다. 플래터를 CD로 생각할 수 있다 각각의 플래터는 CD 처럼 원형의 트랙으로 나뉘어져 있다. 그 트랙들은 정수 개의 섹터로 나뉘어져 있음 특정 데이터가 저장되어 있는 디스크의 위치를 찾을 때 하드 디스크는 실린더, 헤드, 섹터 값을 필요로 함. 어떤 플래터의 어느 트랙, 어느 섹터에 데이터가 있는지 알아야 함 실린더 값 : 데이터가 위치한 트랙을 나타냄 헤드 값 : 요청한 읽기/쓰기 헤드(정확한 플래터)의 정확한 값을 구분함 섹터 값 : 트랙에 위치한 정확한 섹터 요즘 HD는 유일한 블록 번호를 맵핑해서 하나의 블록이 특정 섹터에 대응되도록 한다. 반면 파일 시스템은 소프트웨어로만 존재함. 논리 블록이라는 독자적인 단위를 사용해서 동작함. 파일 시스템의 논리 블록은 디스크의 하나 이상의 물리 블록에 맵핑되어 있다. 4.6.2 입출력 스케줄러의 동작 방식 입출력 스케줄러는 병합과 정렬이라는 두 가지 기본 동작을 수행한다. 병합 둘 이상의 인접한 입출력요청을 단일 요청으로 합치는 과정 예시 : 하나는 5번을 읽으려 하고, 하나는 6,7번까지 읽으려고 할 때 합쳐서 수행함. 연산 횟수는 절반으로 줄어듬 정렬 대기 중인 입출력 요청을 블록 순서의 오름차순으로 정렬하는 것이다. 예시 : 52, 109, 7에 대한 입출력 연산이 들어오면 입출력 스케줄러는 이 요청을 7, 52, 109 순서대로 정렬함. 만약 81번 블록에 대한 새로운 요청이 들어오면 52번과 109번 연산 요청 사이에 끼워넣음 선형적인 방법으로 부드럽게 이동시킬 수 있게 하여서 디스크의 헤드 움직임을 최소화 한다. 4.6.3 읽기 개선 읽기 요청은 반드시 최신 데이터를 반환해야 함 따라서 요청한 데이터가 페이지 캐시에 존재하지 않으면 디스크에서 데이터를 읽어올 때까지 블록되어야 하며 시간이 오래 걸릴 수 있음 → 읽기 Latency 라고 한다. 읽기의 경우 나중에 들어온 요청은 앞선 요청의 완료에 의존적이다. 이에 반해 쓰기 요청은 디스크 성능에 방해가 되지 않는 스트림을 사용하는데, 이는 커널과 디스크의 주의를 독차지 할 수 있다. → 이렇게 되면 읽기 문제가 복잡해지는데 이를 “Writes-starving-reads problem”이라고 한다 만약 입출력 스케줄러가 항상 요청이 들어온 순서에 따라 새로운 요청을 끼워 넣는다면 멀리 떨어진 블록에 대한 요청을 무기한으로 굶겨 죽일 수 있음. 리누스 엘리베이터 같은 단순한 접근 방식은 큐에 충분히 오래된 요청이 있다면 삽입-정렬 기능을 멈춘다. 전체 성능을 희생하여 요청에 대한 공정석을 유지하고 읽기 요청인 경우 레이턴시를 개선한다. 문제는 이 휴리스틱이 너무 단순하다는 것 데드라인 입출력 스케줄러 전통적인 엘리베이터 알고리즘의 일반적인 문제를 해결하기 위해 도입되었다. 리누스 엘리베이터는 대기 중인 입출력 요청을 정렬된 목록(큐)으로 유지한다. 데드라인 입출력 스케줄러는 이 큐를 유지하고 읽기 FIFO 큐와 쓰기 FIFO 큐라는 두 가지 추가 큐를 도입해서 문제를 해결한다. 각 큐에 들어있는 각 요청은 만료기간이 할당되어 있음. 읽기 500밀리초, 쓰기 5초 새로운 입출력 요청이 들어오면 표준 큐에 삽입-정렬되고, 읽기 or 쓰기 FIFO 큐의 끝 부분에 위치한다. 일반적으로 표준 큐가 블록 번호로 정렬되어 있으므로 탐색을 최소화하여 전체 처리량을 최대로 높임 만약 읽기 쓰기 FIFO 큐 앞부분에 있는 아이템이 해당 표준 큐의 만료기간보다 오래되면 입출력 스케줄러는 포준 큐에서 입출력 요청을 처리하지 않고 해당 FIFO 큐에서 요청을 처리하기 시작함. 입출력 요청에 대해서 말랑한 데드라인을 강제한다. 비록 만료전에 처리된다고 보장할 수는 없지만, 이반적으로 거의 요청 만료시간 안에 처리함. 읽기 요청의 만료시간이 좀 더 짧기 떄문에 쓰기가 읽기를 굶겨 죽이는 문제도 최소화 한다.예측 입출력 스케줄러 데드라인 입출력 스케줄러의 문제점 연속된 읽기 요청이 계속 들어올 경우, 정렬된 큐의 요청을 처리하기 위해서 앞뒤로 계속 왔다 갔다함. 새로운 읽기 요청은 앞선 요청이 반환되어야만 처리되는데, 그렇게 되면 데이터를 읽어서 서비스 하는 데 한번, 다시 되돌리는데 한번해서 총 두번의 탐색을 낭비함. 위의 문제점들을 해결하기 위해서 예측 입출력 스케줄러는 데드라인 입출력 스케줄러에다가 예측 매커니즘을 추가하였다. 예측 입출력 스케줄러는 읽기 요청이 들어오면 평소처럼 만료시간 내에 처리한다. 하지만 요청을 처리하고 아무것도 하지 않고 6밀리 초까지 기다림. → 6밀리 초는 애플리케이션이 파일 시스템의 동일한 부분에 대한 새로운 읽기를 요청할 충분한 시간이다. 6밀리 초 까지 요청이 없다면 예측이 잘못되었음을 인정하고 이전 작업 내용을 반환한다. 대부분의 읽기는 의존적이므로 에측을 통해 시간을 많이 아낄 수 있음CFQ 입출력 스케줄러 Complete Fair Queuing 프로세스마다 독자적인 큐를 할당하고, 각 큐는 시간을 할당받는다. Round Robin 방식으로 각 큐를 순회하면서 큐의 허락된 시간이 다 지나거나, 요청이 남아 있지 않을 때 큐에 있는 요청을 처리함. 시간이 남았지만, 더이상 요청이 큐에 없다면 CFQ 스케줄러는 짧은 시간 동안 (default = 10밀리초) 그 큐의 새로운 요청을 기다림. 예측이 맞으면 탐색을 피하고, 틀리면 다음 프로세스의 큐로 간다. 프로세스의 개별 큐 안에서 동기화된 요청(읽기 요청…) 은 동기화되지 않은 요청보다 더 높은 우선순위를 가짐. → 읽기 요청을 배려해서 쓰기 요청이 읽기를 굶겨 죽이는 문제를 회피한다. 대부분의 업무 부하에 적합하며 가장 먼저 고려해볼 만하다.Noop 입출력 스케줄러 가장 기본적인 스케줄러 정렬을 수행하지 않고 병합만 수행함. → 정렬할 필요가 없거나, 정렬을 하지 않는 장치에 특화된 스케줄러 4.6.4 입출력 스케줄러 선택과 설정 기본 입출력 스케줄러는 부팅 시 커널 명령행 인자인 iosched 를 통해서 선택할 수 있다. 유효한 값으로는 cfq, deadline, noop 이 있다. 실행 중에도 각 장치에 대해 /sys/block/[device]/queue/scheduler 값을 변경해서 선택할 수 있음 device : 블록 디바이스를 의미 입출력 스케줄러 설정 예시 # echo cfq &amp;gt; /sys/block/hda/queue/scheduler 4.6.5 입출력 성능 최적화 디스크 입출력은 많이 느리기 떄문에 성능 극대화는 매우 중요함 여러가지 기법들 자잘한 연산을 묶어 몇 개로 합쳐서 연산 최소화 하기 입출력을 블록 크기에 정렬되도록 수행하기 사용자 버퍼링을 사용하기 벡터 입출력 위치를 지정한 입출력 비동기식 입출력 사용자 영역에서 입출력 스케줄링하기 엄청난 입출력을 처리해야 하는 애플리케이션은 입출력 요청을 정렬하고 병합해서 조금이라도 더 성능을 높여야함. (입출력이 많지 않은 애플리케이션에서 정렬하는 것은 어리석은 짓) 만약 입출력 요청이 계속 들어오고 있는 상황에서 중간에 정렬을 하는 것은 비효율적이다. 따라서 요청을 제출하기 전에 정렬을 해주면 원하는 순서대로 수행이 가능함.경로로 정렬하기 파일 경로로 정렬하는 방법은 가장 쉽지만, 효과는 적은 방법이다. (블록 단위 정렬을 흉내내는 방식) 대부분의 파일시스템의 배치 알고리즘에 의해 디렉터리 내의 파일 혹은 부모 디렉터리를 공유하는 디렉터리들은 디스크에서 인접하는 경향이 있음. → 파일의 물리적인 위치를 얼추 비슷하게 맞출 수 있다. 장점 적어도 모든 파일 시스템에 적용 가능한 방법 일시적인 지역성 덕분에 중간 정도의 정확도를 기대할 수 있음. 구현하기 쉬움 단점 파편화를 고려하지 않았음 inode로 정렬하기 inode 는 개별 파일과 관련된 메타데이터를 담고 있는 유닉스의 구성 요소이다. 파일의 데이터가 물리 디스크 블록을 여러개 점유하고 있다고 해도, 하나의 inode만을 가짐. inode 는 유일한 번호가 할당됨.파일 i의 inode 번호 &amp;lt; 파일 j의 inode 번호==파일 i의 물리블록 &amp;lt; 파일 j의 물리블록 inode의 번호는 stat() 시스템 콜을 통해서 얻을 수 있음 주어진 파일의 inode 번호 출력 프로그램 예시 #include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;fcntl.h&amp;gt;#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;sys/stat.h&amp;gt;/* * get_inode - returns the inode of the file associated * with the given file descriptor, or −1 on failure */int get_inode (int fd){ struct stat buf; int ret; ret = fstat (fd, &amp;amp;buf); if (ret &amp;lt; 0) { perror (&quot;fstat&quot;); return −1; } return buf.st_ino;}int main (int argc, char *argv[]){ int fd, inode; if (argc &amp;lt; 2) { fprintf (stderr, &quot;usage: %s &amp;lt;file&amp;gt;\\n&quot;, argv[0]); return 1; } fd = open (argv[1], O_RDONLY); if (fd &amp;lt; 0) { perror (&quot;open&quot;); return 1; } inode = get_inode (fd); printf (&quot;%d\\n&quot;, inode); return 0;} inode 정렬 장점 inode번호는 쉽게 얻을 수 있고 정렬도 쉬움 물리적인 파일 배치를 추측할 수 있는 좋은 지표 단점 파편화에 따라 추측이 틀릴 수 있음 유닉스 파일 시스템이 아닌 경우 정확도가 떨어짐 사용자 영역에서 입출력 요청을 스케줄링하기 위해서 가장 흔히 사용되는 방법물리 블록으로 정렬하기 최적의 방법은 물리적인 디스크 블록으로 정렬하는 것임 각 파일은 파일 시스템에서 가장 작은 할당 단위인 논리 블록 단위로 쪼개짐. (논리 블록 크기는 파일 시스템 마다 다르다.) 각각의 논리 블록은 하나의 물리 블록에 맵핑되어 있다. 커널은 파일의 논리 블록에서 물리 디스크 블록을 알아내는 메서드를 제공한다. ret = ioctl (fd, FIBMAP, &amp;amp;block);if (ret &amp;lt; 0) perror (&quot;ioctl&quot;); block 찾고 싶은 물리 블록에 대한 논리 블록 block은 0부터 시작하는 파일에 상대적인 값. 성공하면 block 은 물리 블록 번호로 바뀐다. 논리 블록과 물리 블록의 맵핑을 찾으려면 2단계가 필요함. 주어진 파일의 블록 개수를 구함 stat() 시스템 콜로 구할 수 있다. 각 논리 블록을 가지고 ioctl()을 통해 이에 상응하는 물리 블록을 구한다. 예제 #include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;fcntl.h&amp;gt;#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;sys/stat.h&amp;gt;#include &amp;lt;sys/ioctl.h&amp;gt;#include &amp;lt;linux/fs.h&amp;gt;/* * get_block - for the file associated with the given fd, returns * the physical block mapping to logical_block */int get_block (int fd, int logical_block){ int ret; ret = ioctl (fd, FIBMAP, &amp;amp;logical_block); if (ret &amp;lt; 0) { perror (&quot;ioctl&quot;); return −1; } return logical_block;}/* * get_nr_blocks - returns the number of logical blocks * consumed by the file associated with fd */int get_nr_blocks (int fd){ struct stat buf; int ret; ret = fstat (fd, &amp;amp;buf); if (ret &amp;lt; 0) { perror (&quot;fstat&quot;); return −1; } return buf.st_blocks;}/* * print_blocks - for each logical block consumed by the file * associated with fd, prints to standard out the tuple * &quot;(logical block, physical block)&quot; */void print_blocks (int fd){ int nr_blocks, i; nr_blocks = get_nr_blocks (fd); if (nr_blocks &amp;lt; 0) { fprintf (stderr, &quot;get_nr_blocks failed!\\n&quot;); return; } if (nr_blocks == 0) { printf (&quot;no allocated blocks\\n&quot;); return; } else if (nr_blocks == 1) printf (&quot;1 block\\n\\n&quot;); else printf (&quot;%d blocks\\n\\n&quot;, nr_blocks); for (i = 0; i &amp;lt; nr_blocks; i++) { int phys_block; phys_block = get_block (fd, i); if (phys_block &amp;lt; 0) { fprintf (stderr, &quot;get_block failed!\\n&quot;); return; } if (!phys_block) continue; printf (&quot;(%u, %u) &quot;, i, phys_block); } putchar (&#39;\\N&#39;);}int main (int argc, char *argv[]){ int fd; if (argc &amp;lt; 2) { fprintf (stderr, &quot;usage: %s &amp;lt;file&amp;gt;\\n&quot;, argv[0]); return 1; } fd = open (argv[1], O_RDONLY); if (fd &amp;lt; 0) { perror (&quot;open&quot;); return 1; } print_blocks (fd); return 0;} 장점 정확히 정렬하고 싶은 대상인 파일이 실제 존재하는 물리 디스크 블록을 반환한다 단점 root 권한이 필요함. ioctl의 FIBMAP이 root 권한이 필요한 CAP_SYS_RAWIO 기능을 요구함 " }, { "title": "[Linux System Programming] Ch03 버퍼 입출력 ", "url": "/posts/linux_ch03/", "categories": "Linux", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-03-13 00:00:00 +0900", "snippet": "[Ch03 버퍼 입출력] 블록 : 파일 시스템의 최소 저장 단위를 나타내는 추상 개념.파일 시스템 연산은 블록 단위로 일어난다. (데이터에 필요한 블록이 4.5개라 하더라도 5개를 써야함.)→ 블록의 일부분만 다루는 연산이 비효율적임.3.1 사용자 버퍼 입출력 일반 파일에 대해 잦은 입출력을 처리해야만 하는 프로그램은 종종 사용자 버퍼 입출력을 수행한다. 이는 커널이 아니라 사용자 영역에서 버퍼링을 처리한다는 의미 커널은 내부적으로 지연된 쓰기연산, 미리읽기, 연속된 입출력 요청 을 모아서 처리하는 방식으로 버퍼링을 구현하고 있음. 일반 파일에 대해 잦은 입출력을 처리해야 하는 프로그램은 종종 사용자 버퍼 입출력을 수행한다.dd bs=1 count=2097152 if=/dev/zero of=pirate2MB 데이터를 1B씩 약 2백만 번에 걸쳐 읽어들임dd bs=1024 count=2048 if=/dev/zero of=pirate2MB 데이터를 1KB씩 약 2천 번에 걸쳐 읽어들임 블록 크기 (Byte) 실제 시간 (초) 사용자 시간 (초) 시스템 시간 (초) 1 18.707 1.118 17.549 1024 0.025 0.002 0.023 1130 0.035 0.002 0.027 1KB 단위로 읽어들이면 시스템콜의 횟수를 1024배 줄임으로써 성능을 비약적으로 개선할 수 있다.다만 블록 크기를 1130 Byte로 키우면 시스템콜의 횟수는 줄지만 실제 물리 블록의 크기의 약수나 배수가 아니므로 성능 저하가 발생한다. 실제로 /dev/zero의 경우 블록 크기는 4096 Byte다.3.1.1 블록크기 실제로 블록 크기는 보통 512, 1024, 2048, 4096 혹은 8192로 정해진다. → 커널과 하드웨어는 블록 크기를 기준으로 대화하기 때문에 블록 크기의 정수배나 약수 단위로 연산을 수행하기만 해도 상당한 성능 개선이 따라옴 그렇다면 모든 데이터를 4KB or 8KB단위로 취급하는게 좋은가? No. 실제로 데이터를 블록 단위로 취급하는 프로그램이 드물기에 현실성이 없음 프로그램은 블록 같은 추상 개념이 아니라 필드, 행, 단일 문자를 다룬다. 그래서 사용자 버퍼 입출력이 필요함.데이터가 쓰여지면 프로그램 **주소 공간 내 버퍼**에 저장이 됨.버퍼가 특정 크기에 도달하면 전체 버퍼는 **한 번의 쓰기 연산을 통해 실제로 기록이 됨.**읽기 또한 버퍼 크기에 맞춰 **블록에 정렬된 데이터를 읽는다.**→ 데이터가 많더라도 모두 블록 크기에 맞춰 적은 횟수의 시스템 콜만 사용하게 됨. 성능 향상! 사용자 애플리케이션 코드 레벨에서 인위적으로 버퍼링을 구현해서 사용해야함.But, 표준 입출력 라이브러라 (stdio)와 표준 C++ iostream이라는 견고하고 뛰어난 사용자 버퍼링 구현체를 가져다 사용하면 된다!3.2 표준 입출력 표준 C 라이브러리는 표준 입출력 라이브러리 (stdio)를 제공함3.2.1 파일 포인터 표준 입출력 루틴은 File Descriptor를 직접 다루지 않고, File pointer라는 독자적인 식별자를 사용한다. 표준 입출력 용어로 열린 파일은 Stream 이라고 부르기도 함. Stream 은 읽기(입력 스트림), 쓰기 (출력 스트림), 또는 읽기/쓰기 (입출력 스트림) 모드로 열 수 있음 3.3 파일 열기 파일을 읽거나 쓰기 위해서 fopen()을 사용한다. (FILE은 stdio.h 에 정의된 FILE typedef)FILE * fopen (const char *path, const char *mode)// EXFILE *stream;stream = fopen (&quot;/etc/manifest&quot;, &quot;r&quot;);if (!stream) ERROR 파일 path를 mode에 따라 원하는 용도로 새로운 스트림을 만든다. 성공 시 유효한 FILE 포인터를 반환. 실패 시 NULL 반환, errno 설정3.3.1 모드 r : 읽기 목적으로 파일을 엶. r+: 읽기/쓰기 목적. 스트림은 파일 시작 지점. w : 쓰기 목적으로 파일을 엶. 파일이 이미 존재하면 길이를 0으로 잘라버림. 파일이 존재하지 않으면 새로 만듬. w+: 읽기/쓰기 목적. 파일이 이미 존재하면 길이를 0으로 자름. 파일이 존재하지 않으면 새로 만듦. 스트림은 파일 시작 지점. a : 덧붙이기 상태에서 쓰기 목적으로 파일을 엶. a+: 덧붙이기 상태에서 읽기/쓰기 목적으로 파일을 엶. 파일이 존재하지 않으면 새로 만듦. 스트림은 파일 끝 지점.3.4 파일 디스크립터로 스트림 열기 fdopen() 함수는 이미 열린 파일 디스크립터를 통해 스트림을 만든다.FILE * fdopen (int fd, const char *mode); 사용가능한 mode는 fopen()과 동일하며, 원래 fd를 열 때 사용했던 모드와 호환성을 유지해야 한다. fopen()에서는 w모드로 스트림을 열었을 때 이미 존재한다면 파일을 0으로 잘라버렸음. 하지만 fdopen()은 그렇지 않은데 그 이유는 이미 파일이 fd에 대해서 열려있기 때문. 따라서 open() 함수에 의해 반환 받은 fd를 fdopen() 함수에서 받았을 경우 open() 함수에 O_TRUNC 플래그가 있어야만 파일을 자를 수 있음! fd가 스트림으로 변환되면 그 fd를 통해 직접 입출력을 수행이 가능하긴 하지만 그렇게 하면 안됨!3.5 스트림 닫기int fclose (FILE *stream) 버퍼에 쌓여있지만 아직 스트림에 쓰지 않은 데이터를 먼저 처리함. fclose 하면 fd까지 닫히나? 성공하면 0 반환, 실패하면 EOF 반환하고 errno 적절한 값으로 설정3.5.1 모든 스트림 닫기int fcloseall (void) fcloseall() 함수는 stdin, sdtout, stderr 를 포함해서 현재 프로세스와 관련된 모든 스트림을 닫는다. 닫기 전에 버퍼에 남아 있는 데이터는 모두 스트림에 쓰여지며 언제나 0을 반환3.6 스트림에서 읽기 스트림에서 데이터를 읽으려면 w나 a를 제외한 나머지 모드(읽기 가능 모드)로 스트림을 열어야 함3.6.1 한 번에 한 문자씩 읽기int fgetc(FILE *stream) stream 에서 다음 문자를 읽고 unsigned char 타입을 int 타입으로 변환해서 반환한다. 타입 변환 이유 : 파일 끝이나 에러를 알려줄 수 있도록 하기 위함. 이런 에러일 때는 EOF반환 반드시 반환 값이 int 타입이어야 한다. char타입으로 저장하게 되면 에러 확인이 불가능함! int c;c = fgetc (stream);if (c == EOF) // errorelse printf()읽은 문자 되돌리기 스트림을 찔러보고 원하는 문자가 아닌 경우 되돌려버린다. 즉, 스트림에 문자를 다시 집어넣는 것임.int ungetc (int c, FILE *stream)// 여러번 호출 시 역순으로 출력. LIFO (Last In First Out)// 파일에 직접 쓰여지는 것이 아니라 버퍼에 쓰여지게 됨// 리눅스에서는 메모리가 허용하는 범위 내에서 무제한 되돌리기 허용ungetc(&#39;a&#39;, stream);ungetc(&#39;b&#39;, stream);ch = getc(fp); // ch 에는 b 가 들어간다.ch = getc(fp); // ch 에는 a 가 들어간다.// 중간에 파일 위치 표시자의 값이 0이 된다면 그 이후에 호출된 unget함수들은 모두 무시됨.fp = fopen(&quot;test.txt&quot;, &quot;r&quot;);getc(fp); // 이 함수 호출 이후 위치 표시자의 값은 1ungetc(&#39;a&#39;, fp); // 이 함수 호출 이후 값은 0ungetc(&#39;b&#39;, fp); // 따라서 버퍼에 b 가 들어갈 수 없다.ch = getc(fp); // ch 에는 a 가 들어간다.printf(&quot;%c&quot;, ch);ch = getc(fp); // ch 에는 test.txt 의 두 번째 문자가 들어간다. ungetc()를 호출하고 중간에 탐색함수를 호출했고, 읽기 요청은 아직 하지 않았을 경우 되돌린 문자를 다 버린다. 스레드는 버퍼를 공유하므로 단일 프로세스에서 여러 스레드가 동작하는 경우에도 동일한 현상 발생 3.6.2 한 줄씩 읽기 fgets() 함수는 stream에서 문자열을 읽는다.char *fgets (char *str, int size, FILE *stream) stream에서 size보다 하나 적은 내용을 읽어서 결과를 str에 저장한다. 마지막 바이트를 읽고 난 다음, 버퍼 마지막에 null 문자 (\\0)을 저장한다. EOF나 개행문자를 만나면 읽기 중단. 개행문자를 읽으면 str에 \\n을 저장 무조건 \\0은 마지막에 넣음. 문자열은 마지막에 NUll로 끝남 성공하면 str을 반환, 에러일 경우 NULL 반환원하는 만큼 문자열 읽기 행 단위로 읽는 방법은 유용하지만 다른 구분자를 사용하고 싶을 때도 있음 fgetc 로 fgets와 동일한 로직을 구현할 수 있다char *s;int c;s = str// n-1 바이트를 읽어서 str에 저장while (--n &amp;gt; 0 &amp;amp;&amp;amp; (c = fgets (stream)) != EOF) *s++ = c;// \\0 을 추가*s = &#39;\\0&#39;;// d를 \\n으로 하면 fgets와 동일while (--n &amp;gt; 0 &amp;amp;&amp;amp; (c = fgec (stream) != EOF &amp;amp;&amp;amp; (*s++ = c) != d) ;if (c==d) *--s = &#39;\\0&#39;;else *s = &#39;\\0&#39;;3.6.3 바이너리 데이터 읽기 개별 문자나 행을 읽는 기능만으로 부족할때 (C 구조체 같은 복잡한 바이너리 데이터를 읽고 써야하는 경우) fread()함수 사용size_t fread( void *buf, size_t size, size_t nr, FILE *stream) stream에서 각각 크기가 size 바이트인 엘리먼트를 nr개 읽어서 buf가 가리키는 버퍼에 저장한다. 읽어들인 엘리먼트 개수가 반환됨. nr보다 적은 값을 반환하여 실패나 EOF를 반환 ferror() or feof()를 사용하지 않고서는 실패 or EOF를 알 수가 없음 변수의 크기, 정렬, 채워넣기, 바이트 순서가 다르기 때문에 어떤 애플리케이션에서 기록한 바이너리 데이터를 다른 앱에서는 못 읽을 수도 있다.정렬문제 모든 아키텍처는 데이터 정렬 요구사항을 가지고 있음. 프로세스는 바이트 크기 단위로 메모리를 읽고 쓰지 않고, 2,4,8,,, 바이트처럼 정해진 기본 단위로 메모리에 접근함. → 기본 단위의 정수배로 시작하는 주소에 접근해야함 따라서 C언어에서 변수는 반드시 정렬된 주소에 저장하고 접근해야함. 예를 들어 32비트 정수는 4바이트 경계에 맞춰 정렬됨. → int는 4로 나누어 떨어지는 메모리 주소 공간에 저장된다. 정렬되지 않은 데이터 접근에 대해서는 다양한 패널티가 존재한다. 접근 가능 but 성능 저하 접근 허용 X, 하드웨어 예외로 처리 강제 정렬을 위해 하위 비트를 제거해버림 3.7 스트림에 쓰기3.7.1 한 번에 문자 하나만 기록하기 fgetc()에 대응하는 쓰기 함수는 fputc()이다.int fputc(int c, FILE *stream); c로 지정한 바이트를 (unsigned char로 변환한 후에) stream이 가리키는 스트림에 쓴다. 문자 혹은 숫자가 아스키 코드표에 맞게 int값으로 들어감. 성공 시 c 반환, 실패 시 EOF 반환하고 errno 설정if (fputc (&#39;p&#39;, stream) == EOF)3.7.2 문자열 기록하기int fputs (const char *str, FILE *stream) str이 가리키는 NULL로 끝나는 문자열 전무를 stream이 가리키는 스트림에 기록한다. 성공하면 음수가 아닌 값 반환, 실패 시 EOF 반환3.7.3 바이너리 데이터 기록하기 C 변수처럼 바이너리 데이터를 직접 저장하려면 표준 입출력에서 제공하는 fwrite()를 사용size_t fwrite (void *buf, size_t size, size_t nr, FILE *stream); buf가 가리키는 데이터에서 size크기의 엘리먼트 nr개를 stream에 쓴다.3.8 사용자 버퍼 입출력 예제 프로그램int main(void){ FILE *in, *out; struct pirate { char name[100]; unsigned long booty; unsigned int beard_len; } p, blackbeard = {&quot;Edward Teach&quot;, 950, 48}; out = fopen (&quot;data&quot;, &quot;w&quot;); if (!out) { perror(&quot;fopen&quot;); return 1; } if (!fwrite(&amp;amp;blackbeard, sizeof(struct pirate), 1, out)){ perror (&quot;fwrite&quot;); return 1; } if (fclose(out)){ perror(&quot;fclose&quot;); return 1; } in = fopen(&quot;data&quot;, &quot;r&quot;); if (!fread(&amp;amp;p, sizeof (struct pirate), 1, in)){ perror(&quot;fread&quot;) return 1; }} 변수 크기, 정렬 등에서 차이가 있기 때문에 특정 애플리케이션에서 쓴 바이너리 데이터를 다른 애플리케이션에서 읽지 못할 수도 있다.만약 unsigned long 타입의 크기가 바뀌거나 채워 넣는 값의 양이 달라진다면 정확한 데이터를 못쓸것.아키텍처와 ABI가 동일한 경우에만 바이너리 데이터를 일관적으로 읽고 쓸 수 있음. ABI : Application Binary Interface3.9 스트림 탐색하기int fseek (FILE *stream, long offset, int whence) offset과 whence에 따라 stream에서 파일 위치를 조작한다. whence SEEK_SET - 파일 위치를 offset값으로 설정 SEEK_CUR - 현재위치에서 offset만큼 더한 값으로 설정 SEEK_END - 파일 위치를 파일 끝에서 offset만큼 더한 값으로 설정 성공하면 0 반환하고 EOF 지시자를 초기화하고 이전에 실행했던 ungetc()를 취소한다. 에러 발생하면 -1 반환하고 errno를 설정 EBADF - 유효하지 않은 스트림 EINVAL - whence인자 잘못됨 fsetpos는 stream의 위치를 pos로 설정한다.int fsetpos (FILE *stream, fpos_t *pos) 이는 whence가 SEEK_SET인 fseek()와 동일하게 동작함. C의 long 타입만으로는 스트림의 위치를 지정하기에 충분하지 않으므로 어떤 플랫폼에서는 이 함수가 스트림 위치를 특정한 값으로 설정할 수 있는 유일한 방법임.void rewind (FILE *stream)// ==fseek(stream, 0, SEEK_SET); 스트림을 시작 위치로 되돌리며 fseek을 위와 같이 사용하는 것과 동일함. 하지만 fseek()와는 달리 rewind()는 오류 지시자를 초기화 한다. rewind는 반환값이 없어서 에러 조건을 직접적으로 파악할 수가 없음.// 이런식으로 직접 확인을 해야함.errno = 0;rewind(stream);if (errno) //error3.9.1 현재 스트림 위치 알아내기 lseek()와는 다르게 fseek()는 갱신된 위치를 반환하지 않음. 따라서 위치를 파악하기 위한 용도로 분리된 인터페이스를 제공함. ftell 은 현재 스트림 위치를 반환한다.long ftell(FILE *stream); 표준 입출력에서는 fgetpos도 제공을 한다.int fgetpos (FILE *stream, fpos_t *pos) 성공하면 0을 반환하고 현재 스트림 위치를 pos에 기록함. 실패하면 -1을 반환하고 errno를 설정 fsetpos()와 마찬가지로 fgetpos()는 복잡한 파일 위치 타입을 사용하는 비-유닉스 플랫폼을 위해 제공한다.3.10 스트림 비우기 표준 입출력 라이브러리는 사용자 버퍼를 커널로 비워서 스트림에 쓴 모든 데이터가 write()을 통해 실제로 디스크에 기록되도록 만드는 인터페이스를 제공함.int fflush (FILE *stream); stream에 있는 쓰지 않은 데이터를 커널로 비운다. stream이 NULL이면 프로세스의 열려있는 모든 입력 스트림이 비워짐. 성공하면 0 반환, 실패하면 EOF반환하고 errno를 설정 fflush()와 버퍼 여기서 설명하는 모든 함수 호출은 커널이 유지하는 버퍼가 아니라 C 라이브러리가 관리하는 버퍼 를 의미한다. 이는 커널 영역이 아니라 사용자 영역에 위치함. → 시스템 콜을 사용하지 않고 사용자 코드를 실행함으로써 성능개선 fflush()는 단지 사용자 버퍼에 있는 데이터를 커널 버퍼로 쓰기만 함. → 이는 사용자 버퍼를 사용하지 않고 write()을 직접 사용하는 효과와 동일 즉, 데이터를 매체에 물리적으로 기록한다는 보장이 없다. 데이터가 매체에 즉각 기록되어야 하는 경우에는 fflush()를 호출한 다음 바로 fsync()를 호출한다. → 사용자 버퍼를 커널에 쓰고 fsync()를 통해 커널 버퍼를 디스크에 기록하도록 보장한다. 3.11 에러와 EOF fread()와 같은 몇몇 표준 입출력 인터페이스는 에러와 EOF를 구분하는 방법을 제공하지 않는 등 이슈가 있다. ferror()는 스트림에 에러 지시자가 설정되었는지 검사한다. int ferror(FILE *stream) 에러 지시자는 에러 조건에 따라 표준 입출력 인터페이스에서 설정한다. 해당 스트림에 에러 지시자가 설정되어 있을 경우 0이 아닌 값을 반환, 그렇지 않은 경우 0 반환 feof()는 해당 스트림에 EOF 지시자가 설정되어 있는지 검사한다.int feof (FILE *stream) EOF 지시자는 파일 끝에 도달하면 표준 입출력 인터페이스에서 설정한다. clearerr() 함수는 스트림에서 에러 지시자와 EOF 지시자를 초기화한다. void clearerr (FILE *stream); 반환값이 없고 항상 성공하기 때문에 stream 인자값이 정상인지 확인할 수 있는 방법이 없다. 이를 호출하고 나면 다시 복구할 방법이 없으므로 에러 지시자와 EOF 지시자를 먼저 검사한 후에 호출해야함3.12 파일 디스크립터 얻어오기 스트림에서 파일 디스크립터를 구해야 하는 경우가 있다. 대응하는 표준 입출력 함수가 없을 때 int fileno (FILE *stream) fileno를 통해서 fd를 구할 수 있다. 성공하면 stream과 관련된 fd를 반환하고, 실패하면 -1을 반환. 주어진 스트림이 유효하지 않은 경우 errno를 EBADF로 설정 표준 입출력 함수와 시스템 콜 사이에서 사용자 버퍼링과 관련된 충돌이 발생하지 않도록 주의해야 함fd를 사용하기전에 스트림을 비우는 것은 좋은 습관.어쨌든 두가지를 섞어 쓰는 것은 좋지 않다.3.13 버퍼링 제어하기 표준 입출력은 세 가지 유형의 사용자 버퍼링을 구현하고, 버퍼의 유형과 크기를 다룰 수 있는 인터페이스를 제공한다. 각각의 사용자 버퍼링 타입은 저마다의 목적이 있으며 상황에 맞게 사용할 때 가장 이상적임버퍼 미사용 사용자 버퍼를 사용하지 않는다. 즉, 커널로 바로 데이터를 보낸다. 표준 에러를 제외하고는 거의 사용되지 않음행 버퍼 행 단위로 버퍼링을 수행한다. 즉, 개행문자가 나타나면 버퍼의 내용을 커널로 보난다. 화면 출력 메시지는 개행문자로 구분되기 때문에 행 버퍼는 화면 출력을 위한 스트림일 경우 유용함. 표준 출력처럼 터미널에 연결된 스트림에서 기본적으로 사용블록 버퍼 고정된 바이트 개수로 표현되는 블록 단위로 버퍼링을 수행한다. 기본적으로 파일과 관련된 모든 스트림은 블록 버퍼를 사용한다. 표준 입출력에서는 블록 버퍼링을 Full 버퍼링이라고 한다. 표준 입출력은 버퍼링 방식을 제어할 수 있는 인터페이스를 제공한다.int setvbuf (FILE *stream, char *buf, int mode, size_t size); mode _IONBF - 버퍼 미사용 _IOLBF - 행 버퍼 _IOFBF - 블록 버퍼 buf 와 size를 무시하는 _IONBF를 제외하고 나머지는 size 바이트 크기의 버퍼를 가리키는 buf를 주어진 stream을 위한 버퍼로 사용한다. buf가 NULL이라면 glibc 가 자동적으로 지정된 크기만큼 메모리를 할당한다. 스트림을 연 다음 다른 연산을 수행하기 전에 호출해야함. 제공된 버퍼는 스트림이 닫힐 때까지 반드시 존재해야 한다. 흔히 스트림을 닫기 전에 끝나는 스코프 내부의 자동 변수로 버퍼를 선언하는 실수를 함. 특히 main()에서 지역변수로 버퍼를 만든 다음에 스트림을 명시적으로 닫지 않는 경우를 주의해야함. int main(void){ char buf[BUFSIZ]; // stdout을 bufsiz 크기에 맞춰 블록 버퍼로 설정한다. setvbuf(stdout, buf, _IOFBF, BUFSIZ); return 0; // buf는 스코프를 벗어나고 해제된다. 하지만 stdout을 닫지 않았음} 스코프를 벗어나기 전에 스트림을 명시적으로 닫아주거나, buf를 전역 변수로 설정함으로써 방지할 수 있음. 표준 에러를 제외하고 터미널은 행 버퍼링으로 동작, 파일은 블록 버퍼링을 사용하는 것이 맞다.블록 버퍼링에서 버퍼의 기본 크기는 BUFSIZ이며 일반적인 블록 크기의 정수배인 최적의 값이다.따라서 개발자들은 일반적으로 스트림을 다룰 때 버퍼링에 대해 고민할 필요가 없다.3.14 스레드 세이프 스레드 : 개별 프로세스 내에 존재하는 여러 개의 실행 단위.멀티 스레드 프로세스 : 주소 공간을 공유하는 여러 개의 프로세스 스레드 세이프(Thread-safe)멀티 스레드 프로그래밍에서 일반적으로 어떤 함수나 변수, 혹은 객체가 여러 스레드로부터 동시에 접근이 이루어져도 프로그램의 실행에 문제가 없음을 뜻함→ 멀티스레드 환경에서 동작해도 원래 의도한 대로 동작하는 것을 스레드 세이프 하다고 할 수 있음 Thread Safe 하지 않은 코드 예시 int num;boolean is_even;int inc(int n){ num += n; if ((num%2) == 0) is_even = true; else is_evne = false; return num;} num이라는 변수에 숫자를 더해서 짝수이면 is_even = true, 홀수이면 false로 설정 싱글 스레드 환경에서는 문제없는 코드 a = int(1); 위의 라인을 멀티스레드에서 수행했을 경우 의도와 맞지 않는 결과가 발생할 수 있음 멀티코어 시스템에서는 둘 이상의 스레드가 같은 프로세스에서 동시에 실행될 수가 있다. 스레드에서 데이터에 접근할 때 동기화에 주의하지 않거나, 스레드 로컬(스레드 감금) 로 만들지 않으면 스레드가 공유 데이터를 덮어써버릴 수 있다. 스레드를 지원하는 OS는 락 메커니즘을 지원한다. 표준 입출력은 이런 메커니즘을 활용해서 단일 프로세스 내의 여러 스레드가 동시에 표준 입출력을 호출할 수 있도록 한다. 심지어는 같은 스트림에 대해서도 가능하다. 하지만 이것만으로는 부족함 여러 함수 호출을 그룹으로 묶어 통째로 락을 걸면 크리티컬 섹션이 하나의 입출력 연산에서 여러 입출력 연산으로 확장됨 크리티컬 섹션 : 임계 구역. 다른 스레드의 간섭 없이 실행할 수 있는 코드 효율성을 높이기 위해 락을 완전히 없애고 싶은 경우 락을 없애면 온갖 문제가 난무하지만 어떤 프로그램은 모든 입출력을 싱글 스레드에 위임하여 스레드를 가두어서 스레드 세이프를 구현하기도 함. → 락에 의한 오버헤드가 없다. 스레드는 입출력 요청에 앞서 락을 획득하고 고유 스레드가 되어야 함 표준 입출력 함수는 본질적으로 스레드 세이프를 보장한다는 것 단일 함수 호출 관점에서 보면 표준 입출력 연산은 Atomic 하다. 3.14.1 수동으로 파일 락 걸기 stream의 락이 해제될 때까지 기다린 후에 락 카운터를 올리고 락을 얻은 다음, 스레드가 stream을 소유하도록 만든 후에 반환한다.void flockfile (FILE *stream); funlockfile 함수는 stream과 연관된 락 카운터를 하나 줄인다.void funlockfile(FILE *stream); 락 카운터가 0이 되면 현재 스레드는 stream의 소유권을 포기해서 다른 스레드가 락을 얻을 수 있도록 한다. 여러번 중첩 호출이 가능함. ftrylockfile() 함수는 flockfile()의 논블록 버전이다.int ftrylockfile (FILE *stream) stream이 락이 걸려있다면 ftrylockfile()은 아무것도 하지 않고 즉시 0이 아닌 값을 반환함. 논블록이 아니라면, 락이 걸린 상태에서는 블록되어서 계속 기다려야함. 만약 stream이 락이 걸린 상태가 아니라면 락을 걸고 락 카운터를 하나 올린 다음 그 stream을 소유하도록 만들고 0을 반환한다.flockfile (stream);fputs(&quot;a&quot;, stream);fputs(&quot;b&quot;, stream);fputs(&quot;c&quot;, stream);funlockfile(stream); 기록 중 다른 스레드가 중간에 끼어들지 못하게 하려면 락을 이용해야함. 설계 자체에서 동일 스트림을 대상으로 입출력하지 않도록 해야한다. 만약 그렇게 할 수 없다면 flockfile() 같은 함수를 이용해서 크리티컬 섹션을 확장해야 함.3.14.2 락을 사용하지 않는 스트림 연산 상세하고 정밀한 락 제어를 통해 가능한 한 락 오버헤드를 최소화해서 성능을 향상시킬 수 있기때문에 스트림에 대해 수동으로 락을 설정함. 앞서 다루었던 표준 입출력 함수들은 내부적으로 락을 사용한다. 수동으로 락을 걸면 각 표준 입출력 함수들의 내부적인 락을 사용하지 않아도 된다. _unlocked postfix가 붙은 함수들을 이용하면 락 오버헤드를 최소화할 수 있다.3.15 표준 입출력 비평 몇몇 전문가는 표준 입출력의 결함을 지적함 fgets()는 충분한 기능을 제공하지 못한다 wild character 같은 경우 eof 로 읽을 수도 있음 gets()는 표준에서 제거되기도 함.. 경고: the ‘gets‘ function is dangerous and should not be used. 이 문제는 gets함수가 strName[20]의 크기를 모르면서 개행을 찾거나 EOF를 만날 때까지 계속 읽기 때문에 주어진 버퍼의 크기를 넘을 수 있습니다.다르게 설명하자면 C언어는 경계 검사를 수행하지 않아 gets함수가 접근 권한이 없는 주소에 도달 할 때까지 읽기를 계속합니다. 접근 권한이 없는 주소에 도달하는 이런 행위가 아마도 Linux에서는 시스템을 이상 종료 시킬 수 있는 오류 일 것입니다. 그래서 많은 바이러스가 이러한 문제점을 이용합니다. 가장 큰 불만은 이중 복사로 인한 성능 문제이다. 데이터를 읽을 때 표준 입출력의 read() 시스템 콜을 사용하면 데이터는 커널에서 표준 입출력의 버퍼로 복사된다. fgetc()같은 표준 입출력을 통해서 읽기를 요청하면 그 데이터는 표준 입출력 버퍼에서 인자로 제공된 버퍼로 또 복사된다. 쓰기 요청도 마찬가지 읽기 요청은 표준 입출력 버퍼를 가리키는 포인터를 반환하는 대체 구현으로 이중 복사 문제를 피할 수 있음 쓰기 요청도 포인터 기록을 통해서 피할 수 있음3.16 맺음말 표준 입출력은 표준 C 라이브러리의 일부로 제공되는 사용자 버퍼링 라이브러리이다. 아래의 가정을 만족할 때 표준 입출력과 사용자 버퍼링은 의미가 있다. 많은 시스템 콜이 의심되는 경우 수 많은 호출을 합쳐서 줄이는 방법으로 오버헤드를 줄이고 싶다. 성능이 중요하며 모든 입출력은 정렬된 블록 경계에 맞춰 블록 크기 단위로 일어나도록 확실하게 보장해야 한다. 접근 패턴이 문자나 행 기반이며 낯선 시스템 콜에 의지하지 않고 손쉽게 데이터에 접근할 수 있는 인터페이스가 필요하다. 저수준 리눅스 시스템 콜보다는 고수준의 인터페이스를 선호한다. " }, { "title": "[Linux System Programming] Ch02 파일 입출력", "url": "/posts/linux_ch02/", "categories": "Linux", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-03-09 00:00:00 +0900", "snippet": "Ch02 파일 입출력2. 파일 입출력리눅스는 많은 인터페이스를 파일로 구현했음. (유닉스 시스템에서는 거의 모든 것을 파일로 표현)파일 입출력은 단순한 파일 처리를 넘어서 다양한 작업에 밀접하게 관련되어 있음.파일은 읽거나 쓰기 전에 반드시 열어야 한다. File Table 커널은 파일 테이블이라고 하는 프로세스 별로 열린 파일 목록을 관리 함. File Descripter(fd) 음이 아닌 정수 값으로 인덱싱 되어있음 각 항목은 열린 파일에 대한 정보를 담고 있음 inode Pointer Metadata fd 0 : stdin 1 : stdout 2 : stderr 읽고 쓸 수 있는 모든 것은 파일 디스크립터를 통해 접근할 수 있음 2.1 파일 열기 파일 접근하는 기본적인 방법 read(), write() 하지만 접근하기 전에 open() 이나 creat() 로 열고, 다 쓴 후에는 close()로 닫아야함. open() 시스템 콜int open (const char *name, int flags);int open (const char *name, int flags, mode_t mode); 경로 이름이 name인 파일을 fd에 맵핑 성공하면 fd return offset 0으로 설정 실패 시 -1 리턴 flags O_RDONLY, O_WRONLY, O_RDWR 이외에도 여러가지 플래그들이 있는데, flags 파라미터에 OR연산을 통해 작동 가능 O_WRONLY O_TRUNC 새로운 파일의 권한파일 생성하는게 아니라면 open()의 mode 인자는 무시됨.하지만 O_CREAT과 같이 생성 시에는 mode가 꼭 필요하다.creat() 함수 O_WRONLY O_CREAT O_TRUNC → 읽기 전용, 해당 파일이 없으면 새로 생성, 파일이 존재하고 일반파일이며 flags인자에 쓰기가 가능하다면 파일 길이를 0으로 잘라버림→ 너무나도 일반적인 flags라서 이를 지원하는 시스템 콜이 바로 create()fd = creat(filename, 0644);==fd = open(filename, O_WRONLY | O_CREAT | O_TRUNC, 0644);2.2 read()로 읽기ssize_t read (int fd, void *buf, size_t len);호출할 때마다 fd가 참조하는 파일의 현재 오프셋에서 len 바이트만큼 buf로 읽어 들인다. return 성공 시 buf에 쓴 바이트 숫자 실패 시 -1 read()의 여러가지 반환 케이스nr = read (fd, &amp;amp;word, len) nr == len 같은 값 : 정상 0 &amp;lt; nr &amp;lt; len : 읽은 바이트는 word에 저장. 중간에 시그널이 중단 or 읽는 도중 에러 발생 or len 만큼 읽기전에 EOF 발생 → 원인 파악 가능 (buf ,len 을 고친다음 호출 수행) nr == 0 : EOF 블록 : 현재 사용가능한 데이터가 없음 nr == -1 &amp;amp;&amp;amp; EINTR : 바이트 읽기 전에 시그널 도착 nr == -1 &amp;amp;&amp;amp; EAGAIN : 읽을 데이터가 없어서 블록. 논믈록 모드 일 때만 일어나는 상황 nr == -1 &amp;amp;&amp;amp; OTHER : 심각한 에러→ 일반적인 read()는 에러 처리하면서 실제로 모든 len 바이트( 적어도 EOF까지)를 읽는 경우 적합하지 않음while (len != 0 &amp;amp;&amp;amp; (ret = read(fd, buf, len)) != 0) { if (ret == -1){ if (errno == EINTR) continue; perror (&quot;read&quot;); break; } len -= ret; buf += ret;}위의 코드는 5가저 조건을 모두 처리한다.논블록 읽기 때떄로 프로그래머 입장에서 읽을 데이터가 없을 때 read()호출이 블록되지 않기를 바라는 경우가 있음 블록되는 대신 읽을 데이터가 없다는 사실을 알려주기 위해 호출이 즉시 반환되는 편을 선호한다. open() 할 때 플래그를 O_NONBLOCK을 넘겨주었다면 파일 디스크립터를 논블록으로 열게되는데, 이 때 읽을 데이터가 없다면 read() 는 호출이 블록되는 대신 -1을 반환하면서 errno를 EAGAIN으로 설정한다.Blocking I/O Model I/O 작업이 진행되는 동안 유저 프로세스는 자신의 작업을 중단한채 대기해야함. → 리소스 낭비가 심하다. 이를 해결하기 위해 클라이언트 별로 쓰레드를 만들어 연결시켜준다면 클라이언트 수가 늘어날 수록 쓰레드가 너무 많아진다. 이렇게 되면 context switching 횟수가 증가하게 됨. 비효율적Non Blocking I/O Model I/O 작업을 진행하는 동안 유저 프로세스의 작업을 중단시키지 않는다. 함수를 호출하면 진행상황과 상관없이 바로 결과를 반환read() 크기 size_t 바이트 단위로 크기를 측정하기 위해 사용되는 값 저장 SIZE_MAX ssize_t 부호가 있는 size_t 이다. (signed) 음수 에러를 포함하기 위해 사용 SSIZE_MAX len이 이보다 큰 경우의 read() 호출결과는 정의되어 있지 않음 32bit 기계에서는 0x7ffffffff 2.3 Write()로 쓰기파일에 데이터를 기록하기 위해 사용하는 가장 기본적이며 일반적인 시스템 콜ssize_t write (int fd, const void *buf, size_t count);count 바이트만큼 fd가 참조하는 파일의 현재 위치에 시작지점이 buf인 내용을 기록한다. return 성공하면 쓰기에 성공한 바이트 수를 반환 에러가 발생하면 -1을 반환하며 errno를 적절한 값으로 설정 /*buf에 들어있는 문자열을 fd가 가리키는 파일에 입력한다 */const char *buf = &quot;My ship is solid!&quot;;ssize_t nr;nr = write(fd, buf, strlen (buf));if (nr == -1) /* 에러 */덧붙이기 모드 O_APPEND 옵션으로 open()을 하게되면 현재 파일 오프셋이 아니라 파일 끝에서부터 쓰기 연산이 일어난다. 다중 프로세스가 같은 파일 수정을 진행했을 때 race condition이 발생한다. 이는 명시적인 동기화 과정 없이 동일 파일에 덧붙이는 작업이 불가능함을 의미함. 덧붙이기 모드를 이용하면 프로세스가 여럿 존재할지라도 항상 덧붙이기 작업이 수행됨write() 동작방식리눅스 커널은 디스크의 데이터를 캐싱하는데, 이를 페이지 캐시(page cache)라고 하고, 캐시되어 있던 페이지가 다시 디스크로 적용되는 것(동기화 되는 것)을 page writeback이라고 한다. 페이지 캐시의 최대 목적은 디스크 입출력을 최소화 시키는 데 있다. 디스크 접근은 메모리 접근에 비해 상대적으로 많이 느리다. milliseconds vs nanoseconds L1 &amp;gt; L2 &amp;gt; L3 &amp;gt; Memory &amp;gt; Disk Data Locality: 최근에 사용된 데이터는 다시 사용될 가능성이 높다.Write caching3가지 동작 예상 write()에 대해서 이미 캐싱해놓은 데이터와는 상관없이 바로 디스크에 데이터를 내려버리는 경우. 즉, 메모리에 있는 캐시 데이터를 지나치고 바로 디스크로 데이터를 갱신한다. 이 경우에는 기존에 캐싱되어 있는 페이지 캐시는 invalidate 된다. 만약 read()가 해당 데이터에 대해서 들어오면 디스크로부터 읽어온다. 메모리에 있는 캐시와 디스크 모두 갱신해준다. 가장 간단한 방법으로 이러한 방식을 write-through cache라고 한다. 캐시부터 디스크까지 모두 write() 연산이 수행된다. 이 경우 캐시와 디스크 모두를 항상 최신 상태로 만들어주기 때문에 캐시를 일관성있게 유지해준다. (cache coherent) (현재 Linux에서 사용하고 있는 방식) write back 방식은 write() 요청이 들어왔을 때 페이지 캐시에만 우선 갱신하고 backing store에는 바로 갱신하지 않는 방식이다. 이 방식을 채택하면 cache와 원본 데이터가 서로 다르게 되며, 캐시에 있는 데이터가 최신 데이터가 된다. 최신 데이터는 캐싱이 된 이후로 업데이트가 되었다는 의미로 dirty 상태(unsynchronized)가 되며 dirty list에 추가되어 커널에 의해 관리된다. 커널은 주기적으로 dirty list에 등록되어 있는 페이지 캐시를 backing store에 동기화해주는데 이러한 작업을 writeback이라고 한다. writeback 방식은 write-through 방식보다 나은 방법인데, 왜냐하면 최대한 디스크에 쓰는 것을 미루어둠으로써 나중에 대량으로 병합해서 디스크에 쓸 수 있기 때문이다. 단점은 조금 더 복잡하다는 것이다.출처(https://scslab-intern.gitbooks.io/linux-kernel-hacking/content/chapter16.html)2.4 동기식 입출력 필요한 경우 디스크에 순서대로 기록해야만 하는 경우→ 커널의 대기열에서 성능 개선에 적합한 방식으로 쓰기 요청 순서를 변경하기 때문에 문제가 발생할 수 있음 시스템이 비정상 종료될 경우→ 버퍼에 있는 내용을 디스크에 쓰기 전에 시스템이 종료될 수 있음 분명히 입출력을 동기화 하는 것은 중요한 주제임. 하지만 Write 작업이 지연되는 문제를 너무 확대 해석하면 안됨. 최신 OS라면 버퍼를 통해서 지연된 쓰기 작업 을 구현하고 있다. 그럼에도 시점을 제어하고 싶을 때가 있기 때문에 리눅스 커널에서는 “성능”을 희생하는 대신, 입출력을 동기화하는 몇 가지 옵션을 제공한다.fsync()와 fdatasync() fsync()를 호출하면 fd에 맵핑된 파일의 모든 변경점을 디스크에 기록한다. 반드시 fd는 쓰기 모드로 열려야함. fdatasync()는 fsync()와 동일한 기능을 하지만, 메타데이터까지 저장하는 fsync()와는 다르게 데이터만 기록한다. 그렇기 때문에 더 빠름.int ret;ret = fsync(fd);if (ret == -1); /* ERROR */ 몇몇 리눅스 배포판에서 fdatasync()는 구현되어있지만, fsync()는 구현되어있지 않을 때도 있다. 이때는 EINVAL를 반환sync() 모든 버퍼 내용(데이터와 메타데이터 모두) 을 디스크에 강제로 기록해서 동기화함. 최적화는 조금 부족void sync (void); 인자도 없고, 반환 값도 없음 → 항상 호출 성공O_SYNC 플래그 open() 호출 시 O_SYNC 플래그를 사용하면 모든 파일 입출력은 동기화 됨. (읽기는 언제나 동기화 됨. 하지만 write은 보통 동기화 되지 않음) write()가 작업 후 반환하기 직전에 fsync()를 매번 호출하는 방식이라고 이해해도 좋음. (실제로 리눅스 커널에서는 좀 더 효율적인 방식으로 구현하고 있지만 의미는 동일) Latency 가 조금씩 늘어남 → 입출력 동기화에 들어가는 비용이 매우 크기 때문에, 다른 대안을 모두 적용한 다음 최후의 선택으로 사용해야함 일반적으로 쓰기 작업이 디스크에 바로 기록되어야 하는 애플리케이션에서는 fsync()나 fdatasync()를 사용함. 이들은 호출 횟수가 적어서 O_SYNC보다 비용이 적게 듬.O_DSYNC와 O_RSYNC O_DSYNC는 메타데이터를 제외한 일반 데이터만 동기화 (fdatasync()와 동일) O_RSYNC는 쓰기뿐만 아니라 읽기까지도 동기화되도록 한다. read() 호출은 특별한 옵션 없이도 항상 동기화 되기 때문에 O_RSYNC 플래그가 특별히 필요하지 않다. 다만 최종적으로 사용자에게 넘겨줄 데이터가 생길 때 까지 반환되지 않음. 리눅스는 O_RSYNC를 O_SYNC와 동일하게 정의한다. 리눅스 구현상 이런 동작을 구현하기가 쉽지 않다고 한다. 2.5 직접 입출력 리눅스 커널은 디바이스와 애플리케이션 사이에 캐시, 버퍼링, 입출력 관리 같은 복잡한 계층을 구현하고 있음 성능이 중요한 애플리케이션에서는 우회해서 직접 입출력을 하고 싶을수도 있다. 일반적으로는 노력에 비해 효과가 낮다. 하지만 DB시스템은 독자적인 캐시를 선호하며 OS의 개입을 최소한으로 줄이기를 원함 O_DIRECT open()호출에서 O_DIRECT를 넘기면 커널이 입출력 관리를 최소화하도록 한다. 페이지 캐시를 우회해서 사용자 영역 버퍼에서 직접 디바이스로 입출력 작업을 시작한다. 모든 입출력은 동기식. 입출력 작업이 완료된 후에 호출이 반환 됨 2.6 파일 닫기int close (int fd); fd로 읽고 쓰는 작업을 마치면 close로 파일 맵핑을 끊어야한다. close()를 호출하면 fd에 연관된 파일과의 맵핑을 해제하며 프로세스에서 파일을 떼어낸다. 파일을 닫더라도 파일을 디스크에 강제로 쓰지 않는다는 점을 기억해야한다. 확실히 기록하려면 동기식 입출력 방법 중 하나를 써야함 에러 값 지연된 연산에 의한 에러는 한참 후에도 나타나지 않기 때문에 close()의 반환값을 검사해주는 것이 중요함. EBADF (파일 디스크립터가 유효하지 않음) EIO (저수준의 입출력에러)2.7 lseek()로 탐색하기 가끔 파일의 특정 위치로 직접 이동해야 할 필요가 있을 떄가 있다. lseek()을 사용하면 fd에 연결된 파일의 오프셋을 특정 값으로 지정할 수 있다. 파일 오프셋 갱신 외에 다른 동작은 하지 않고 어떤 입출력도 발생하지 않음.off_t lseek (int fd, off_t pos, int origin); origin SEEK_CUR fd의 파일 오프셋을 현재 오프셋에서 pos값을 더한 값으로 설정. pos값은 음수, 0, 양수 모두 가능 pos가 0이면 현재 파일 오프셋을 반환 SEEK_END fd의 파일 오프셋을 현재 오프셋에서 pos값을 더한 값으로 설정. pos값은 음수, 0, 양수 모두 가능 pos가 0이면 파일 오프셋을 현재 파일의 끝으로 설정 SEEK_SET fd의 파일 오프셋을 pos값으로 설정 pos가 0이면 파일 오프셋을 파일의 처음으로 설정 현재 파일 오프셋 찾기 lseek()은 갱신된 파일 오프셋을 반환하므로 lseek()에 SEEK_CUR와 0을 pos값으로 넘기면 현재 파일 오프셋을 찾을 수있다. pos = lseek (fd, 0, SEEK_CUR) 파일의 시작 혹은 끝 지점으로 오프셋을 이동하거나, 현재 오프셋을 알아내는데 많이 사용 됨!파일 끝을 넘어서 탐색하기 파일 끝을 넘어서도록 위치를 지정하는 것은 아무런 일도 발생하지 않음. 이때 read()를 하면 EOF반환 이때 write()를 하면 마지막 오프셋과 새로운 오프셋 사이에 새로운 공간이 만들어지며 0으로 채워짐 0으로 채운 공간을 구멍 (spare file)이라고 하는데, 이 구멍들은 물리적인 디스크 공간을 차지하지 않음→ 파일시스템에서 모든 파일을 합친 크기가 물리적인 디스크 크기보다 더 클 수 있음→ 이런 파일이 공간을 상당히 절약하며 효율을 크게 높일 수 있다.제약사항 파일 오프셋의 최댓값은 off_t의 크기에 제한됨. 커널은 내부적으로 오프셋 값을 C의 long long타입으로 저장 64비트 머신에서는 문제가 되지 않지만, 32비트 머신에서는 EOVERFLOW 에러 발생 가능 2.8 지정한 위치 읽고 쓰기ssize_t pread (int fd, void *buf, size_t count, off_t pos); pread()를 사용하면 fd에서 pos오프셋에 있는 데이터를 buf에 count 바이트만큼 읽는다.ssize_t pwrite (int fd, const void *buf, size_t count, off_t pos); pwrite()를 사용하면 buf에 담긴 데이터를 fd의 pos 오프셋에 count 파이트만큼 쓴다. 둘 모두 작업 후 파일 오프셋을 갱신하지 않는다. 둘 모두 현재 파일의 오프셋을 무시하며 pos로 지정한 오프셋을 사용한다는 점을 제외하고는 read()와 write() 시스템 콜과 거의 유사하게 동작한다. read() 나 write() 호출 전에 lseek()을 호출하는 방식과 유사하지만 3가지 차이점이 존재 작업 후 파일 오프셋을 원위치로 되돌리거나 임의의 오프셋에 접근해야 하는 경우 쉽게 사용가능 호출이 완료된 후 파일 포인터를 갱신하지 않음 lseek()를 사용할 때 발생할 수 있는 경쟁 상태를 피할 수 있다. lseek()은 본질적으로 여러 스레드에서 같은 fd를 처리할 경우 안전하지가 않음. race condition 발생 가능. 에러 값 두 함수는 호출이 성공하면 읽거나 쓴 바이트 개수를 반환함. pread() 0반환 : EOF pwrite() 0 반환 : 아무런 데이터도 쓰지 못했음 pread()는 read()와 lseek()에서 허용하는 errno 값을 설정 pwrite()는 write()와 lseek()에서 허용하는 errno 값을 설정2.9 파일 잘라내기파일을 특정 길이만큼 잘라내기 위한 시스템 콜int ftruncate (int fd, off_t len)int truncate (const char *path, off_t len); 두 시스템 콜은 모두 파일을 len 크기만큼 잘라낸다. ftruncate()는 쓰기 모드로 열린 fd에 대해 동작. truncate()는 쓰기 권한이 있는 파일 경로에 대해서 동작 성공 둘 다 0을 반환 에러 -1 반환, errno를 적절한 값으로 설정함. 호출이 성공하면 파일의 길이는 len이 된다. len과 자르기 전의 파일 크기 사이에 존재하던 데이터는 없어지고, read()를 통해 이 영역에 접근할 수 없게 됨.2.10 다중 입출력 논블록 입출력이 효과적이지 않은 두가지 이유 프로세스는 계속 열린 fd 중 하나가 입출력을 준비할 때까지 기다리면서 어떤 임의의 순서대로 입출력을 요청해야 한다. 프로세스를 재워 다른 작업을 처리하게 하고 fd가 입출력을 수행할 준비가 되면 깨우는 편이 더 효과적일 수 있음. 논블록 입출력으로 이것을 해결할 수 있지만 프로세스가 계속 깨워져있어야 한다는 단점이 존재한다. 다중 입출력은 애플리케이션이 여러개의 fd를 동시에 블록하고 그중 하나라도 블록되지 않고 읽고 쓸 준비가 되면 알려주는 기능을 제공 다중 입출력: fd 중 하나가 입출력이 가능할 때 알려준다. 준비가 됐나? 준비된 fd가 없다면 하나 이상의 fd가 준비될 때까지 잠든다. 깨어나기. 어떤 fd가 준비됐나? 블록하지 않고 모든 fd가 입출력을 준비하도록 관리한다. 1로 돌아가서 다시 시작한다. select()int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct *timeval *timeout);struct timeval { long tv_sec; long tv_usec;} select() 호출은 fd가 입출력을 수행할 준비가 되거나 옵션으로 정해진 시간이 경과할 때까지만 블록된다. 파라미터 n fd 집합에서 가장 큰 fd 숫자에 1을 더한 값 즉, fd에서 가장 큰 값이 무엇인지 알아내서 1 더해야 함. readfds 블록되지 않고 read()작업이 가능한지를 파악하기 위해 감시 writefds 블록되지 않고 write()작업이 가능한지를 파악하기 위해 감시 exceptfds 예외가 발생했거나 대역을 넘어서는 데이터 (이는 소켓에만 적용) 가 존재하는지 감시 → 어떤 집합이 NULL이면 해당 이벤트 감시하지 않음 timeout NULL이 아니면 입출력이 준비된 fd가 없을 경우에도 tv_sec, tv_usec 이후에 반환됨. 두 값이 모두 0이면 호출은 즉시 반환됨. 호출이 성공하면 각 집합은 요청받은 입출력 유형을 대상으로 입출력이 준비된 fd만 포함하도록 변경된다. ex) 7과 9인 두개의 fd가 readfds에 들어있다고 한다면 호출이 반환될 때 7이 집합에 남아있고 9가 남아있지 않다면, 7은 블록없이 읽기 가능! 9는 아마도 읽기 요청이 블록될 것임 select()에서 사용하는 fd집합은 직접 조작하지 않고 매크로를 사용해서 관리함FD_CLR(int fd, fd_set *set);FD_ISSET(int fd, fd_set *set);FD_SET(int fd, fd_set *set);FD_ZERO(fd_set *set); FD_ZERO 는 지정된 집합내의 모든 fd를 제거함. 항상 select() 호출 전에 사용해야함 FD_SET은 주어진 집합에 fd를 추가함 FD_CLR은 주어진 집합에서 fd를 하나 제거함 제대로 설계된 코드라면 FD_CLR을 사용할 일이 절대 없음! FD_ISSET은 fd가 주어진 집합에 존재하는지 검사 집합에 들어있다면 0이 아닌 정수 반환. 들어있지 않다면 0반환 반환값과 에러코드 호출 성공 전체 세 가지 집합 중에서 입출력이 준비된 fd개수를 반환함. timeout을 초과하면 반환값이 0이 될 수 있다. 에러 발생 -1 반환, errno 설정 select() 예제#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;sys/time.h&amp;gt;#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#define TIMEOUT 5#define BUF_LEN 1024int main() { struct timeval tv; fd_set readfds; int ret; // 표준 입력에서 입력을 기다리기 위한 준비를 합니다. FD_ZERO(&amp;amp;readfds); FD_SET(STDIN_FILENO, &amp;amp;readfds); // select가 5초 동안 기다리도록 timeval 구조체를 설정합니다. tv.tv_sec = TIMEOUT; tv.tv_usec = 0; // select() 시스템콜을 이용해 입력을 기다립니다. ret = select(STDIN_FILENO + 1, &amp;amp;readfds, NULL, NULL, &amp;amp;tv); if (ret == -1) { perror(&quot;select&quot;); return 1; } else if (!ret){ printf(&quot;%d seconds elapsed.\\n&quot;, TIMEOUT); return 0; } // select() 시스템콜이 양수를 반환했다면 &#39;블록(block)&#39;없이 즉시 읽기가 가능합니다. if (FD_ISSET(STDIN_FILENO, &amp;amp;readfds)) { char buf[BUF_LEN + 1]; int len; // &#39;블록(block)&#39;없이 읽기가 가능합니다. len = read(STDIN_FILENO, buf, BUF_LEN); if (len == -1) return 1; if (len) { buf[len] = &#39;\\0&#39;; printf(&quot;read: %s\\n&quot;, buf); } return 0; }}select()로 구현하는 이식 가능한 sleeptv.tv_sec = 0;tv.tv_usec = 500;select (0, NULL, NULL, NULL, &amp;amp;tv); 역사적으로 select()는 1초 미만의 짧은 시간 동안 프로세스를 재울 수 있는 더 나은 방법을 제공해왔음 최신 리눅스는 아주 짧은 시간 잠들기 인터페이스를 지원하고 있음pselect()int pselect (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct *timespec *timeout, const sigset_t *sigmask);struct timespec { long tv_sec; long tv_nsec;} select()와의 차이점 pselect()는 timeout 인자로 timeval 구조체 대신 timespec 구조체를 사용. 이는 초, 나노 초 조합을 사용하므로 이론적으로 더 짧은 시간 동안 잠들 수 있다. 하지만 실제로는 둘 다 마이크로 초도 확실히 지원하지 못함.. pselect()는 timeout 인자를 변경하지 않기 때문에 잇달은 호출 과정에서 timeout 인자를 계속 초기화해야 할 필요가 없다. select() 시스템 콜은 sigmask 인자를 받지 않는다. 이 인자는 NULL로 설정하면 pselect()는 select()와 동일하게 동작한다. pselect()가 추가된 이유 fd와 시그널을 기다리는 사이에 발생할 수 있는 race condition 을 해결하기 위한 sigmask 인자를 추가하기 위함이다. 블록할 시그널 목록을 인자로 받아서 select() 도중에 시그널이 도착하는 경우에도 이를 처리함. sigmask가 가리키는 신호마스크가 자동으로 설정되어 차단되고, pselect() 호출이 반환될 때는 신호마스크가 복원되어 실행하게 된다. poll() select()의 몇 가지 결점을 보완함. select()는 ‘읽기, 쓰기 예외’ 3가지를 독립적으로 설정하고 매개변수로 넘겨줘야했다. 하지만 poll은 구조체 배열을 사용함으로써 설계상으로도 훨씬 더 좋아졌음. 그럼에도 불구하고 여전히 습관이나 이식성의 이유료 select()를 더 많이 사용함int poll (struct pollfd *fds, nfds_t nfds, int timeout);struct pollfd { int fd; short events; short revents;}; fds가 가리키는 단일 pollfd 구조체 배열을 nfds 개수만큼 사용함. events 필드는 fd에서 감시할 이벤트의 비트마스크 를 의미 POLLIN - 읽을 데이터가 존재한다. 즉, 읽기가 블록(blokc)되지 않는다. POLLRDNORM - 일반 데이터를 읽을 수 있다. POLLRDBAND - 우선권이 있는 데이터를 읽을 수 있다. POLLPRI - 시급히 읽을 데이터가 존재한다. POLLOUT - 쓰기가 블록(block)되지 않는다. POLLWRNORM - 일반 데이터 쓰기가 블록(block)되지 않는다. POLLWRBAND - 우선권이 있는 데이터 쓰기가 블록(block)되지 않는다. POLLMSG - SIGPOLL 메시지가 사용 가능하다. events를 설정하면 등록한 이벤트 중 발생한 이벤트가 revents필드에 설정된다. revents 필드는 등록한 이벤트 중 발생된 이벤트 정보를 커널이 설정해줌. revents 필드에는 다음 이벤트가 설정될 수 있다. POLLER - 주어진 파일 디스크립터에 에러가 있다. POLLHUP - 주어진 파일 디스크립터에서 이벤트가 지체되고 있다. POLLNVAL - 주어진 파일 디스크립터가 유효하지 않다. 예제1 fd의 읽기와 쓰기를 감시하려면 events 를 POLLIN POLLOUT으로 설정 호출이 반환되면 pollfd 구조체 배열에서 원하는 fd가 들어있는 항목을 찾아 revents에 해당 플래그가 켜져있는지 확인한다. POLLIN 이 설정되어 있다면 읽기는 블록되지 않음. POLLOUT이 설정되어 있다면 쓰기는 블록되지 않는다. 예제2 #include &amp;lt;stdio.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;poll.h&amp;gt;#define TIMEOUT 5int main() { struct pollfd fds[2]; int ret; // 표준 입력에 대한 이벤트를 감시하기 위한 준비를 한다 fds[0].fd = STDIN_FILENO; fds[0].events = POLLIN; // 표준 출력에 쓰기가 가능한지 감시하기 위한 준비를 한다. fds[1].fd = STDOUT_FILENO; fds[1].events = POLLOUT; // 위에서 pollfd 구조체 설정을 모두 마쳤으니 poll() 시스템콜을 작동시킨다. ret = poll(fds, 2, TIMEOUT * 1000); if (ret == -1) { perror(&quot;poll&quot;); return 1; } if (!ret) {//타임아웃 printf(&quot;%d seconds elapsed.\\n&quot;, TIMEOUT); return 0; } if (fds[0].revents &amp;amp; POLLIN) printf(&quot;stdin is readable\\n&quot;); if (fds[1].revents &amp;amp; POLLOUT) printf(&quot;stdout is writeable\\n&quot;); return 0;} ppoll() ppoll()은 리눅스에서만 사용가능한 인터페이스 pselect() 처럼 timeout 인자는 나노 초 단위로 지정 가능하며 블록할 시그널 집합은 sigmask 인자로 제공poll()과 select() 비교 비슷한 작업을 하지만 poll은 select 보다 훨씬 유용함! poll은 가장 높은 파일 fd값에다가 1을 더해서 인자로 전달할 필요 없음 select에서 값이 900인 fd를 감시하게되면 매번 fd 집합에서 900번째 비트까지 일일히 검사해야함 select 의 fd 집합은 크기가 정해져있어서 트레이드 오프가 발생함. poll은 딱 맞는 크기의 fd 집합을 사용함 select 는 fd 집합을 반환하는 시점에서 재구성되므로 매번 fd 집합을 초기화해야함. poll은 event(입력), revent(출력)이 분리되어있다. select 의 timeout 인자는 반환하게 되면 미정의 상태가 됨. 2.11 커널 들여다보기가상 파일 시스템(VFS) 사용 중인 파일시스템이 무엇인지 몰라도 파일시스템 데이터를 처리하고 파일 시스템 함수를 호출할 수 있도록 하는 추상화 메커니즘 추상화를 위해서 리눅스에서 모든 파일시스템의 기초가 되는 공통 파일 모델을 제공함. 일반적인 시스템 콜(read, write) 등은 커널이 지원하는 어떠한 파일시스템이나 매체에서도 파일을 다룰 수 있다페이지 캐시 디스크 파일 시스템에서 최근에 접근한 데이터를 저장하는 메모리 저장소 메모리에 쓰기를 요청한 데이터를 저장하면 동일한 데이터에 대한 요청이 연이어 발생할 경우 커널은 반복적인 Disk 접근을 피해서 메모리에서 바로 처리할 수 있다. Temporal Locality 라는 개념을 활용함 특정 시점에서 리소스에 접근하면 오래 지나지 않은 장래에 다시 또 접근할 가능성이 높다는 이론 Sequential Locality 데이터가 순차적으로 참조됨을 뜻함 이를 활용하기 위해 페이지 캐시 미리 읽기를 구현하고 있음 커널이 파일시스템 데이터를 탐색하는 첫번째 장소가 페이지 캐시 이다. 동적으로 페이지 캐시 크기 변경 가능 메모리가 가득차게되면 페이지 캐시 중에서 가장 적게 사용한 페이지를 삭제해서 메모리를 확보한다. 이런 작업은 자동적으로 매끄럽게 일어남. 디스크 스왑과 캐시 삭제 간의 균형을 맞추는 데는 휴리스틱 기법을 사용함 페이지 쓰기 저장 커널은 버퍼를 통해 쓰기 작업을 지연시킨다. 쓰기 요청을 하면 버퍼로 데이터를 복사한 다음 버퍼에 변경 표시를 하여 디스크에 있는 복사본보다 메모리에 있는 복사본이 새롭다고 알려준다. 그러면 쓰기 요청은 바로 반환된다. 최종적으로 버퍼에 있는 내용이 디스크로 반영되어 디스크와 메모리에 있는 데이터가 동기화가 되어야하는데 이를 쓰기 저장이라고 한다. 두 가지 상황에서 발생함 여유 메모리가 설정된 경계 값 이하로 줄어들면 변경된 버퍼를 디스크에 기록한 다음, 버퍼를 삭제해서 메모리 공간을 확보한다. 설정된 값보다 오랫동안 유지된 버퍼는 디스크에 기록된다. 이는 변경된 버퍼가 무한정 메모리에만 남아있는 상황을 방지한다. 쓰기 저장은 Flusher 스레드 라고 하는 커널 스레드 무리에서 수행함2.12 마무리 가능한 모든 것을 파일로 표현하는 리눅스 같은 시스템에서는 어떻게 파일을 열고, 읽고, 쓰고, 닫는지 이해하는 것이 매우 중요하다. 이 모든 연산은 유닉스의 고전이며 여러 표준에 기술되어 있다." }, { "title": "[BlockChain] Blockchain Transaction flow", "url": "/posts/blockchain/", "categories": "Blockchain, Trouble Shooting", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-03-05 00:00:00 +0900", "snippet": "Blockchain Transaction flow1. 작동 시작만약 민지가 철수한테 비트코인을 보내고 싶어한다면, 민지는 비트코인이 저장되어있는 휴대폰이나 컴퓨터의 비트코인 지갑 어플을 열어볼것이다.(지갑 어플은 보통 공짜로 받을 수 있음)(비트코인이나 이더리움은 단순히 블록체인의 특정 기능을 이용한 암호화폐인데, 비트코인은 비트코인만 거래하고, 이더리움은 이더만 거래할 수 있음! 그러니깐 민지가 사용하는 지갑 어플은 비트코인 지갑일 것이다.)2. Smart Contract가 발동됨민지가 네트워크에 거래를 보내게 되면, 네트워크의 노드들이 smart contract를 발동한다. 근데 이제 그 smart contract가 어떤일을 하냐면, 민지가 사용할 수 있는 비트코인이 있는지 아니면 이미 다 써버렸는지를 확인한다.확인이 되면 그 거래는 제안된 블록(proposed block)에다가 추가된다.3. Operators가 Transaction을 뿌림제안된 블록이 이제 peer-to-peer 프로토콜을 통해서 네트워크에 뿌려진다4. 합의하기이제 블록체인 시스템에서 가장 중요한 부분이라고 볼 수 있는 지점이다.비트코인 네트워크에서 그 블록 (이전에 제안된 블록)을 검증하기 위해서, 노드들이나 채굴꾼들이 수학문제 (아주 어려운) 를 계산하면서 유효성 검사를 하게된다. 비트코인은 이러한 검증을 Proof of Work 라는 개념을 통해서 진행한다.(요 부분은 추후에 다시 다룰 예정. 비잔티움 장애 허용이라는 문제를 해결하기 위해서 비트코인이 제안한 방법)어쨌든 그 Proof of Work 의 수식을 가장먼저 해결한 노드는 새롭게 채굴된 비트코인을 보상받는다.일단 그 문제(수식)의 솔루션이 나오면 다른 노드들은 쉽게 이 제안된 노드가 정확한지 알 수 있게되고 새로운 블럭은 블록체인 네트워크에 추가된다5. 새로운 블록 뿌리기이 블록은 처음에 제안된 거래를 위해서 우리가 사용하는 peer-to-peer 커뮤니케이션을 통해 네트워크에다가 뿌려지게 된다.Block operator가 새로운 블록의 사본을 받게되면 분산 장부에다가 그 사본을 추가한다. 이건 현재 네트워크에 참여하고 있는 멤버들이 모두 현 상태에 대해서 동의한다는 것을 보장한다!6. 거래 완료사용자의 지갑은 사용자와 연관된 거래가 포함된 새로운 블록이 생성되는지를 계속 바라보고 있다. 사용자의 작동에 대한 코드가 포함된 블록이 있다는 것을 확인하게 되면, 그 사용자가 요청했던 동작이 수행되었다고 지갑이 알람을 보낸다.민지가 철수에게 비트코인을 전송한다는 내용을 담은 블록이 블록체인 시스템에 추가되면, 그 거래가 영향을 끼친 지갑에 알람을 보내줄 것이다.출처 : https://learning.edx.org/course/course-v1:LinuxFoundationX+LFS170x+2T2021/" }, { "title": "[Shell] Shell script에서의 특수문자 사용", "url": "/posts/tb-shell/", "categories": "Shell, Trouble Shooting", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-02-21 00:00:00 +0900", "snippet": "Shell script에서의 특수문자 사용Shell 스크립트를 이용해서 Mysql 데이터를 백업하는 mysqldump 작업 로직을 구성하고 싶었다.가장 간단하게 짜본 스크립트는 아래와 같다.#!/bin/bashHOST_BETA=&quot;HOST_BETA&quot;HOST_STAGE=&quot;HOST_STAGE&quot;HOST_PROD=&quot;HOST_PROD&quot;PORT=&quot;PORT&quot;USER=&quot;USER&quot;PASSWORD=&quot;PASSWORD&quot;DB=&quot;DB&quot;PHASE=$1if [ $1 = &quot;beta&quot; ]; then echo &quot;mysqldump -h$HOST_BETA -P$PORT -u$USER -p$PASSWORD --single-transaction --default-character-set=utf8 --extended-insert=FALSE $DB &amp;gt; ./log/$(date +\\%Y\\%m\\%d)_${DB}_$PHASE.sql&quot; `mysqldump -h$HOST_BETA -P$PORT -u$USER -p$PASSWORD --single-transaction --default-character-set=utf8 --extended-insert=FALSE $DB &amp;gt; ./log/$(date +\\%Y\\%m\\%d)_${DB}_$PHASE.sql`elif [ $1 = &quot;stage&quot; ]; then echo &quot;mysqldump -h$HOST_STAGE -P$PORT -u$USER -p$PASSWORD --single-transaction --default-character-set=utf8 --extended-insert=FALSE $DB &amp;gt; ./log/$(date +\\%Y\\%m\\%d)_${DB}_$PHASE.sql&quot; `mysqldump -h$HOST_STAGE -P$PORT -u$USER -p$PASSWORD --single-transaction --default-character-set=utf8 --extended-insert=FALSE $DB &amp;gt; ./log/$(date +\\%Y\\%m\\%d)_${DB}_$PHASE.sql`elif [ $1 = &quot;prod&quot; ]; then echo &quot;mysqldump -h$HOST_STAGE -P$PORT -u$USER -p$PASSWORD --single-transaction --default-character-set=utf8 --extended-insert=FALSE $DB &amp;gt; ./log/$(date +\\%Y\\%m\\%d)_${DB}_$PHASE.sql&quot; `mysqldump -h$HOST_PROD -P$PORT -u$USER -p$PASSWORD --single-transaction --default-character-set=utf8 --extended-insert=FALSE $DB &amp;gt; ./log/$(date +\\%Y\\%m\\%d)_${DB}_$PHASE.sql`else echo &quot;Usage:&quot; echo &quot;(phase:beta or stage or prod)&quot; exit 0fi그런데 자꾸mysqldump: Got error: 1045: Access denied for user &#39;USER&#39;@&#39;host&#39; (using password: YES) when trying to connec접속 에러가 발생하는 것었다.분명 echo로 나오는 커맨드를 터미널에서 직접 입력했을때는 잘 작동이 되었는데, shell script를 실행했을 때는 에러가 발생했다.Trouble Shooting 1. shell script ip 문제?처음에는 에러 메시지에서 host로 나오는 ip가 나의 localhost ip가 아니고ifconfigutun2: flags=8051&amp;lt;UP,POINTOPOINT,RUNNING,MULTICAST&amp;gt; mtu 1400 inet HOST --&amp;gt; HOST netmask 0xffffffffifconfig 명령어를 쳤을 때 마지막에 나오는 utun2 가상 인터페이스 호스트가 에러 메시지에 나오길래 shell script에서 가져오는 현재 아이피가 다른 것이라서 MySQL 연결이 안되는건가? 라고 생각을 했다.하지만 MySQL의 mysql 디비에서 user 접근 권한을 확인해봤더니mysql&amp;gt; use mysql;mysql&amp;gt; select host,user from user;+-----------+------------------+| host | user |+-----------+------------------+| % | USER |+-----------+------------------+요런식으로 ‘USER’@’%’ 모든 ip에서 접속 가능하도록 등록이 되어있었다.이 에러는 원인이 아니었다.Trouble Shooting 2. 특수문자 문제?MySQL 접속 비밀번호에는 특수문자가 포함되어있다.터미널에서 mysql에 접속하는 커맨드를 이용할 때 비밀번호에 특수문자가 포함되어있다면 \\를 앞에 넣어줘야한다.예를 들어, 비밀번호가 123!@#이라면mysql -h HOST -P PORT -u USER -p123\\!\\@\\# DB이런식으로 특수문자 앞에 \\를 넣어줘야 인식이 된다.예시$ echo (&amp;gt;$ echo \\((그래서 나는 스크립트에도 같은 식으로 패스워드를 넣었다.그런데 shell 에서는 특수문자를 받을 수 있어서 \\라는 문자를 그대로 받아버려서 비밀번호 에러가 발생한 것이었다.참고 stackoverflow에서 보면 알 수 있듯이, &quot;&quot; 이런식으로 쌍따옴표를 이용해서 감싸기도 하나보다.어쨌든 terminal에서는 \\를 붙여서 특수문자 표기를 하지만 shell에서는 그렇지 않다." }, { "title": "[SQLalchemy] NULL 조회 ", "url": "/posts/tb02-sqlalchemy/", "categories": "SQLalchemy, Trouble Shooting", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-02-17 00:00:00 +0900", "snippet": "SQLalchemy에서의 NULL 조회cluster_item = self.db.query(Cluster)\\ .filter((Cluster.userid.is_(None)) &amp;amp; (Cluster.domain.is_(None)))\\ .order_by(Cluster.id).first()위와 같이 NULL을 조회했었는데, 정상적으로 조회가 되지 않았다.살펴보니 방법이 달랐다.NULL 조회시userid is None으로 하면 안된다.userid == None# ORuserid.is_(None)이렇게 해야한다.두개 이상 키의 NULL을 찾고 싶을 때userid.is_(None) and domain.is_(None)and로 묶으면 안된다..filter((Cluster.userid.is_(None)) &amp;amp; (Cluster.domain.is_(None)))이런식으로 구분해줘야 한다.참고 : https://veluxer62.github.io/explanation/sqlalchemy-filter-is-null/" }, { "title": "[Kubernetes] Kubernetes 서비스 정리(ClusterIP, Nodeport, Loadbalancer) ", "url": "/posts/k8s_service/", "categories": "Trouble Shooting", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-02-14 00:00:00 +0900", "snippet": "Kubernetes ServiceClusterIP말 그대로 클러스터 내부에서 사용하는 IP클러스터 내부의 노드나 파드에서는 ClusterIP를 이용해서 서비스에 연결된 각 파드들에 접근한다.하지만 외부에서는 이 IP로 접근 불가능apiVersion: v1kind: Servicemetadata: name: testspec: ports: - port: 8080 protocol: TCP targetPort: 8080 selector: app: testport 로 접근 시 targetport 로 리다이렉팅NodePort클러스터 내부외 외부 모두 접근이 가능하다.Nodeport는 클러스터의 모든 노드에 특정 포트를 열어두고 어떤 노드에 접근하든지 모두 다 포트 포워딩을 해준다.apiVersion: v1kind: Servicemetadata: name: testspec: selector: app: test type: NodePort ports: - name: 30088-5000 nodePort: 30088 # 서비스가 클러스터 외부로 노출하는 포트 protocol: TCP port: 30001 # 서비스가 클러스터 내부로 오픈하는 포트 targetPort: 5000 # 타겟 파드에 요청을 보내는 포트즉, 외부에서 30088로 접근하면 30001로 포트포워딩 되고 다시 5000번으로 포트 포워딩 됨.LoadbalancerNodeport + ClusterIP 라고 보면 될 것 같다.LoadBalancer: 클라우드 공급자의 로드 밸런서를 사용하여 서비스를 외부에 노출시킨다. 외부 로드 밸런서가 라우팅되는 NodePort와 ClusterIP 서비스가 자동으로 생성된다.(요 부분은 혹시 틀린 내용이 있다면 지적부탁드립니다.)이전 ClusterIP, Nodeport 와는 다르게 External IP가 생성된다. 이를 통해서 외부에서 접근이 가능함.Nodeport의 확장판이라고 생각할 수 있는데, 외부에 노출이 가능하다는 점이 가장 큰 차이점이다. 또한 Nodeport 앞단에 Loadbalancer가 붙어서 헬스체크를 하면서 알고리즘을 통해 트래픽을 전달한다.kind: ServiceapiVersion: v1metadata: name: test annotations: service.beta.kubernetes.io/openstack-internal-load-balancer: &quot;true&quot;spec: selector: app: test type: LoadBalancer ports: - name: http1 port: 30080 targetPort: 5000 - name: http2 port: 30081 targetPort: 5000 - name: http3 port: 30082 targetPort: 5000get svc 를 하게 되면 LoadBalancer의 External IP와 Ports가 나오게된다.NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S)service/test LoadBalancer &amp;lt;CLUSTER-ip&amp;gt; &amp;lt;external-ip&amp;gt; 30080:30352/TCP,30081:31824/TCP,30082:31996/TCP근데 yaml에서 30352 포트를 사용한적이 없는데 Ports에서 30080:30352 라고 나온다.이게 무엇인고 하니, 위의 그림처럼 LoadBalancer를 만들게 되면 자동으로 Nodeport가 생성이 된다.그래서 아래와 같이 describe service를 하게 되면 Nodeport 가 연결되어있는 것을 확인할 수 있다.Name: default-testNamespace: defaultLabels: &amp;lt;none&amp;gt;Annotations: service.beta.kubernetes.io/openstack-internal-load-balancer: trueSelector: app=testType: LoadBalancerPort: http1 30080/TCPTargetPort: 5000/TCPNodePort: http1 30352/TCPPort: http2 30081/TCPTargetPort: 5000/TCPNodePort: http2 31824/TCPPort: http3 30082/TCPTargetPort: 5000/TCPNodePort: http3 31996/TCPSession Affinity: NoneExternal Traffic Policy: ClusterEvents: &amp;lt;none&amp;gt;describe 해서 나온 값들을 보면Port: http1 30080/TCPTargetPort: 5000/TCPNodePort: http1 30352/TCP요렇게 되어있다.즉, 30080 -&amp;gt; 30352 -&amp;gt; 5000 이렇게 리다이렉팅이 된다는 의미이다!참고 : https://nearhome.tistory.com/95 , https://ooeunz.tistory.com/123, https://kim-dragon.tistory.com/52" }, { "title": "[Docker] Centos Image 에서 sudo command not found 에러", "url": "/posts/docker/", "categories": "Trouble Shooting, Docker", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, GitHub Pages", "date": "2022-02-07 00:00:00 +0900", "snippet": "Centos Image 에서 sudo command not foundcentos/python-36-centos7 이미지 사용 도중Dockerfile 내부에서 커맨드로 파일의 모드를 바꿔야할 일이 생겼다.RUN sudo chmod 755 start.sh근데 sudo 를 실행했을 떄 /bin/sh: sudo: command not found요런 에러가 발생한다.ubuntu 의 경우는 apt-get update 명령어를 통해 업데이트를 진행하면 되지만, centos의 경우는 yum update 또한 sudo 명령어가 필요하다.su -s 또한 password를 요구하기 때문에User 를 root 로 접속하여서 sudo 를 다운받았다.USER rootRUN yum install -y sudoRUN sudoUSER 명령어가 없다면, 기본적으로 default 유저로 접속이 된다.별 것 아니지만, 누군가에겐 도움이 되길 바란다!ps. 근데 root 접속이 가능하다면, 굳이 sudo 다운받지 않고 그냥 커맨드 실행하면 된다.." }, { "title": "[Linux] Sudoer 및 sudo 사용하기. sudo passwd 실행 안될 때", "url": "/posts/sudoer/", "categories": "Linux, Centos", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-02-03 00:00:00 +0900", "snippet": "Sudoer 및 sudo 사용하기root 권한root 는 일반적으로 unix에 존재하는 특권 사용자의 이름을 의미하는데 모든 권한을 가지고 있다고 보면 되겠다.매우 강력하여 편리하게 보이지만 위험할 수 있기 때문에 모든 계정에 root 권한을 주지는 않는다.일반 계정이 sudo 명령어로 root 권한을 가진 채 커맨드를 이용하기 위해서는 sudoer 파일에 필요한 부분을 적어서 사용하게 된다.Sudoer란sudoer란 일반 계정이 sudo 명령어를 사용해서 임시로 root 권한을 얻어 이용할 수 있는 것을 의미한다.또한 root 권한을 계정에 부여할 수도 있다.파일의 위치는 /etc/sudoers 이다.예를 들어deploy ALL=NOPASSWD: ALL, !/bin/su, !/sbin/reboot, !/usr/bin/reboot, !/sbin/shutdown, !/sbin/halt, !/usr/bin/halt, !/sbin/poweroff, !/usr/bin/poweroff, !/sbin/init, !/usr/sbin/adduser, !/usr/sbin/useradd, !/usr/sbin/userdel, !/sbin/iptables, !/usr/bin/passwd이런식으로 deploy 계정에 대해 사용할 수 있는 커맨드와 사용할 수 없는 커맨드들이 적혀있다.앞에 ! 느낌표가 붙은 커맨드는 sudo 명령어로 사용하게 되면 아래처럼 에러 문구가 발생한다.죄송하지만 deploy 사용자는 &#39;/usr/sbin/useradd TEST&#39;을(를) root(으)로 실행하도록 허가받지 않았습니다.sudo -s-s (–shell) 옵션은 쉘을 의미한다.즉, root 권한을 가진 shell을 새롭게 연다는 것이다.sudo passwd (*) 실행 안될 때/etc/sudoers 에서 deploy 계정의 경우 !/usr/bin/passwd 이렇게 passwd 명령어를 sudo 로 사용할 수 없게 막혀있는 것을 확인할 수 있다.[deploy@ ~]$ sudo passwd-&amp;gt; 죄송하지만 deploy 사용자는 &#39;/usr/bin/passwd&#39;을(를) root(으)로 실행하도록 허가받지 않았습니다.[deploy@ ~]$ sudo -s[root@ ~]# sudo passwd-&amp;gt; root 사용자의 비밀 번호 변경 중-&amp;gt; 새 암호:요런식으로 sudo (명령어) 로는 안되지만, sudo -s 옵션으로 들어가서는 되는 것을 확인할 수 있다." }, { "title": "[MySQL] == NULL 값 조회 안되는 이슈 ", "url": "/posts/mysql/", "categories": "Trouble Shooting, MySQL", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-01-21 00:00:00 +0900", "snippet": "[MySQL] == NULL 값 조회 안되는 이슈MySQL 쿼리문을 작성할 때 필드 값이 NULL인 Row를 조회하고 싶을 때가 있다.근데 아무 생각 없이SELECT * FROM your_table WHERE your_field = NULL이라고 썼더니 조회가 안된다.결론부터 이야기하자면SELECT * FROM your_table WHERE your_field IS NULLNULL은 요런식으로 IS 혹은 IS NOT 문을 사용해서 조회해야한다.이제부터 그 이유를 알아보자.MySQL에서 NULL의 의미NULL은 놓친 알 수 없는 값을 의미한다. 그리고 NULL은 다른 값들과는 다르게 대우된다.NULL을 테스트 해보기 위해서 IS NULL 과 IS NOT NULL을 아래와 같이 실행해보면mysql&amp;gt; SELECT 1 IS NULL, 1 IS NOT NULL;+-----------+---------------+| 1 IS NULL | 1 IS NOT NULL |+-----------+---------------+| 0 | 1 |+-----------+---------------+이렇게 나온다.아래의 테스트에서 볼 수 있듯이 수학적인 기호 (=, &amp;lt;, &amp;lt;&amp;gt;) 이런 것들은 쓸 수가 없다. &amp;lt;&amp;gt; 는 not equal을 의미한다.mysql&amp;gt; SELECT 1 = NULL, 1 &amp;lt;&amp;gt; NULL, 1 &amp;lt; NULL, 1 &amp;gt; NULL;+----------+-----------+----------+----------+| 1 = NULL | 1 &amp;lt;&amp;gt; NULL | 1 &amp;lt; NULL | 1 &amp;gt; NULL |+----------+-----------+----------+----------+| NULL | NULL | NULL | NULL |+----------+-----------+----------+----------+왜 NULL에는 수학적 기호를 사용하지 못할까?왜나하면 NULL의 수학적 비교 값은 여전히 NULL이기 때문이다. 이러한 비교를 통해서는 여전히 어떠한 의미있는 값을 얻을 수가 없다.MySQL에서는 0 혹은 NULL은 false를 의미하고 다른 값들은 true를 의미한다.boolean 연산에서 기본적인 true 값은 1이다.일반적인 에러는 NOT NULL인 칼럼에 0 혹은 빈 문자열 &#39;&#39;이 못들어간다고 생각하는데 그렇지 않다.NULL은 값이 없다 라는 의미이긴 하지만 사실 값은 값이다…mysql&amp;gt; SELECT 0 IS NULL, 0 IS NOT NULL, &#39;&#39; IS NULL, &#39;&#39; IS NOT NULL;+-----------+---------------+------------+----------------+| 0 IS NULL | 0 IS NOT NULL | &#39;&#39; IS NULL | &#39;&#39; IS NOT NULL |+-----------+---------------+------------+----------------+| 0 | 1 | 0 | 1 |+-----------+---------------+------------+----------------+-&amp;gt;조금 말이 어렵긴한데,,,(NULL에 대해서는 꽤 많은 문제점들이 시사되고 있다.) 어쨌든 NULL에다가 수학적 비교를 하게 되면 그 값 또한 NULL이 되기 때문에 WHERE 문에서 적용이 안된다. 따라서 IS NULL 혹은 IS NOT NULL 과 같은 구체적인 비교 구문으로 값을 찾아야한다.원문 참조 : https://dev.mysql.com/doc/refman/8.0/en/working-with-null.html" }, { "title": "[Crontab] [Tip] Crontab 이슈 해결 ", "url": "/posts/crontabl/", "categories": "Trouble Shooting, crontab", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-01-20 00:00:00 +0900", "snippet": "[Crontab] [Tip] Crontab 이슈 해결crontab 을 써보면서 겪었던 몇 가지 이슈를 해결하는 과정을 기록하려 한다.자주 사용하시는 분들은 당연하게 생각하는 것들을 몰랐던 나는 검색을 통해 해결했는데, trouble shooting 을 하는 다른 분들께도 도움이 되었으면 좋겠다.Permission denied*/30 * * * * ./my.sh이런식으로 crontab을 30분 간격으로 실행되도록 등록했다.그런데 아무런 변화가 없었다.그래서 로그를 살펴보았다.Crontab log/var/log/cron 에 기록이 되며 root 권한이기 때문에sudo tail -f /var/log/cron이런식으로 확인하면 되겠다.그런데 나같은 경우는 파일의 권한이 -rw-r–r–.(744) 로 되어있었는데, 이 부분을 755로 변경해주니 permission denied 이슈는 해결되었다.Crontab 실행 shell 로그 찍기permission denied 는 해결하였는데, 계속 실행이 안되었다.그래서 crontab으로 실행하는 쉘 스크립트의 로그를 찍어보았다.요 부분은(crontab -e)*/30 * * * * ./my.sh &amp;gt;&amp;gt; {LOG_DIR}/cron.log 2&amp;gt;&amp;amp;1이런식으로 로그를 직접 저장을 하면서 확인을 하면 되겠다.그래서 내가 확인한 이슈는 다음과 같다.Command not foundkubectl not found현재 수행하는 로직은 Crontab -&amp;gt; Shell -&amp;gt; Python 을 수행하고 있다. Python 에서는 subprocess call을 통해서 kubectl을 불러오는데, 이 부분에서 command not found 에러가 발생하였다.이유는 이러하다. 우리가 서버를 접속하거나 탭을 켜게 되면 자동으로 ~/.bash_profile 혹은 ~/.bashrc 가 실행이 된다. 이를 통해서 필요한 환경변수들을 불러오게 된다. 하지만 crontab을 통한 실행에서는 환경변수를 가지고 가지 않는다. 따라서 여러 가지 환경변수들을 crontab에 직접 저장을 해주어야한다. 대표적으로 /usr/local/bin 이 그러하다. crontab 의 기본 PATH는 /usr/bin이다. 즉, /usr/local/bin 등 다른 경로에 있는 command에 대해서는 crontab이 인식하지 못한다.$ which kubectl$ /usr/local/bin/kubectl이라고 뜨는 것을 확인할 수 있다.따라서 아래처럼 crontab -e 를 통해 편집 탭에서 환경변수를 직접 넣어주어야한다.PATH=/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/binLD_LIBRARY_PATH=/usr/local/lib* * * * * my_command.sh some_argsPython 로그 안찍힘마지막으로는 Python 로그가 찍히지 않는 이슈이다.위에서 언급한 것 처럼 나는 Crontab -&amp;gt; Shell -&amp;gt; Python 로 작업을 수행했는데, Python 에서 loguru 모듈을 통해 찍고 있는 로그가 저장이 안되는 이슈가 발생하였다.아마 crontab에서 수행하다 보니 경로가 꼬인 것으로 확인되는데,,, 그래서 나는 그냥 crontab의 결과 값을 다시 한번 로그로 저장하도록 구현했다.* * * * * my_command.sh &amp;gt;&amp;gt; {LOG_DIR}/logs/cron_$(date +\\%Y\\%m\\%d\\%H\\%M\\%S).log 2&amp;gt;&amp;amp;1로그가 찍힐 때의 날짜 및 시간을 저장하기 위해서 Shell 스크립트 문법인 $(date +\\%Y\\%m\\%d\\%H\\%M\\%S) date를 사용하였다. 요 부분은 디렉토리가 꼬여서 저장이 안되고 있었던 것으로 확인되었다. 즉, 정상적으로 파이썬 로그는 찍힘." }, { "title": "[MongoDB] MongoDB 버전차이 연결 실패 에러 ", "url": "/posts/mongo/", "categories": "Trouble Shooting, MongoDB", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-01-14 00:00:00 +0900", "snippet": "MongoDB 버전차이 연결 실패 에러서버와 서버 사이 ACL은 telnet으로 확인했을 때 접속이 잘 되었다.하지만 몽고디비 접속이 안되었다.접속 커맨드$ mongo --host db_name/IP01:27017,IP02:27017,IP03:27017 --username name --password --authenticationDatabase DB_name DB_nameMongoDB shell version v3.4.13Enter password:에러로그connecting to: mongodb://IP01:27017,IP02:27017,IP03:27017/DB_name?replicaSet=DB_name2022-01-14T09:51:00.815+0000 I NETWORK [thread1] Starting new replica set monitor for DB_name/IP01:27017,IP02:27017,IP03:270172022-01-14T09:51:00.817+0000 I NETWORK [ReplicaSetMonitor-TaskExecutor-0] Successfully connected to IP01:27017 (1 connections now open to IP01:27017 with a 5 second timeout)2022-01-14T09:51:00.817+0000 I NETWORK [thread1] Successfully connected to IP02:27017 (1 connections now open to IP02:27017 with a 5 second timeout)2022-01-14T09:51:00.843+0000 I NETWORK [thread1] Detected bad connection created at 1642153860816699 microSec, clearing pool for IP02:27017 of 0 connections2022-01-14T09:51:00.843+0000 I NETWORK [thread1] Dropping all pooled connections to IP02:27017(with timeout of 5 seconds)2022-01-14T09:51:00.843+0000 I NETWORK [thread1] Ending connection to host IP02:27017(with timeout of 5 seconds) due to bad connection status; 0 connections to that host remain open2022-01-14T09:51:00.843+0000 I NETWORK [ReplicaSetMonitor-TaskExecutor-0] Detected bad connection created at 1642153860816672 microSec, clearing pool for IP03:27017 of 0 connections2022-01-14T09:51:00.843+0000 I NETWORK [ReplicaSetMonitor-TaskExecutor-0] Dropping all pooled connections to IP03:27017(with timeout of 5 seconds)2022-01-14T09:51:00.843+0000 I NETWORK [ReplicaSetMonitor-TaskExecutor-0] Ending connection to host IP03:27017(with timeout of 5 seconds) due to bad connection status; 0 connections to that host remain open처음에는 방화벽 문제인 줄 알았으나, 에러로그를 살펴보면 Connection은 처음에 성공적으로 확인되는 것을 볼 수 있다.혹시 몰라서 MongoDB 서버의 버전과 클라이언트의 MongoDB 버전을 확인해봤더니 차이가 좀 났다.Original Client Version$ mongo --versionMongoDB shell version v3.4.13git version: fbdef2ccc53e0fcc9afb570063633d992b2aae42OpenSSL version: OpenSSL 1.0.1e-fips 11 Feb 2013allocator: tcmallocmodules: nonebuild environment:distmod: rhel70distarch: x86_64target_arch: x86_64Updated Client Version$ mongo --versionMongoDB shell version v5.0.5Build Info: {&quot;version&quot;: &quot;5.0.5&quot;,&quot;gitVersion&quot;: &quot;d65fd89df3fc039b5c55933c0f71d647a54510ae&quot;,&quot;openSSLVersion&quot;: &quot;OpenSSL 1.0.1e-fips 11 Feb 2013&quot;,&quot;modules&quot;: [],&quot;allocator&quot;: &quot;tcmalloc&quot;,&quot;environment&quot;: {&quot;distmod&quot;: &quot;rhel70&quot;,&quot;distarch&quot;: &quot;x86_64&quot;,&quot;target_arch&quot;: &quot;x86_64&quot;}}Destination MongoDB Server version$ mongo --versionMongoDB shell version v4.2.14git version: 0e6db36e92d82cc81cbd40ffd607eae88dc1f09dOpenSSL version: OpenSSL 1.0.1e-fips 11 Feb 2013allocator: tcmallocmodules: nonebuild environment:distmod: rhel70distarch: x86_64target_arch: x86_64MongoDB 서버의 버전은 4.2버전대였고, 접속 시도한 클라이언트의 버전은 3.4버전대였다.둘 사이의 버전 차이가 커서 접속에 실패했던 부분이었다.클라이언트를 5.0으로 업데이트하니 문제가 해결되었다.참고 : https://www.mongodb.com/community/forums/t/unable-to-connect-to-cluster-no-primary-detected/90700/17" }, { "title": "[독서][부의 추월차선] 부의 추월차선은 어떻게 갈 수 있을까 ", "url": "/posts/book01/", "categories": "Book", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-01-08 00:00:00 +0900", "snippet": "[독서][부의 추월차선] 부의 추월차선은 어떻게 갈 수 있을까제목부터 상당히 자극적이다.부의 추월차선고속도로는 일반적으로 차선의 용도가 정해져있다.4차선 도로를 예로 든다면 4차선은 화물차량용, 2, 3차선은 서행차선용, 1차선은 추월차선으로 이용된다.천천히 달리고 싶은 차들은 2, 3차선에서 적정속도로 달린다.하지만 더 빠르게 가고 싶은 차들은 1차선에서 다른 차들을 추월하며 달린다.부의 추월차선. 과연 부에도 추월차선이 있어서 우리가 그 도로로 달린다면 서행하지 않고 빠르게 갈 수 있을까.그런 생각이 가장 먼저 든 책이었다.부자가 되겠다는 생각을 항상 하고 있는 나로서는 굉장히 매력적인 책 표지였다.이 책에서는 기본적으로 삶의 지도에는 인도, 서행차선, 추월차선이 존재한다고 이야기한다.부자가 되기 위해서는 추월차선에서 빠르게 달려야만 하고 인도와 서행차선으로 달렸을 경우 부자가 될 수 있는 확률은 희박하다고 말한다.가장 흥미로웠던 것은 추월차선을 통해서 빠르게 부자가 되는 것이 가능하다는 것을 증명하기 위해 부의 방정식을 제시했다.부의 방정식부에는 방정식이 있다. 하지만 자신이 위치한 차선에 따라서 방정식이 바뀐다.인도의 부의 방정식 부 = 소득 + 빚인도를 달리는 사람들은 현재를 사는 사람들이다. 미래에 대한 생각 없이 현재를 즐기며 살아간다.따라서 미래에 본인이 짊어질 부담인 빚을 계속해서 만들며 현재를 더 풍족하게 시간을 보낸다.서행차선의 부의 방정식 부 = (주요 수입원 : 직업) + (부의 증식방법 : 투자)일반적인 사람들이 살아가는 방식이다.현재를 희생하며 안정된 미래를 꿈꾼다.서행차선의 부의 방적식은 다시 말해원금가치 + 복리 이자로 해석할 수 있다.즉, 원금 가치는 자신의 능력 X 일할 수 있는 시간이 되고,복리 이자는 투자 자금으로 투자를 통해 얻을 수 있는 가치가 된다.하지만 이 책에서는 서행차선의 부의 방정식은 매우 오랜 시간이 걸리고 확률 또한 희박하다고 이야기한다.우리는 부자가 되기를 원한다. 하지만 60대가 넘어 하고 싶은 일들을 쉽게 하지 못하는 때에 부자가 되는 것보다 몇 십년 더 젋을 때, 혈기가 왕성할 떄 부자가 되는 것이 더 좋다는 것은 당연한다.서행차선으로 달리면 빠른 시간에 부자가 되는 것은 매우 힘들다.복리 이자가 적어도 5% 이상의 이익을 매번 기록한다는 것도 확률적인 부분에 우리의 미래를 건다고 볼 수 있다.원금가치를 자신의 능력 X 일할 수 있는 시간 라고 이야기 했다.여기서 우리가 변화시킬 수 있는 변수는 두 가지이다.자신의 능력을 변화시키는 것과 일할 수 있는 시간을 변화시키는 것.먼저 일할 수 있는 시간를 보자.이것은 아주 한정적이다. 일반적으로 우리는 주 40시간을 일한다. 우리의 능력이 정해져있다면 우리는 일할 수 있는 시간을 늘려야하는데, 24시간의 시간적 흐름에 존재하는 우리는 매우 한정적인 시간이라는 변수를 가지고 있다.그렇다면 자신의 능력을 극대화한다면? 맞다. 부자가 될 수 있다.예를 들어 매우 뛰어난 운동선수가 되거나 (르브론 제임스, 메시,,,,) 아주 뛰어난 끼로 연예인이 되거나 한가지 분야에서 탁월한 능력을 보이면 가능한 부분이다.하지만 이런 사람들은 우리가 이야기하는 내용의 요지에서 벗어난 사람들이다.여기서는 우리 같이 평범하고 일반적인 사람들을 기준으로 이야기하고 있다.즉, 우리는 서행차선에서 우리 삶의 통제력을 본인이 가지고 있는 것이 아니라 시간과 운이라는 외부에 맡기고 있는 셈이다.추월차선의 부의 방정식추월차선과 서행차선의 가장 큰 차이점은 통제권을 누가 가지고 있느냐이다.추월차선을 달리는 사람은 통제권을 본인이 가지고 있다.변수 또한 무한대로 늘어날 수 있다. 따라서 빠르게 부자되는 것이 가능하다.하지만 빠르게 부자가 된다는 것은 쉽게 부자가 된다는 것은 절대 아니다.결과가 있기 위해서는 과정이 분명히 존재한다. 그 과정은 매우 고되고 힘들 수 있다. 하지만 우리가 바라는 결과를 위해서는 그런 과정을 겪는 것을 즐길 수 있어야 한다.우리는 삶을 소비자로서 사는 것이 아닌 생산자로서 살아가야한다.살아가면서 사용하는 여러 소비재들, 음식 그리고 서비스들을 단순히 소모하고 이용하는 소비자의 마인드가 아니라 그것들을 어떻게 경쟁력있게 제공하고 고객들을 끌어당길 수 있는지에 대해 생각을 하며 살아가야한다.추월차선의 부의 방정식은 이러하다. 부 = 순이익 + 자산 가치순이익 = 판매 개수 X 단위당 이익자산 가치 = 순이익 X 산업 승수사실상 추월차선은 본인의 사업을 하지 않고서는 달릴 수 없다.순이익이란 자신이 판매하는 사업 아이템을 얼마나 이익을 보면서 많이 파는가에 대한 내용이다.자산 가치는 본인 사업의 가치에 대한 이야기를 하는 것이다.서행차선의 한계가 있는 변수와는 다르게 추월차선에서의 변수들은 한계가 없다. 몇개나 파는지는 사업의 종류에 따라 다르지만 무한정 늘릴 수 있다. 이익 또한 어떻게 구성하냐에 따라서 무한히 늘어날 수 있다.정리내가 아직 더 큰 세상을 경험하지 못해서 그런 것일 수도 있겠지만, R = VD는 성공 공식에 대해서 어디에서나 나오는 이야기인 듯 하다.지각을 바꾸면 미래의 행동이 바뀐다 거나 본인이 생각하는 마음가짐을 확신에 찬 어조로 바꾼다면 다가올 상황이 바뀐다거나…이 모든 것은 시크릿이야기로 흘러들어간다.될 수 있다고 믿고, 할 수 있다고 믿어라.이미 그렇게 되었다고 생각을 하라.시각화를 통해 더 실감나고 생생한 상상을 하라.이 모든 것들은 시크릿 내용이다.이 우리가 과학적으로 밝혀내지 못한 외부의 흐름들을 우리는 어떻게 받아들여야 할까.사실 나는 믿거나 말거나라고 생각한다.이 또한 종교와 닮아있다. 종교도 어떤이에게는 매우 유익할 것이다. 의지할 곳 없는 사람이 기댈 수 있는 안식처를 제공해주니깐.하나의 철학인 것이다.자신의 흔들리지 않는 철학적인 뼈대가 없다면 어디든 잡아야한다. 그게 종교가 될 수도 있고, 시크릿의 철학이 될 수 있다.하지만 그 철학을 믿음으로서 남에게 피해를 끼친다면 지금 이야기하려는 내용에서 벗어난 것일테니 번외로 하겠다.부자가 되는 것 또한 그렇다.나는 이미 부자다.삼성역 근처 람보르기니 매장에서 노란색 우라칸을 계약하고 강남대로를 쌩하고 달리는 내 모습이 보인다.이런 결과를 위해서 나는 생산자가 되기 위한 과정을 거칠 것이다.항상 주변을 예리하게 살펴보자.나는 이미 부자다!" }, { "title": "[번역] Google Pro Tip: 대략적인 계산방식을 통한 최적의 디자인을 하기", "url": "/posts/eng02-google/", "categories": "Translate", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2022-01-05 00:00:00 +0900", "snippet": " 다양한 기술 포스팅들이 올라오는 http://highscalability.com/ 사이트에는 양질의 개발관련 글이 올라온다. 그 중 시스템 설계를 위한 대략적인 계산 법에 대해 좋은 칼럼이 있어서 번역글을 작성해본다. 부족한 번역 실력 양해 부탁한다.원본 링크Google Pro Tip: 대략적인 계산방식을 통한 최적의 디자인을 하기[Back-Of-The-Envelope-Calculations : 일반적으로 봉투와 같은 사용 가능한 종이 조각에 적어 놓은 대략적인 계산을 의미한다.]주어진 문제에 대한 최고 의 설계가 어떤 것인지 어떻게 알 수 있을까?예를 들어서, 30장의 썸네일의 결과값을 내놓는 이미지 검색 엔진을 설계한다면 당신은 이미지들을 순차적으로 불러올 것인가?혹은 병렬적으로?캐싱은 할 건가?이런 것들은 어떻게 결정을 할 것인가?만약 너가 멀티버스의 힘(power of the multiverse)을 이용한다면, 생각하는 모든 옵션의 설계를 시도해보고 어떤 것이 가장 좋은지 확인할 수 있을 것이다.하지만 그건 터무니없는 이야기이다.다른 선택지는 대안이 되는 알고리즘의 순서를 고려하는 것이다.(order of various algorithm)계산적 사고 황금기의 예언자인 구글은 분명이 이렇게 하겠지만, 또 다른 방법으로는 어떻게 하고 있을까?Back-Of-The-Envelope(봉투 뒷면) 계산 방법을 이용해서 다양한 설계 계산하기구글의 사회 기반 시설 대학원 (School of Infrastructure Wizardry / 광고 서비스, 검색, 맵리듀스, 버퍼프로토콜 등 구글의 중요하고 다양한 대표 시스템들을 포함하고 있음) 대표인 제프 딘(Jeff Dean) 은 봉투 뒷편 계산법을 사용해서 다양한 설계를 계산하는 방법을 주장한다.그는 스탠포드 강의에서 전체 이야기를 풀어냈었다.봉투 뒷편 계산법은 당신이 사고 실험과 통용적인 성능의 숫자를 혼합해서 추정을 할 수 있게 해준다. 이를 통해 어떤 설계가 당신의 요구사항에 적절하게 부합하는지 알아차릴 수 있게 한다.딘 박사는 직접 설계를 통해서 설계 성능의 대체 시스템을 추정하는 것이 아니라, 봉투 뒷편 계산법을 이용해서 대략적인 설계를 할 수 있는 것이 모든 소프트웨어 엔지니어에게 중요한 기술이라고 생각한다.스탠포드 강의에서 딘 박사는 매우 좋은 예시를 하나 제시했는데, 그전에 먼저 알아야 할 것들이 존재한다.모두가 반드시 알아야하는 숫자들설계 대안을 계산하기 위해서 당신은 전형적인 운영 동작이 얼마나 오래 걸리는지에 대한 적절한 감각이 있어야만 한다.딘 박사는 아래의 리스트를 제시했다. L1 캐쉬 참고 : 0.5 ns 분기 예측 오류 : 5 ns L2 캐쉬 참조 : 7 ns 뮤텍스(Mutex) 락/언락 : 100 ns 주 메모리 참조 : 100 ns Zippy 로 1 KB 압축 : 10,000 ns 1Gbps 네트워크로 2KB 전송 : 20,000 ns 메모리에서 1 MB 순차적으로 Read : 250,000 ns 같은 데이터 센터 내에서의 메시지 왕복 지연 시간 : 500,000 ns 디스크 탐색 : 10,000,000 ns 네트워크에서 1 MB 순차적으로 Read : 10,000,000 ns 디스크에서 1 MB 순차적으로 Read : 30,000,000 ns 한 패킷의 CA(캘리포니아)로부터 네덜란드까지의 왕복 지연시간 : 150,000,000 ns몇 가지 주의할 점이 있다. 성능의 다양한 옵션에 따라서 규모의 차이가 있다는 것을 인지하라. 데이터 센터는 서로 멀리 떨어져 있기 때문에 서로 어떤 것들 보내는데 긴 시간이 소요된다. 메모리는 빠르고 디스크는 느리다. 값 싼 압축 알고리즘(2의 N제곱)을 사용한다면 네트워크 대역폭을 아낄 수 있다. 쓰기는 읽기보다 40배나 값 비싼 연산이다. 글로벌 공유 데이터는 값 비싸다. 이것은 분산 시스템의 근본적인 한계이다. 대량으로 작성된 공유 데이터에서의 락은 트랜잭션을 직렬화 시키면서 성능을 저하시킨다. 쓰기의 확장을 고려한 설계를 하라. 쓰기 경합을 낮추도록 최적화하라. 넓게 최적화 하라. 할 수 있는 한 쓰기를 병렬화 하라.에시: 30장의 썸네일을 가진 이미지 결과 생성 페이지 만들기이 예시는 스탠포드 강의에서 제시된 것이다. 두가지의 설계 대안은 사고 실험으로 사용된다.설계1 - 연속적 이미지를 연속적으로 읽어온다. 디스크 탐색을 한다. 256K의 이미지를 읽고 다음 이미지로 넘어간다. 성능 : 30번탐색 _ 10ms/탐색 + 30 _ 256K % 30MB/s = 560ms설계2 - 병렬적 문제를 병렬로 읽는다. 성능 : 10ms/탐색 + 256K read % 30MB/s = 18ms 디스크 읽기로부터 변화가 있을 것이다. 따라서 대략적인 소요 시간은 30-60ms 일 것이다.어떤 설계가 더 적합한가?당신의 요구사항에 따라서 다르겠지만 봉투 뒷편 계산법을 사용한다면 직접 설계하지 않고도 빠르게 성능을 비교할 수 있다.이제 당신은 스스로에게 다른 설계 질문과 설계의 다양성에 대한 차이를 물어볼 수 있는 프레임워크를 갖추었다. 썸네일 이미지를 하나씩 캐싱하는게 합리적인가? 하나의 엔트리에 전체 이미지를 캐싱해야만 하는가? 썸네일을 미리 계산하는게 합리적인가?이러한 추정치들을 현실적으로 하기 위해서 당신은 당신의 서비스의 성능을 알아야만 한다.만약 알지 못하는 변수가 있는 경우 해당 부분만 빠르게 프로토타입으로 제작하여 해결할 수 있다.예를 들어서 캐싱이 좋은 설계 대안인지 알아보기 위해서 당신은 캐쉬에 쓰기연산을 할 때 얼마나 시간이 소요되는지 알아야할 필요가 있다.얻은 교훈 봉투 뒷편 계산법 은 당신이 다양한 변형을 살펴볼 수 있게 한다. 당신의 시스템을 설계할 때, 이러한 종류의 게산은 당신 머리속으로 계속해서 반복해야 한다. 당신의 시스템 블럭들을 설게하기 위해서 봉투 뒷면의 숫자를 알고 있어야한다. 일반적인 성능의 수치를 단순히 안다는 것은 충분하지 않으며, 하위 시스템이 얼마나 성능을 내는지 알고 있어야만 한다. 어떻게 계산이 되었는지 알지 못한다면 봉투 뒷편 계산법을 반대로 수행할 수 없을 것이다.나는 개인적으로 이러한 접근을 상당히 좋아한다.일반적인 경우보다 봉투 뒷편 계산법은 시작부터 끝까지 시스템의 본질에 기반을 두는 것 같아 보인다.오늘날의 관행은 실제로 더 크고 전체적인 분석에서 연구 가능하고 틀어 막을 수 있는 다양한 알고리즘들의 속임수에 초점을 맞추고 있다.관련 글들 Numbers Everyone Should Know The Back of the Napkin by Dan Roam A Physicist Explains Why Parallel Universes May Exist by Brian Green " }, { "title": "[번역] Stack Overflow는 어떻게 운영되고 있을까?", "url": "/posts/eng01-stackoverflow/", "categories": "Translate", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2021-12-28 00:00:00 +0900", "snippet": " 개발자들의 필수 사이트 Stack Overflow가 어느 정도의 부하를 감당하고 있는지, 어떤 스펙의 하드웨어로 운영하고 있는지에 대한 좋은 칼럼이 있어서 번역글을 작성해본다. 부족한 번역 실력 양해 부탁한다.원본 링크Stack Overflow는 어떻게 운영되고 있을까?Stack Overflow 가 규모 있게는 돌아가지만 완전한 규모에 위치하고 있지는 않은 것 같다고 생각한다.이게 무슨말이냐면 우리는 매우 효율적으로 웹을 운영하고 있지만, 나는 여전히 우리가 크다 라고는 생각하지 않는다.우리가 현재 어떠한 규모에 위치하고 있는지 알아보기 위해서 몇 가지의 숫자를 한번 제시해보겠다.이 숫자들은 몇 일 전 24시간 동안의 기록에 대한 것들이다. (정확하게는 2012년 11월 12일이다.)전형적으로 평일에 나온 숫자들이고 오직 활성화된 데이터 센터들만을 포함하고 있다. (우리가 소유하고 있는 것 말이다.)우리 CDN 서버로의 접근과 대역폭은 우리 네트워크를 접근하지 않기 때문에 포함되어 있지 않다. 148,084,883 - 로드벨런서로의 HTTP 응답 수 36,095,312 - 페이지 로드의 수 833,992,982,627 bytes (776 GB) - 보내진 HTTP 트래픽 양 286,574,644,032 bytes (267 GB) - 수신한 전체 양 1,125,992,557,312 bytes (1,048 GB) - 송신한 전체 양 334,572,103 SQL 쿼리 (HTTP 응답으로 부터만 본 결과) 412,865,051 - Redis hits 3,603,418 - 태그 엔진들의 요청 수 558,224,585 ms (155 hours) - SQL 쿼리들을 실행하는데 소요된 시간 99,346,916 ms (27 hours) - redis에 hit 하는데 소요된 시간 132,384,059 ms (36 hours) - 태그 엔진 요청에 소요된 시간 2,728,177,045 ms (757 hours) - ASP.Net 에서의 과정에 소요된 시간(우리가 이러한 숫자들을 어떻게 빠르게 얻을 수 있었는지, 그리고 그 숫자들을 가지는 것 만으로도 얼마나 노력할만한 가치가 있는지 포스팅을 해야만 했다.)이것들이 전체를 포함한 것이 아닌 오직 Stack Exchange 네트워크만을 의미한다는 것을 명심하길 바란다. 2가지 총합의 예외를 제외한 나머지 숫자들은 우리가 성능을 살펴보기 위해서 오직 HTTP 요청으로만 얻었다.숫자들이 하루 치고는 굉장히 많은 시간들인데 과연 어떻게 관리를 하고 있는 것일까?우리는 이것들을 마법이라고 부르고, 어떤 이들은 멀티 코어 프로세서를 가진 멀티 서버 라고 부른다.하지만 우린 계속해서 마법이라고 부를 것이다.아래는 데이터 센터의 Stack Exchange 네트워크에서 무엇이 동작하고 있는지에 대한 것이다. 4 MS SQL Servers 11 IIS Web Servers 2 Redis Servers 3 Tag Engine servers (anything searching by tag hits this, e.g. /questions/tagged/c++) 3 elasticsearch servers 2 Load balancers (HAProxy) 2 Networks (each a Nexus 5596 + Fabric Extenders) 2 Cisco 5525-X ASAs (think Firewall) 2 Cisco 3945 Routers이렇게 생겼다!우리는 사이트만 운영하는 것이 아니다. 가장 가까운 랙에 있는 나머지 서버들은 배포, 도메인 컨트롤러, 모니터링, 운영 데이터베이스 등과 같이 사이트를 직접 서비스하지 않는 보조 기능을 위한 VM과 다른 인프라 장비들이다.위의 리스트 중에서 2개의 SQL 서버는 최근까지 만해도 백업용도였다. - 지금은 읽기 전용 로드에 사용되어지고 있어서 길게 생각하지 않고 계속해서 규모를 늘리고 있다. (이건 주로 the Stack Exchange API 로 이루어져 있다.)Core Hardware만약 중복된 것들을 제외하고 Stack Exchange가 (현재와 같은 수준의 성능을 유지하면서) 동작하기 위해서는 아래의 것들이 필요하다. 2 SQL servers (SO가 한 대를 차지하고 있고 다른 모든 것들은 남은 한 대에 있다… 그래도 헤드룸에 남아 있는 기계 한대로 동작할 수 있긴 하다) 2 Web Servers (2개라고 믿고 있지만 아마 3개일 것이다.) 1 Redis Server 1 Tag Engine server 1 elasticsearch server 1 Load balancer 1 Network 1 ASA 1 Router(언젠가는 장비들을 종료시키고 Breaking Point 가 무엇인지 테스트 해야만 한다!)이제는 몇 개의 VM들과 백 그라운드에서 잡, 도메인 컨트롤러 등을 처리할 수 있는 몇 가지만 남아있다. 하지만 이것들은 너무나도 경량화되어 있어서 Stack Overflow 그 자체에 집중할 수가 없고 모든 페이지들을 최고 속도로 렌더링할 수가 없다.만약 제대로된 비교를 하기 위해서는 (apples to apples) 모든 VMware 서버들을 모든 경우의 수에 투입해봐라. 많은 수의 장비는 아니지만 이 장비들의 스펙을 클라우드에서 합리적인 가격으로 맞추는 것은 거의 불가능하다.아래는 빠르게 서버를 Scale up하는 방법들이다. SQL 서버들은 384 GB 의 메모리와 1.8TB of SSD 저장소를 가지고 있다. Redis 서버들은 96 GB 의 RAM 을 가지고 있다. elastic search 서버들은 196 GB 의 RAM을 가지고 있다. Tag engine 서버들은 우리가 살 수 있는 가장 빠른 raw processors 를 가지고 있다. 네크워크 코어들은 각 포트가 10 Gb 의 대역폭을 가지고 있다. 웹 서버들은 그렇게 특별하지 않은데, 32 GB 와 2x quad core, 그리고 300GB 의 SSD 저장소를 가지고 있다. 2x 10Gb를 가지고 있지 않는 서버들은 (e.g. SQL) 4x 1 Gb 의 네트워크 대역폭을 가지고 있다.20Gb 가 엄청난 과잉일까?물론이다! 활성화된 SQL 서버들은 20GB 파이프에서 평균적으로 약 100-200 Mb를 가지고 있다.하지만 백업, 리빌드 등과 같은 기능들은 메모리 및 SSD 저장소가 현재 얼마나 있는지에 따라서 완전히 포화될 수도 있기 때문에 목적에 부합한다.Storage현재 약 2TB의 SQL 데이터를 가지고 있기 떄문에(첫번째 클러스터의 18개 SSD에서 1.06 TB / 1.63 TB / 두번째 클러스터의 4개 SSD에서 1.45 TB), 우리는 클라우드가 필요하다.(흠, 이 단어가 또 나왔다.)모든 것은 SSD라는 것을 명심해라. 모든 데이터베이스에서 평균적인 쓰기 시간은 0 MS 이다. 이게 우리가 측정할 수 있는 최고의 단위는 아니기 때문에 저장소는 더 잘 대처하고 있을 것이다.데이터베이스가 메모리에 있고 그 앞에 2레벨의 캐쉬가 있다면, Stack Overflow의 실제 읽기-쓰기 비율은 40:60이다.그래, 제대로 읽은 것 맞다. 60%의 우리 데이터베이스 디스크 접근은 쓰기이다. (읽기/쓰기 부하를 알아야한다.)각 웹 서버 또한 2x 320GB SSDs in a RAID 1 의 저장소를 가지고 있다.Elastic Box들은 300 GB를 필요로 하고 SSD 보다 더 나은 성능을 보인다. (우린 write/reindex를 매우 자주 한다.)우리가 SAN과 핵심 네트워크에 2x 10Gb 속도로 연결이 되는 24x900GB 10K SAS(Equal Logic PS6110X)를 가지고 있는 것은 별 의미가 없다.이건 고가용성을 위한 공유 메모리로서 VM에 독점적으로 사용되지만 실제로는 우리 웹사이트를 호스팅하는데 지원되지 않는다.다시 말해서 SAN이 죽더라도 우리의 웹사이트는 일시적으로 알아차리지 못할 수도 있다. (VM 도메인 컨트롤러가 그 요소일 뿐이다.)종합내용 (Put it all together)그래서 전체적인 것들이 어떻다는 것일까?우리는 성능을 원한다. 아니, 우리는 성능이 필요하다.성능은 우리에게 매우 중요한 특징이다. (Performance is a feature)우리의 모든 사이트에서 로딩되는 메인 페이지는 질문 페이지인데 내부적으로는 Question/Show라고 잘 알려져있다. 11월 12일 페이지는 평균 28 밀리세컨즈로 렌더링이 되었다.50ms 의 속도를 유지하기 위해 노력하는 동안, 우리는 여러분의 페이지 로딩 경험을 가능한 빠르게 하기 위해서 정말로 고군분투했다.우리의 모든 개발자들은 성능에 관해서 보증 가능할 정도로 꼼꼼한 괴짜들이기 때문에 소요 시간을 낮게 유지하는데 큰 도움을 준다.아래의 내용은 24시간동안 평균적인 렌더링에 있어서 SO의 Top Hit Page들이다. Question/Show: 28 ms (29.7 million hits) User Profiles: 39 ms (1.7 million hits) Question List: 78 ms (1.1 million hits) Home page: 65 ms (1 million hits) (매우 느린편이다. - Kevin Montrose 는 곧 수정이 될 것이다. : 가장 주요한 원인)우리는 모든 요청들을 기록하면서 우리의 페이지에 어떤 것들이 오고가는지에 대해 아주 효율적인 가시성을 가지고 있다.당신은 아래 종류의 메트릭을 필요로한다. 만일 그렇지 않다면 결정을 할 때 어디에 근간을 두겠는가?이런 간편한 메트릭을 통해서 우리는 좀 더 쉽게 접근할 수 있고 쉽게 파악할 수 있다.페이지 접근 비율이 급격하게 떨어진 후, 만약 당신이 구체적인 페이지의 접근 비율 급락 원인에 대해서 궁금해 한다면 나는 이 숫자들을 첨부한 것에 대해 기쁘게 생각할 것 같다.나는 여기서 렌더링 시간에 초점을 맞추었는데, 이는 웹페이지를 생상하는데 얼마나 오래 걸리는지에 대한 시간이기 때문이다. 데이터의 전송 속도는 완전히 다른 주제이기 때문에 추후에 다시 한번 더 다루도록 하겠다. (솔직히 아주 관련이 있긴 하다.)Room to grow서버들이 매우 낮은 활용률로 동작하고 있다는 것은 분명히 주목할 필요가 있다.웹 서버들는 평균적으로 5-15% CPU, 15.5 GB 의 RAM 사용 그리고 20-40 Mb/s 의 네트워크 트레픽을 가지고 있다. SQL 서버들은 평균적으로 5-10% CPU, 365 GB 의 RAM 사용 그리고 100-200 Mb/s 의 네트워크 트레픽을 가지고 있다.이를 통해 다음과 같은 이점들을 얻을 수 있다.업그레이드 하기전 더 커질 수 있는 일반적인 공간, 무엇인가 잘못되었을 때(이상한 쿼리, 이상한 코드, 해커들의 공격 등 무엇이든 될 수 있다.) 머물 수 있는 헤드룸 그리고 필요하다면 전력을 재충전할 수 있는 능력.아래는 방금 Opserver 로 부터 얻은 우리 웹의 등급이다.활용율이 낮은 주요 원인은 효과적인 코드때문이다.이건 지금 이 포스팅의 주요한 주제는 아니지만 효율적인 코드가 당신의 하드웨어가 발전하는데 치명적일 수 있다. 수행할 필요가 없는 작업은 아무것도 하지 않는 것 보다 비용이 많이든다. 또한 당신의 코드 하위 집합이 더 효율적일 수 있는 경우에도 그러하다.비용은 다음과 같은 형태로 만들어진다.전력 소비, 하드웨어 비용(당신이 더 크고 많은 서버를 원한다면…), 더 복잡한 무언가를 이해하는 개발자들(솔직히 말해서 이건 양쪽으로 다 갈 수 있다. 효율적인게 반드시 간단한건 아니다.) 그리고 페이지 렌더링의 느린 속도(다음 페이지로 넘어가는 유저들이 더 적어지거나 아예 다시 방문하지 않을 수도 있다.).비효율적인 코드의 비용은 당신이 생각하는 것보다 훨씬 높을 수 있다.지금까지 우리는 Stack Overflow가 현재의 하드웨어로 어떻게 운영되는지 보았다. 다음 시간에는 우리가 왜 클라우드 상에서 운영하지 않는지를 알아볼 것이다." }, { "title": "[Audio] ffprobe 설명 및 사용법", "url": "/posts/audio-ffprobe/", "categories": "Audio", "tags": "blog, jekyll, blog, jekyll theme, NexT theme, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2021-12-26 00:00:00 +0900", "snippet": "ffprobe 설명 및 사용법ffprobe 이란?많이 알려져 있는 ffmpeg은 미디어 포맷을 변환하는데 사용하는 도구라면, ffprobe는 쉽게 말해 간단한 멀티미디어 Stream 분석기이다.[공식 문서 : https://ffmpeg.org/ffprobe.html]사용 나는 서버 상에서 사용을 해야하는데, 설치하지 못하는 환경이라서 docker image를 이용해 run을 시켰다.Command output 을 json으로 출력을 하였고 몇 가지 옵션을 추가하였다.$ docker run --rm -v /home:/config DOCKER_IMAGE:latestffprobe -v quiet-print_format json-show_format-show_streams/config/test1.wavOutput 아래의 결과 값과 같이 해당 미디어의 다양한 Key값들을 분석해서 보여줄 수 있다.{ &quot;streams&quot;: [ { &quot;index&quot;: 0, &quot;codec_name&quot;: &quot;pcm_s16le&quot;, &quot;codec_long_name&quot;: &quot;PCM signed 16-bit little-endian&quot;, &quot;codec_type&quot;: &quot;audio&quot;, &quot;codec_time_base&quot;: &quot;1/16000&quot;, &quot;codec_tag_string&quot;: &quot;[1][0][0][0]&quot;, &quot;codec_tag&quot;: &quot;0x0001&quot;, &quot;sample_fmt&quot;: &quot;s16&quot;, &quot;sample_rate&quot;: &quot;16000&quot;, &quot;channels&quot;: 1, &quot;bits_per_sample&quot;: 16, &quot;r_frame_rate&quot;: &quot;0/0&quot;, &quot;avg_frame_rate&quot;: &quot;0/0&quot;, &quot;time_base&quot;: &quot;1/16000&quot;, &quot;duration_ts&quot;: 49920, &quot;duration&quot;: &quot;3.120000&quot;, &quot;bit_rate&quot;: &quot;256000&quot;, &quot;disposition&quot;: { &quot;default&quot;: 0, &quot;dub&quot;: 0, &quot;original&quot;: 0, &quot;comment&quot;: 0, &quot;lyrics&quot;: 0, &quot;karaoke&quot;: 0, &quot;forced&quot;: 0, &quot;hearing_impaired&quot;: 0, &quot;visual_impaired&quot;: 0, &quot;clean_effects&quot;: 0, &quot;attached_pic&quot;: 0, &quot;timed_thumbnails&quot;: 0 } } ], &quot;format&quot;: { &quot;filename&quot;: &quot;/config/test1.wav&quot;, &quot;nb_streams&quot;: 1, &quot;nb_programs&quot;: 0, &quot;format_name&quot;: &quot;wav&quot;, &quot;format_long_name&quot;: &quot;WAV / WAVE (Waveform Audio)&quot;, &quot;duration&quot;: &quot;3.120000&quot;, &quot;size&quot;: &quot;99884&quot;, &quot;bit_rate&quot;: &quot;256112&quot;, &quot;probe_score&quot;: 99 }}" }, { "title": "[K8S] Grafana vs Kibana", "url": "/posts/tb10-k8s-grafana-kibana/", "categories": "K8S", "tags": "blog, jekyll, blog, jekyll theme, NexT theme, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2021-12-19 00:00:00 +0900", "snippet": "Grafana vs Kibana쿠버네티스에서 서비스를 운영하기 위해서 모니터링 툴을 적용해야 했다.기존 시스템에서는 ELK 스택 중 하나인 Kibana를 써왔지만, 쿠버네티스 시스템에서는 Prometheus + Grafana 스택을 많이들 쓴다고 해서 기존 Kibana와 Grafana의 차이점에 대해서 알아보았다.Kibana 로깅 시스템에서의 시각화 도구 Kibana 는 Elasticsearch 및 더 광범위한 ELK Stack에서 통합되어 다양한 인덱스 데이터를 검색 및 확인하는데 사용됨. 막대 차트, 원형 차트, 표, 히스토그램, 지도 등을 생성할 수 있어 인덱스 데이터의 시각화가 간편함. 주로 Log Message 분석에 사용됨 Index를 통해서 Log를 상세하게 분석할 수 있다.Grafana 시계열 매트릭 데이터 수집에 강점을 가지고 있다. System info (CPU, Memory, Disk …) 등의 메트릭 지표를 시각화하는데 사용된다. 알람 기능이 무료이다. 대쉬보드가 위주이다.Kibana vs Grafana목적 Grafana 메시지 로깅에 대한 정보보다는 시스템의 메트릭을 확인하는데 더 큰 중점을 가지고 있음. Kibana 여러가지 Index 설정을 통해 메시지의 로그를 구체적이고 가시적으로 확인하기 위함. 어떤 것이 더 낫다고 이야기할 수 있는 부분이 아니다. 서로 다른 목적을 가지고 있는 시각화 툴이다. 어떤 팀에서는 Kibana 와 Grafana를 함께 운용하는 팀도 있다. 즉, 목적성에 맞게 사용하는 것이 필요함!" }, { "title": "[K8S] 쿠버네티스 재시작은 어떻게? Rollout restart vs apply", "url": "/posts/tb09-k8s/", "categories": "K8S", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2021-12-15 00:00:00 +0900", "snippet": "Rollout restart vs applyDeployment 나 Kubernetes의 여러가지 Object들을 생성하기 위해서 Apply 명령어를 많이 쓴다.그렇다면 deployment 를 재시작하기 위해서는 어떤 명령어를 써야할까?Apply kubectl apply 는 모든 쿠버네티스의 Obejct들 (Pod, Deployment, ConfigMaps, Secrets, etc) 에 모두 적용이 가능하다. 명세(yaml) 파일의 spec 필드의 변경이 있어야 apply 실행시 적용이 가능함.Rollout restart Kubectl rollout 은 Deployments, Statefulsets 와 같은 연산이 가능한 부분에 대해서만 적용이 가능함. spec 필드의 변경과 같은 어떠한 변화의 필요 없이 pod 재시작이 가능하다. 간단하게 정리하자면 Rollout restart 를 하게 되면 Gracefully 하게 pod가 Terminating 되고 새로운 pod가 생성된다. 하지만 Apply는 rollout restart 처럼 파드가 재시작되지는 않는다. config (yaml) 값이 변경되어야만 재시작이 됨. 이외에도 replace와 같은 명령어를 사용하게 되면 Gracefull 하진 않지만, pod가 delete 되고 create된다.참고 : https://stackoverflow.com/a/66420597/14995221" }, { "title": "[K8S] kubernetes imagepullpolicy 는 무엇이고 언제 적용될까?", "url": "/posts/tb08-k8s/", "categories": "K8S", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2021-12-11 00:00:00 +0900", "snippet": "kubernetes imagepullpolicy 는 무엇이고 언제 적용될까?imagepullpolicy해석 그대로 컨테이너를 생성할때 사용하는 Image의 Pull 정책에 대한 설정값이다.IfNotPresent이미지가 로컬에 없는 경우에만 내려받는다.Alwayskubelet이 컨테이너를 기동할 때마다, kubelet이 컨테이너 이미지 레지스트리에 이름과 이미지의 다이제스트가 있는지 질의한다. 일치하는 다이제스트를 가진 컨테이너 이미지가 로컬에 있는 경우, kubelet은 캐시된 이미지를 사용한다. 이외의 경우, kubelet은 검색된 다이제스트를 가진 이미지를 내려받아서 컨테이너를 기동할 때 사용한다.Neverkubelet은 이미지를 가져오려고 시도하지 않는다. 이미지가 어쨌든 이미 로컬에 존재하는 경우, kubelet은 컨테이너 기동을 시도한다. 이외의 경우 기동은 실패한다. 보다 자세한 내용은 미리 내려받은 이미지를 참조한다.IfNotPresent 이미지가 Local에 없는 경우에만 내려받음Always kubelet이 컨테이너를 가동할 때마다 컨테이너 이미지의 이름과 이미지의 Digest가 있는지 확인한다. 로컬에 있는 경우 캐시된 이미지를 사용, 이외의 경우는 다시 이미지를 내려받음Never 이미지를 가져오려고 시도하지 않음. 로컬에 이미지가 존재하지 않는다면 컨테이너 실행은 실패한다.그렇다면 어떤 특정 시기에 이 값이 영향을 미칠까?나 같은 경우는 일반적으로 Always값을 사용한다. 위의 설명에서 확인할 수 있듯이 컨터이너 실행에서 정책이 영향을 미친다. 즉, Deployment 가 항상 새로운 이미지를 바라보는 것이 아니다. 컨테이너가 Run할때 어떤식으로 동작할 것인지를 본다. 그렇다면 언제 컨테이너를 실행할까?Pod의 Life cyclePod에는 1개 이상의 Container가 실행될 수 있는데,언제 컨테이너가 실행되는지 알기 위해서는 Pod의 Life Cycle을 확인할 필요가 있다. Pending에서 시작해서 컨테이너 중 하나라도 OK로 시작되면 Running 으로 바뀐다. 컨테이너가 실패로 종료되었는지 여부에 따라 Succeeded or Failde 로 바뀜.CrashLoopBackOff 에서의 ImagePullPolicyPod가 crashloopbackoff 상태일때는 ImagePullPolicy가 어떻게 적용될까?CrashLoopBackOff CrashloopBackOff 는 Pod가 Starting -&amp;gt; Crashing -&amp;gt; Starting Again 을 계속 반복한다는 것을 의미한다. 즉, 컨테이너 실행 중 Crashing 이 발생하면 Pod가 반복적으로 Restart를 수행한다. Pod가 CrashloopBackOff 상태일때 Restart 값을 확인해보면 계속 증가하는 것을 확인할 수 있다. 즉, container가 새로 생성될 때마다 imagepull을 하게된다. crashloopbackoff 이면 pod가 pending -&amp;gt; restart -&amp;gt; running 으로 가는거니깐 container 새로 생성. 즉 image 받아옴.참고 : https://stackoverflow.com/a/45906651/14995221" }, { "title": "[MLops] [MLops Deployment &amp; Monitoring] Model Monitoring", "url": "/posts/ml/", "categories": "MLops", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2021-12-03 00:00:00 +0900", "snippet": "[ MLops Deployment &amp;amp; Monitoring ] Model MonitoringTrain, Test, Deploy.그래서, 다 끝난거야?배포 작업 이후에 어떤 것이 문제가 될 수 있을까?&amp;lt;/br&amp;gt;그것을 알기 위해서는 Monitoring 작업이 필수적이다.&amp;lt;/br&amp;gt;Model Monitoring 는 크게 3가지로 나뉜다. Data Drift Model Drift (Concept Drift) Domain Shift그럼 대략적으로 하나씩 훑어보자.Data Drift 의 종류 즉각적인 Drift 점진적인 Drift 주기적인 Drift 일시적인 Drift그렇다면 Data Drift 는 어떻게 알아차릴까?먼저 A 부분을 Healthy 한 Data라고 가정한다.그리고 비교하고 싶은 B라는 window를 지정한다.그 후 둘 간의 Distance를 비교한다.비교 방법 Rule-based distance metrics (aka, data quality) 통계적 방법 KL divergence ( 가장 많이 사용함 ) Kolmogorov-Smirnov statistic D_1 distance High Dimensional data일 경우? 단순히 Distance를 비교하게 되면 데이터 손실이 크다-&amp;gt; 차원 축소의 Logic을 잘 거친 후에 Distance를 비교해야한다. Evaluation Store (평가 저장소)ML에서는 버그가 매우 조용하고 잡기 힘들다. 또한 Monitoring 을 통해서 얻을 수 있는 데이터가 다시 Model의 학습데이터로 사용될 수 있다.따라서 Monitoring은 기존 Legacy SW보다 ML에서는 매우 중요하다.이 그림은 ML에서 Monitoring 을 통해 데이터를 어떻게 활용할건지에 대한 Flywheel 그림이다.단순히 문제가 발생한 데이터를 버리는 것이 아니라 재가공을 진행하여 다시 학습을 시켜 Model을 한번 더 강화시키는 것이다.참고 : https://fullstackdeeplearning.com/spring2021/lecture-11/" }, { "title": "[Python] Python에서 * 와 ** 의 차이", "url": "/posts/tb01-args/", "categories": "Python", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2021-11-24 00:00:00 +0900", "snippet": "Python에서 * 와 ** 의 차이*args 몇개의 파라미터를 받을지 모른다. 이럴 경우 args는 Tuple 형태로 전달된다.def test(*args): for a in args: print(a)test(1,2,3,4,5,6)&amp;gt;&amp;gt;123456**kwargs 파라미터 명을 같이 보낼 수 있다. Dictionary 형태로 전달된다.def test2(**kwargs): print(kwargs.keys()) print(kwargs.values())test2(a=1,b=2,c=3)&amp;gt;&amp;gt;&amp;gt;dict_keys([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])dict_values([1, 2, 3])Trouble ShottingClass로 정의해둔 형태를 호출해서 Dictionary 형태로 넘기고 싶었다.class FooCreate(FooBase): a: str b: str c: strclass FooDeployService: def create_item(self, item, db): item = FooCreate(**item) result = FooService(db).create_item(item) return handle_result(result)class FooService(AppService): def create_item(self, item: FooCreate) -&amp;gt; ServiceResult: Foo_item = FooCRUD(self.db).create_item(item) if not Foo_item: return ServiceResult(AppException.FooCreateItem()) return ServiceResult(Foo_item)즉, 아래와 같은 test형태로 create_item을 호출하고 싶었는데,test -&amp;gt; FooDeployService -&amp;gt; FooService**item이 아니라 item을 넣으니 FooCreate 클래스의 attribute 형태에 맞게 Mapping 되지 않고 에러가 발생했다. 아래와 같이 ** 형태로 넣으니 Key값을 가진 파라미터 형태로 하나씩 들어가기 때문에 에러가 나지 않고 해결되었다.def test(): item = {&quot;a&quot;: a, &quot;b&quot;: b, &quot;c&quot;: c} FooDeployService().create_item(item, db)참고 : https://sshkim.tistory.com/182" }, { "title": "[K8S] 쿠버네티스(K8S)에서의 Log Aggregator, Logstash vs Fluentd", "url": "/posts/tb05-k8s_log_aggregator/", "categories": "K8S", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2021-11-23 00:00:00 +0900", "snippet": "쿠버네티스(K8S)에서의 Log Aggregator, Logstash vs FluentdLog Aggregator (로그 수집기) 란? 거의 대부분의 서비스에서는 디버깅을 위한 로그 수집은 필수적이다.ELK 스택으로 로그 수집 및 시각화를 많이 하곤 한다. ELK Elastic Search Apache Lucene 기반의 Java 오픈소스 분산 검색 엔진 방대한 양의 데이터를 신속하게 (Near Real Time)으로 저장, 검색, 분석할 수 있다. Logstash Elastic 에서 만든 오픈 소스 서버측 데이터 처리 파이프라인 Kibana 로그 수집기로부터 데이터를 받아 시각화할 수 있는 오픈소스 Kubernetes에서의 Logging 가장 쉽고 가장 널리 사용되는 로깅 방법은 표준 출력과 표준 에러 스트림에 작성하지만 표준출력으로는 완전한 로깅이 불가능하다-&amp;gt; 컨테이너가 크래시되거나, 노드가 종료된 경우에도 애플리케이션의 로그에 접근해야한다. 따라서 클러스터에서 로그는 노드, 파드 또는 컨테이너와는 독립적으로 별도의 스토리지와 라이프사이클을 가져야 한다. 이를 클러스터-레벨-로깅이라고 한다.Logstash vs Fluentd Kubernetes에서의 로그 수집은을 할 떄는 어떤 툴을 사용할까?상황에 따라 다르지만 Fluentd가 더 매력적인 부분들이 많다. Fluentd는 Treasure Data에 의해 구축되었고 CNCF의 일부이다. CNCF : Cloud Native Computing Foundation은 컨테이너 기술을 발전시키고 기술 산업이 발전할 수 있도록 지원하기 위해 2015년에 설립된 Linux Foundation 프로젝트 Kubernetes나 Cloud 환경에서 더 Support가 잘 되고 있음 Docker에서 Fluentd를 위한 build-in logging driver를 가지고 있다. 이를 통해 Fluentd를 사용하면 다른 로그 파일 도움없이 직접적으로 STDOUT 을 내보낼 수 있다. Logstash는 Filebeat와 같은 플러그인을 이용해야만 가능 전체적인 차이점을 보고 싶다면 여기를 참고Logstash, Fluentd 각각 장단점이 있지만 Kubernetes와 같은 Cloud환경에서는 Fluentd가 더 적합한 것 같다. " }, { "title": "[Blog] Bucket List", "url": "/posts/bucketList/", "categories": "blog", "tags": "blog, jekyll, jekyll theme, NexT theme, Computer Science, 컴퓨터공학, 개발, 소프트웨어, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2021-11-22 00:00:00 +0900", "snippet": "Bucket List2021.11.22 작성 대도시와 근접한 마당있는 넓은 집에서 아내와 큰 리트리버와 함께 바베큐해먹기 작성중…" }, { "title": "[Audio] ffmpeg 사용해서 16k wav 파일로 변환하기", "url": "/posts/tb04-ffmpeg/", "categories": "Audio", "tags": "blog, jekyll, blog, jekyll theme, NexT theme, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2021-11-17 00:00:00 +0900", "snippet": "ffmpeg 사용해서 16k wav 파일로 변환하기Audio AttributesAudio 파일을 사용하기 위해서는 여러가지 값들을 알고 있어야한다.Sample Rate 샘플의 빈도 수 즉, 1초당 추출되는 샘플의 개수. SR이 높으면 높은 밀도의 음성, 낮으면 낮은 밀도의 음성. → 이것을 강제로 낮추면 느린 배속으로 재생이 되고, 높히면 빠른 배속으로 재생이 됨.Bit Rate 1초당 전송되는 데이터 양 즉, 1초당 전송되는 비트 수를 의미함.ffmpeg커맨드에서 Audio 파일을 원하는 포맷에 맞게 변경하기 위해서 ffmpeg과 soxi를 많이 쓰는데 오늘은 ffmpeg으로 16k wav파일을 만드는 커맨드를 보려한다.사용 나는 서버 상에서 ffmpeg을 사용해야하는데, 설치하지 못하는 환경이라서 docker image를 이용해 run을 시켰다.$ docker run --rm -v /home:/config DOCKER_IMAGE:latest ffmpeg -i /config/test1.wav 이런식으로 하면 ffmpeg이 사용 가능하다.ffmpeg version n4.3.1 Copyright (c) 2000-2020 the FFmpeg developers built with gcc 4.8.5 (GCC) 20150623 (Red Hat 4.8.5-44) libavutil 56. 51.100 / 56. 51.100 libavcodec 58. 91.100 / 58. 91.100 libavformat 58. 45.100 / 58. 45.100 libavdevice 58. 10.100 / 58. 10.100 libavfilter 7. 85.100 / 7. 85.100 libswscale 5. 7.100 / 5. 7.100 libswresample 3. 7.100 / 3. 7.100Guessed Channel Layout for Input Stream #0.0 : monoInput #0, wav, from &#39;/config/test1.wav&#39;: Duration: 00:00:03.12, bitrate: 256 kb/s Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/sAt least one output file must be specified원하는 옵션으로 만들기나는 들어오는 모든 input Audio를wav, 16k, 16bit, mono 의 Format으로 만들고 싶었다.$ docker run --rm -v /home:/config DOCKER_IMAGE:latest ffmpeg -y -i /config/test1.aac -f s16le -ac 1 -ar 16000 /config/test1_out.wavffmpeg에서는 input 파일명과 output 파일명이 같을 수 없다. 원하는 옵션으로 output 파일이 만들어진다." }, { "title": "[Trouble Shooting] [DB] ERROR 2006 (HY000) MySQL server has gone away 에러 해결", "url": "/posts/tb06-mysql-server-error/", "categories": "Trouble Shooting, DB", "tags": "blog, jekyll, blog, jekyll theme, NexT theme, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2021-11-15 00:00:00 +0900", "snippet": "ERROR 2006 (HY000) MySQL server has gone away 에러 해결Flask에서 MySQL을 이용하기 위해 Sqlalchemy 를 사용하던 도중 API 호출 시ERROR 2006 (HY000) MySQL server has gone away에러가 자주 발생하였다. 원인① MySQL 과 연결에 오류가 있는 경우② 패킷 전송에 문제가 있는 경우③ 이전 연결 세션에 영향을 받은 경우구글링해서 찾아본 결과, DB서버쪽의 설정값과 Flask client에서의 문제가 있을 수 있다.MySQL 서버 설정하기max_allowed_packet 값을 변경해주는 것인데,max_allowed_packet 는 서버로 질의하거나 받게되는 패킷의 최대 길이를 나타내는 변수 값이다.즉, client와 통신할 때 핸들링 할 수 있는 데이터 양을 의미한다.$ SET GLOBAL max_allowed_packet=64*1024*1024;이 컨맨드로 64MB로 max값을 수정했다.영구적으로 수정하려면 myslq의 conf에서 설정을 변경해주어야한다. (my.ini 파일)Client Sqlalchemy에서 설정 값 부여하기engine = db.create_engine(&quot;mysql+pymysql://root:PASSWORD@IP:3306/DBNAME&quot;, pool_pre_ping=True)engine을 선언할 때 pool_pre_ping 옵션 값에 True를 부여한다.pool_pre_ping 옵션은 Disconnect handling을 해결하는 옵션인데, DB서버 접속 전 “select 1” 과 같은 쿼리문을 ping으로 날려서 connection을 확인하고 연결을 진행한다.참고 : https://tjddnjs.tistory.com/69, https://blog.dork94.com/195" }, { "title": "[Trouble Shooting] Jekyll chirpy 템플릿으로 Github 블로그 시작하기. (Bundler Install Error)", "url": "/posts/tb07-jekyll-bundler-error/", "categories": "Trouble Shooting, ETC", "tags": "blog, jekyll, blog, jekyll theme, NexT theme, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2021-11-13 00:00:00 +0900", "snippet": "Jekyll chirpy 템플릿으로 Github 블로그 시작하기. (Bundler Install Error)Github 블로그 with Chirpy Jekyll Themegithub 블로그를 시작할 때 Jekyll을 많이 사용한다.그럼 Jekyll이 무엇일까?Jekyll? 텍스트 변환 엔진으로, Markup 언어로 글을 작성하면 이를 통해 웹사이트를 만들어줌. 서버 소프트웨어가 필요 없어 매우 빠르고 가볍다.-&amp;gt; Jekyll을 사용한 템플릿을 땡겨와서 블로그를 시작하면 기본 틀을 잡기 매우 간편하다.Chirpy Jekyll을 이용한 여러 템플릿을 제공해준다. Git : https://github.com/cotes2020/jekyll-theme-chirpy Tutorial : https://chirpy.cotes.info/categories/tutorial/-&amp;gt; Readme를 꼼꼼히 읽어보면 시작하는 방법이 상세하게 나와있다.(사실 비전공자의 입장에서 본다면 시작하기가 꽤나 까다로울 수도…)처음 시작[ Mac 환경에서 진행함 ]$ brew install ruby$ bundle$ bundle exec jekyll s # Running Local Server먼저 bundle을 설치해야한다.Bundler 란?-&amp;gt; Bundler는 정확히 필요한 gem과 그 gem의 버전을 설치하고, 추적하는 것으로 일관성 있는 Ruby 프로젝트를 제공하는 도구!근데 bundle 명령어를 칠 떄마다An error occurred while installing racc (1.6.0), and Bundler cannot continue.요런 비슷한 에러가 자꾸 발생했다.해결책xcode-select --installsudo gem install -n /usr/local/bin cocoapods요걸로 설치가 되면 끝! (참고 : https://hello-bryan.tistory.com/208)하지만 나는…xcode-select: error: command line tools are already installed, use &quot;Software Update&quot; to install updates이런 에러가 다시 떴다.$ sudo rm -rf /Library/Developer/CommandLineTools$ sudo xcode-select --install다시 깔아줬음 그랬더니 gem 으로 설치됨. bundler 도 설치된다.sudo gem install -n /usr/local/bin cocoapods(참고 : https://blog.ddoong2.com/2019/10/09/Install-Command-Line-Tool/)-&amp;gt; 이렇게 했더니 bundler 설치 완료!!그 외의 것들은 Chirpy Jekyll Theme 튜토리얼을 잘 따라하면 블로그 포스팅이 완료된다.Github Action을 이용해서 page를 만들어주는게 독특했다." }, { "title": "First Post", "url": "/posts/First-post/", "categories": "jekyll, blog, firstPost", "tags": "blog, jekyll, blog, jekyll theme, NexT theme, 지킬 테마, 지킬 블로그 포스팅, GitHub Pages", "date": "2021-11-12 00:00:00 +0900", "snippet": "WelcomeHello world, this is my first Jekyll blog post.I hope you like it!" } ]
